"File","SizeBytes","Imports","Mentions"
"D:\dex\backend\app\ai\anomaly_detector.py","40313","from __future__ import annotations | import asyncio | import json | import logging | import math | import statistics | from collections import defaultdict, deque | from dataclasses import dataclass, field | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Deque, Dict, List, Optional, Set, Tuple, Union | import numpy as np | from scipy import stats","It helps identify potential risks before they become losses.  ||  - Integration with existing risk management and alerting systems  ||  affected_trades: List[str] = field(default_factory=list)  ||  ""Low volume may affect trade execution"",  ||  ""High risk - new owner may have different intentions""  ||  ""failed_trades_ratio"": 0.0,  ||  ""risk_level"": ""HIGH"" if stress_score > 0.7 else ""MODERATE"" if stress_score > 0.3 else ""LOW"",  ||  return ""HIGH RISK: Significant anomaly activity. Reduce position sizes and increase monitoring.""  ||  return ""MODERATE RISK: Some anomalies detected. Use caution and monitor alerts closely.""  ||  return ""LOW RISK: Normal market conditions. Standard risk management applies."""
"D:\dex\backend\app\ai\decision_journal.py","49204","from __future__ import annotations | import asyncio | import json | import logging | import statistics | from collections import defaultdict | from dataclasses import dataclass, field | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Set, Tuple","strategies, and understand why certain trades succeeded or failed.  ||  - AI-generated trade rationales and post-mortems  ||  - Integration with existing trading and risk systems  ||  TRADE_ENTRY = ""trade_entry""  ||  TRADE_EXIT = ""trade_exit""  ||  RISK_ADJUSTMENT = ""risk_adjustment""  ||  RISK_MANAGEMENT = ""risk_management""  ||  risk_assessment: Dict[str, Any]  ||  risk_realized: Decimal  ||  risk_expected: Decimal  ||  ""indicators"": [""holding_losers_too_long"", ""quick_profit_taking"", ""risk_reduction_after_loss""],  ||  ""indicators"": [""strategy_change_after_loss"", ""increased_risk_after_win"", ""market_timing_based_on_recent""],  ||  insight_type=""risk"",  ||  ""Risk of significant losses from decision-making patterns""  ||  DecisionType.TRADE_ENTRY: {  ||  ""risk_score"", ""liquidity"", ""price_momentum"", ""volume_profile"",  ||  ""template"": ""Entry decision based on {primary_factor} with {confidence} confidence. {supporting_factors} supported the decision while {risk_factors} were identified as risks.""  ||  DecisionType.TRADE_EXIT: {  ||  ""profit_target"", ""stop_loss"", ""risk_change"", ""market_shift"",  ||  ""template"": ""Exit decision triggered by {exit_reason} after {hold_time}. {outcome_summary} with {risk_management} risk management.""  ||  ""risk_budget"", ""confidence_level"", ""volatility"", ""liquidity"",  ||  ""template"": ""Position size of {position_size} determined by {sizing_method}. Risk factors: {risk_factors}. Expected risk: {expected_risk}.""  ||  risk_difference = float(outcome_data.risk_realized - outcome_data.risk_expected)  ||  f""Risk realized: {float(outcome_data.risk_realized):.1%} vs Expected: {float(outcome_data.risk_expected):.1%}""  ||  if decision.context.risk_assessment:  ||  ""risk_score"": decision.context.risk_assessment.get(""overall_risk_score""),  ||  ""liquidity"": decision.context.risk_assessment.get(""liquidity_score""),  ||  ""volatility"": decision.context.risk_assessment.get(""volatility_score"")  ||  ""risk_factors"": self._format_risk_factors(factors, decision.context.risk_assessment),  ||  if decision.decision_type == DecisionType.TRADE_EXIT and decision.outcome_data:  ||  ""risk_management"": ""effective"" if decision.outcome_data.risk_realized <= decision.outcome_data.risk_expected else ""exceeded""  ||  ""sizing_method"": factors.get(""sizing_method"", ""risk-based calculation""),  ||  ""expected_risk"": f""{factors.get('expected_risk', 'moderate')}""  ||  elif ""risk_score"" in factors:  ||  risk_score = factors[""risk_score""]  ||  if isinstance(risk_score, (int, float)) and risk_score > 0.8:  ||  return ""high risk assessment""  ||  elif isinstance(risk_score, (int, float)) and risk_score < 0.3:  ||  return ""low risk assessment""  ||  def _format_risk_factors(self, factors: Dict[str, Any], risk_assessment: Optional[Dict[str, Any]]) -> str:  ||  """"""Format risk factors into readable text.""""""  ||  risks = []  ||  if risk_assessment:  ||  if risk_assessment.get(""liquidity_risk"", 0) > 0.6:  ||  risks.append(""liquidity constraints"")  ||  if risk_assessment.get(""volatility_risk"", 0) > 0.7:  ||  risks.append(""high volatility"")  ||  if risk_assessment.get(""market_risk"", 0) > 0.5:  ||  risks.append(""adverse market conditions"")  ||  return "", "".join(risks) if risks else ""standard market risks""  ||  # Risk management improvements  ||  if outcome_data.risk_realized > outcome_data.risk_expected * Decimal(""1.5""):  ||  suggestions.append(""refine risk estimation"")  ||  recommendation=""Review decision process and implement stricter risk management"",  ||  # Record a trade entry decision  ||  risk_assessment={""overall_risk_score"": 0.3, ""liquidity_score"": 0.8},  ||  decision_id=""trade_001"",  ||  decision_type=DecisionType.TRADE_ENTRY,  ||  rationale=""High confidence entry based on technical analysis and low risk assessment"",  ||  expected_outcome={""expected_pnl"": ""100"", ""expected_risk"": ""0.02"", ""time_horizon"": ""24h""}  ||  risk_realized=Decimal(""0.015""),  ||  risk_expected=Decimal(""0.02""),  ||  await journal.update_decision_outcome(""trade_001"", DecisionOutcome.GOOD, outcome_data)"
"D:\dex\backend\app\ai\ensemble_models.py","54225","from __future__ import annotations | import asyncio | import json | import logging | import math | import statistics | from collections import defaultdict, deque | from dataclasses import dataclass, field | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Tuple, Union | import numpy as np | from scipy import stats | from scipy.stats import entropy | import logging | from ..core.settings import settings","risk_estimate: float  # Risk/volatility estimate  ||  # Risk assessment  ||  downside_risk: float  # VaR-style downside risk  ||  risk_level: str  # ""low"", ""moderate"", ""high"", ""extreme""  ||  risk_estimate=volatility * horizon_multiplier,  ||  risk_estimate=0.05,  ||  risk_estimate=features.volatility_1h * horizon_scale,  ||  risk_estimate=0.05,  ||  risk_estimate=features.volatility_1h * positional_adjustment,  ||  risk_estimate=0.05,  ||  downside_risk=ensemble_result[""downside_risk""],  ||  risk_level=ensemble_result[""risk_level""],  ||  # Risk assessment  ||  volatilities = [p.risk_estimate for p in predictions.values()]  ||  downside_risk = avg_volatility * 2  # VaR-style metric  ||  # Risk level  ||  risk_level = self._assess_risk_level(avg_volatility, consensus_strength, total_confidence)  ||  ""downside_risk"": downside_risk,  ||  ""risk_level"": risk_level,  ||  def _assess_risk_level(self, volatility: float, consensus: float, confidence: float) -> str:  ||  """"""Assess overall risk level.""""""  ||  # Higher volatility = higher risk  ||  # Lower consensus = higher risk  ||  # Lower confidence = higher risk  ||  risk_score = volatility * 10 + (1 - consensus) * 5 + (1 - confidence) * 3  ||  if risk_score > 10:  ||  elif risk_score > 7:  ||  elif risk_score > 4:  ||  downside_risk=0.05,  ||  risk_level=""moderate"",  ||  print(f""  Risk Level: {prediction.risk_level}"")"
"D:\dex\backend\app\ai\federated_learning.py","47536","from __future__ import annotations | import asyncio | import hashlib | import json | import logging | import math | import random | import statistics | from collections import defaultdict, deque | from dataclasses import dataclass, field | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Set, Tuple, Union | import numpy as np | from scipy.stats import entropy | import logging | from ..core.settings import settings","RISK_CALIBRATION = ""risk_calibration""  ||  risk_adjusted_return_improvement: float  ||  sample_size: int  # Number of trades/decisions  ||  ""total_trades_analyzed"": 0,  ||  ""risk_level"": consensus_data.get(""avg_risk_score"", 0.5),  ||  ""risk_level"": 0.5,  ||  risk_adjusted_return_improvement=performance_data.get(""risk_adjusted_return_improvement"", 0.0),  ||  ""total_trades_analyzed"": model.total_sample_size,  ||  ""risk_adjusted_return_improvement"": random.uniform(0.02, 0.15),  ||  ""risk_score_threshold"": random.uniform(0.3, 0.7)"
"D:\dex\backend\app\ai\market_intelligence.py","97022","from __future__ import annotations | import asyncio | import json | import logging | import math | import re | import statistics | from collections import defaultdict, deque | from dataclasses import dataclass, field | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Set, Tuple, Union | import numpy as np | from scipy.stats import pearsonr, zscore | from ..core.settings import settings | import logging","- Coordination pattern recognition across multiple wallets  ||  wallet_balance_before: Decimal  ||  wallet_balance_after: Decimal  ||  manipulation_risk: float = 0.0  ||  manipulation_risk: float = 0.0  ||  Monitors large wallet movements, identifies patterns, and predicts  ||  # Calculate manipulation risk  ||  manipulation_risk = self._calculate_manipulation_risk(whale_transactions)  ||  manipulation_risk=manipulation_risk,  ||  wallet_balance_before=Decimal(str(tx_data.get(""balance_before"", 0))),  ||  wallet_balance_after=Decimal(str(tx_data.get(""balance_after"", 0))),  ||  def _calculate_manipulation_risk(self, whale_transactions: List[WhaleTransaction]) -> float:  ||  """"""Calculate manipulation risk based on whale patterns.""""""  ||  risk_factors = 0.0  ||  risk_factors += 0.2  ||  risk_factors += (unusual_timing_count / len(whale_transactions)) * 0.5  ||  risk_factors += (high_impact_count / len(whale_transactions)) * 0.3  ||  return min(1.0, risk_factors)  ||  manipulation_risk=confidence * 0.8,  ||  manipulation_risk=wash_score * 0.9,  ||  manipulation_risk=avg_bot_score * 0.6,  ||  # Check gas price (bots often use consistent gas prices)  ||  gas_price = transaction.get(""gas_price"", 0)  ||  if gas_price > 0:  ||  # Check transaction timing (bots often execute at precise intervals)  ||  ""manipulation_risk"": whale_activity.manipulation_risk,  ||  ""highest_risk_level"": self._get_highest_risk_level(coordination_alerts),  ||  ""manipulation_risk"": self._assess_coordination_risk(coordination_alerts),  ||  ""risk_factors"": self._identify_risk_factors(  ||  # Coordination risk component (inverted, 0-1 scale)  ||  coordination_risk = self._assess_coordination_risk(coordination_alerts)  ||  coordination_component = 1.0 - coordination_risk  ||  def _get_highest_risk_level(self, alerts: List[CoordinationAlert]) -> str:  ||  """"""Get highest risk level from coordination alerts.""""""  ||  risk_levels = [""critical"", ""high"", ""medium"", ""low""]  ||  for level in risk_levels:  ||  def _assess_coordination_risk(self, alerts: List[CoordinationAlert]) -> float:  ||  """"""Assess overall coordination risk.""""""  ||  risk_scores = []  ||  risk_score = alert.confidence * severity_weight  ||  risk_scores.append(risk_score)  ||  # Use maximum risk score  ||  return max(risk_scores) if risk_scores else 0.0  ||  coordination_risk = self._assess_coordination_risk(alerts)  ||  # Combine intelligence score and coordination risk  ||  health_score = intelligence_score * (1.0 - coordination_risk)  ||  if whale_activity.manipulation_risk > 0.7:  ||  recommendations.append(""High manipulation risk from whale activity - use smaller position sizes"")  ||  high_risk_alerts = [a for a in alerts if a.severity == ""high""]  ||  if high_risk_alerts:  ||  recommendations.append(""High coordination risk detected - reduce position sizes and monitor closely"")  ||  recommendations.append(""Market intelligence shows mixed signals - proceed with standard risk management"")  ||  def _identify_risk_factors(  ||  """"""Identify key risk factors.""""""  ||  risk_factors = []  ||  # High-risk sentiment factors  ||  risk_factors.append(f""High bot activity ({sentiment.bot_percentage:.1%})"")  ||  risk_factors.append(f""High spam content ({sentiment.spam_percentage:.1%})"")  ||  # Whale-related risks  ||  if whale_activity.manipulation_risk > 0.6:  ||  risk_factors.append(f""Whale manipulation risk ({whale_activity.manipulation_risk:.1%})"")  ||  risk_factors.append(""Coordinated whale activity detected"")  ||  # Market regime risks  ||  risk_factors.append(""Extreme volatility regime"")  ||  risk_factors.append(""Extreme price volatility"")  ||  # Coordination risks  ||  risk_factors.append(f""{alert.pattern_type.value} detected ({alert.severity} risk)"")  ||  return risk_factors[:5]  # Return top 5 risk factors  ||  ""manipulation_risk"": 0.0  ||  ""risk_factors"": [""Analysis system unavailable""],  ||  print(f""Manipulation Risk: {whale['manipulation_risk']:.1%}"")  ||  if intelligence_report['risk_factors']:  ||  print(""\n--- Risk Factors ---"")  ||  for risk in intelligence_report['risk_factors']:  ||  print(f""⚠️ {risk}"")"
"D:\dex\backend\app\ai\reinforcement_learning.py","41234","from __future__ import annotations | import asyncio | import json | import logging | import math | import random | from collections import defaultdict, deque | from dataclasses import dataclass, field | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Tuple, Union | import numpy as np | from scipy.stats import beta | import logging | from ..core.settings import settings","This module implements Q-Learning for trade timing, Multi-Armed Bandit for strategy  ||  RISK_ADJUSTED = ""risk_adjusted""  ||  risk_exposure: float  ||  self.risk_exposure,  ||  """"""Q-Learning agent for optimal trade timing.""""""  ||  def get_position_size(self, state: MarketState, risk_tolerance: float = 0.1) -> float:  ||  risk_tolerance: Maximum risk tolerance (0.0 to 1.0)  ||  # Apply risk tolerance cap  ||  final_size = min(combined_size, risk_tolerance)  ||  risk_exposure=0.0, time_in_position=0, market_session=""american"",  ||  self.reward_type = RewardType.RISK_ADJUSTED  ||  risk_tolerance: float = 0.1  ||  risk_tolerance: Risk tolerance for position sizing  ||  market_state, risk_tolerance  ||  ""risk_level"": self._assess_risk_level(market_state, optimal_position_size),  ||  elif self.reward_type == RewardType.RISK_ADJUSTED:  ||  # Risk-adjusted normalization  ||  def _assess_risk_level(self, state: MarketState, position_size: float) -> str:  ||  """"""Assess risk level of the decision.""""""  ||  risk_score = 0.0  ||  # Position size risk  ||  risk_score += position_size * 0.4  ||  # Volatility risk  ||  risk_score += state.volatility * 5.0  ||  # Market condition risk  ||  risk_score += 0.2  ||  # Liquidity risk  ||  risk_score += 0.3  ||  if risk_score < 0.3:  ||  elif risk_score < 0.6:  ||  elif risk_score < 0.8:  ||  ""risk_level"": ""moderate"",  ||  risk_exposure=0.15,  ||  risk_tolerance=0.2  ||  print(f""  Risk Level: {decision['risk_level']}"")"
"D:\dex\backend\app\ai\risk_explainer.py","40084","from __future__ import annotations | import logging | import re | from dataclasses import dataclass, field | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Set, Tuple |     import asyncio","""""""AI Risk Explanation System.  ||  This module provides natural language explanations of risk assessments and trading  ||  recommendations. It translates complex risk metrics into human-readable insights  ||  that help users understand why certain trades are flagged as risky or safe.  ||  - Plain-English risk explanations with specific examples  ||  - Integration with existing risk management framework  ||  """"""Risk explanation styles for different user types.""""""  ||  class RiskSeverity(Enum):  ||  """"""Risk severity levels for messaging.""""""  ||  class RiskFactor:  ||  """"""Individual risk factor with explanation.""""""  ||  severity: RiskSeverity  ||  class RiskExplanation:  ||  """"""Complete risk explanation with natural language output.""""""  ||  overall_risk: RiskSeverity  ||  risk_score: Decimal  ||  risk_factors: List[RiskFactor]  ||  class RiskExplainer:  ||  """"""AI-powered risk explanation system.""""""  ||  """"""Initialize risk explainer.  ||  # Risk factor templates for explanation generation  ||  self.risk_templates = {  ||  ""name"": ""Liquidity Risk"",  ||  RiskSeverity.SAFE: ""Excellent liquidity with deep order book"",  ||  RiskSeverity.LOW: ""Good liquidity with reasonable depth"",  ||  RiskSeverity.MODERATE: ""Moderate liquidity, expect some slippage"",  ||  RiskSeverity.HIGH: ""Low liquidity, significant slippage risk"",  ||  RiskSeverity.CRITICAL: ""Extremely low liquidity, very high slippage risk""  ||  RiskSeverity.SAFE: ""Normal position sizing acceptable"",  ||  RiskSeverity.LOW: ""Consider slightly smaller positions"",  ||  RiskSeverity.MODERATE: ""Use smaller positions and wider slippage tolerance"",  ||  RiskSeverity.HIGH: ""Use very small positions and high slippage tolerance"",  ||  RiskSeverity.CRITICAL: ""Avoid trading or use micro positions only""  ||  RiskSeverity.SAFE: ""Contract appears secure with standard functions"",  ||  RiskSeverity.LOW: ""Minor contract risks detected"",  ||  RiskSeverity.MODERATE: ""Some concerning contract features found"",  ||  RiskSeverity.HIGH: ""Significant contract security risks detected"",  ||  RiskSeverity.CRITICAL: ""Severe security vulnerabilities found""  ||  RiskSeverity.SAFE: ""Contract security checks passed"",  ||  RiskSeverity.LOW: ""Monitor for unusual behavior"",  ||  RiskSeverity.MODERATE: ""Use small test positions first"",  ||  RiskSeverity.HIGH: ""Extreme caution recommended"",  ||  RiskSeverity.CRITICAL: ""Avoid trading this token""  ||  ""name"": ""Honeypot Risk"",  ||  RiskSeverity.SAFE: ""No honeypot characteristics detected"",  ||  RiskSeverity.LOW: ""Minor flags but likely tradeable"",  ||  RiskSeverity.MODERATE: ""Some honeypot indicators present"",  ||  RiskSeverity.HIGH: ""Multiple honeypot warning signs"",  ||  RiskSeverity.CRITICAL: ""Strong honeypot indicators detected""  ||  RiskSeverity.SAFE: ""Trading should work normally"",  ||  RiskSeverity.LOW: ""Test with very small amount first"",  ||  RiskSeverity.MODERATE: ""Perform canary trade before full position"",  ||  RiskSeverity.HIGH: ""Highly recommend avoiding this token"",  ||  RiskSeverity.CRITICAL: ""Do not trade - likely honeypot""  ||  RiskSeverity.SAFE: ""Healthy trading volume with good activity"",  ||  RiskSeverity.LOW: ""Decent volume but could be higher"",  ||  RiskSeverity.MODERATE: ""Low volume may affect execution"",  ||  RiskSeverity.HIGH: ""Very low volume, poor execution likely"",  ||  RiskSeverity.CRITICAL: ""Extremely low volume, avoid trading""  ||  RiskSeverity.SAFE: ""Volume supports normal trading"",  ||  RiskSeverity.LOW: ""Consider timing trades around volume spikes"",  ||  RiskSeverity.MODERATE: ""Use limit orders and expect delays"",  ||  RiskSeverity.HIGH: ""Only trade during volume spikes"",  ||  RiskSeverity.CRITICAL: ""Wait for volume to increase""  ||  RiskSeverity.SAFE: ""Well-distributed token ownership"",  ||  RiskSeverity.LOW: ""Slightly concentrated but acceptable"",  ||  RiskSeverity.MODERATE: ""Moderate concentration among few wallets"",  ||  RiskSeverity.HIGH: ""High concentration creates dump risk"",  ||  RiskSeverity.CRITICAL: ""Extreme concentration - major dump risk""  ||  RiskSeverity.SAFE: ""Holder distribution looks healthy"",  ||  RiskSeverity.LOW: ""Monitor large holder activity"",  ||  RiskSeverity.MODERATE: ""Watch for large holder movements"",  ||  RiskSeverity.HIGH: ""High risk of coordinated selling"",  ||  RiskSeverity.CRITICAL: ""Extreme dump risk from concentrated holders""  ||  RiskSeverity.SAFE: ""Normal volatility patterns"",  ||  RiskSeverity.LOW: ""Slightly elevated volatility"",  ||  RiskSeverity.MODERATE: ""High volatility expected"",  ||  RiskSeverity.HIGH: ""Extreme volatility likely"",  ||  RiskSeverity.CRITICAL: ""Chaotic price movements expected""  ||  RiskSeverity.SAFE: ""Standard position sizing appropriate"",  ||  RiskSeverity.LOW: ""Consider slightly tighter stops"",  ||  RiskSeverity.MODERATE: ""Use smaller positions and wider stops"",  ||  RiskSeverity.HIGH: ""Use very small positions"",  ||  RiskSeverity.CRITICAL: ""Avoid or use micro positions only""  ||  # Educational content for different risk categories  ||  ""Low liquidity means your trades can move the price significantly (slippage)"",  ||  ""Owner privileges like blacklisting or tax changes can impact your trades"",  ||  ""Unverified contracts carry additional risks""  ||  ""High concentration means few wallets own most of the supply"",  ||  ""Concentrated holdings create risk of coordinated dumps"",  ||  def _determine_severity(self, score: Decimal, thresholds: Dict[str, Decimal]) -> RiskSeverity:  ||  """"""Determine risk severity based on score and thresholds.""""""  ||  return RiskSeverity.SAFE  ||  return RiskSeverity.LOW  ||  return RiskSeverity.MODERATE  ||  return RiskSeverity.HIGH  ||  return RiskSeverity.CRITICAL  ||  def explain_liquidity_risk(self,  ||  trade_size_usd: Decimal) -> RiskFactor:  ||  """"""Explain liquidity-related risks.""""""  ||  return RiskFactor(  ||  name=""Liquidity Risk"",  ||  severity=RiskSeverity.CRITICAL,  ||  liquidity_ratio = trade_size_usd / liquidity_usd if liquidity_usd > 0 else Decimal(""1.0"")  ||  severity = RiskSeverity.SAFE  ||  severity = RiskSeverity.LOW  ||  severity = RiskSeverity.MODERATE  ||  severity = RiskSeverity.HIGH  ||  severity = RiskSeverity.CRITICAL  ||  template = self.risk_templates[""liquidity""]  ||  evidence.append(f""Your trade size: {self._format_currency(trade_size_usd)}"")  ||  evidence.append(f""Trade/Liquidity ratio: {self._format_percentage(liquidity_ratio)}"")  ||  explanation += f"". With ${self._format_currency(liquidity_usd)} in liquidity and your trade of {self._format_currency(trade_size_usd)}, you're trading {self._format_percentage(liquidity_ratio)} of the available liquidity.""  ||  return RiskFactor(  ||  name=""Liquidity Risk"",  ||  owner_privileges: List[str]) -> RiskFactor:  ||  """"""Explain contract security risks.""""""  ||  risk_factors = []  ||  risk_factors.append(""Contract is not verified"")  ||  high_risk_privileges = {""mint"", ""blacklist"", ""pause"", ""modify_tax"", ""modify_limits""}  ||  dangerous_privileges = [p for p in owner_privileges if p in high_risk_privileges]  ||  risk_factors.append(f""Owner can: {', '.join(dangerous_privileges)}"")  ||  risk_factors.append(""Uses proxy contract (implementation can change)"")  ||  risk_factors.append(""Contains suspicious functions"")  ||  if len(risk_factors) == 0:  ||  severity = RiskSeverity.SAFE  ||  elif len(risk_factors) <= 1 and not dangerous_privileges:  ||  severity = RiskSeverity.LOW  ||  elif len(risk_factors) <= 2:  ||  severity = RiskSeverity.MODERATE  ||  severity = RiskSeverity.HIGH  ||  severity = RiskSeverity.CRITICAL  ||  template = self.risk_templates[""contract_security""]  ||  if risk_factors and self.explanation_style != ExplanationStyle.EXPERT:  ||  explanation += f"". Specific concerns: {'; '.join(risk_factors[:3])}""  ||  evidence = risk_factors if risk_factors else [""Standard contract functions detected""]  ||  return RiskFactor(  ||  score=Decimal(str(len(risk_factors) * 0.2)),  ||  def explain_honeypot_risk(self,  ||  simulation_results: Optional[Dict[str, Any]]) -> RiskFactor:  ||  """"""Explain honeypot-related risks.""""""  ||  severity = RiskSeverity.CRITICAL  ||  severity = RiskSeverity.HIGH  ||  severity = RiskSeverity.MODERATE  ||  severity = RiskSeverity.LOW  ||  severity = RiskSeverity.SAFE  ||  template = self.risk_templates[""honeypot""]  ||  if severity != RiskSeverity.CRITICAL:  ||  severity = RiskSeverity.HIGH  ||  return RiskFactor(  ||  name=""Honeypot Risk"",  ||  def explain_volume_risk(self,  ||  trade_size_usd: Decimal) -> RiskFactor:  ||  """"""Explain trading volume risks.""""""  ||  severity = RiskSeverity.HIGH  ||  volume_ratio = trade_size_usd / volume_24h if volume_24h > 0 else Decimal(""1.0"")  ||  severity = RiskSeverity.SAFE  ||  severity = RiskSeverity.LOW  ||  severity = RiskSeverity.MODERATE  ||  severity = RiskSeverity.HIGH  ||  severity = RiskSeverity.CRITICAL  ||  template = self.risk_templates[""trading_volume""]  ||  evidence.append(f""Your trade size: {self._format_currency(trade_size_usd)}"")  ||  evidence.append(f""Trade/Volume ratio: {self._format_percentage(volume_ratio)}"")  ||  return RiskFactor(  ||  total_holders: Optional[int]) -> RiskFactor:  ||  """"""Explain holder concentration risks.""""""  ||  severity = RiskSeverity.MODERATE  ||  severity = RiskSeverity.SAFE  ||  severity = RiskSeverity.LOW  ||  severity = RiskSeverity.MODERATE  ||  severity = RiskSeverity.HIGH  ||  severity = RiskSeverity.CRITICAL  ||  template = self.risk_templates[""holder_concentration""]  ||  if severity == RiskSeverity.SAFE:  ||  severity = RiskSeverity.LOW  ||  evidence.append(""Very few holders increases concentration risk"")  ||  return RiskFactor(  ||  risk_assessment: Dict[str, Any],  ||  trade_context: Dict[str, Any]) -> RiskExplanation:  ||  """"""Generate comprehensive risk explanation with natural language output.  ||  risk_assessment: Risk assessment data from RiskManager  ||  trade_context: Trade context including size, strategy, etc.  ||  Complete risk explanation with recommendations  ||  risk_factors = []  ||  # Extract trade context  ||  trade_size_usd = Decimal(str(trade_context.get(""trade_size_usd"", ""1000"")))  ||  strategy_name = trade_context.get(""strategy_name"", ""manual"")  ||  # Analyze liquidity risk  ||  liquidity_risk = self.explain_liquidity_risk(  ||  liquidity_usd=risk_assessment.get(""liquidity_usd""),  ||  trading_volume_24h=risk_assessment.get(""volume_24h""),  ||  price_impact=risk_assessment.get(""price_impact""),  ||  trade_size_usd=trade_size_usd  ||  risk_factors.append(liquidity_risk)  ||  security_risk = self.explain_contract_security(  ||  security_data=risk_assessment.get(""security_data"", {}),  ||  contract_verified=risk_assessment.get(""contract_verified"", False),  ||  owner_privileges=risk_assessment.get(""owner_privileges"", [])  ||  risk_factors.append(security_risk)  ||  # Analyze honeypot risk  ||  honeypot_risk = self.explain_honeypot_risk(  ||  honeypot_detected=risk_assessment.get(""honeypot_detected"", False),  ||  honeypot_confidence=risk_assessment.get(""honeypot_confidence"", 0.0),  ||  simulation_results=risk_assessment.get(""simulation_results"")  ||  risk_factors.append(honeypot_risk)  ||  # Analyze volume risk  ||  volume_risk = self.explain_volume_risk(  ||  volume_24h=risk_assessment.get(""volume_24h""),  ||  volume_change_24h=risk_assessment.get(""volume_change_24h""),  ||  trade_size_usd=trade_size_usd  ||  risk_factors.append(volume_risk)  ||  holder_risk = self.explain_holder_concentration(  ||  top_10_holders_percent=risk_assessment.get(""top_10_holders_percent""),  ||  total_holders=risk_assessment.get(""total_holders"")  ||  risk_factors.append(holder_risk)  ||  # Calculate overall risk  ||  total_weighted_score = sum(factor.score * factor.weight for factor in risk_factors)  ||  total_weight = sum(factor.weight for factor in risk_factors)  ||  summary = self._generate_summary(overall_severity, overall_score, risk_factors)  ||  detailed_explanation = self._generate_detailed_explanation(risk_factors, trade_context)  ||  recommendations = self._generate_recommendations(risk_factors, overall_severity, trade_context)  ||  warnings = self._generate_warnings(risk_factors)  ||  educational_notes = self._generate_educational_notes(risk_factors)  ||  confidence = self._calculate_confidence(risk_assessment)  ||  return RiskExplanation(  ||  overall_risk=overall_severity,  ||  risk_score=overall_score,  ||  risk_factors=risk_factors,  ||  severity: RiskSeverity,  ||  risk_factors: List[RiskFactor]) -> str:  ||  """"""Generate concise risk summary.""""""  ||  RiskSeverity.SAFE: ""This trade appears safe with minimal risks detected"",  ||  RiskSeverity.LOW: ""This trade has low risk with minor concerns"",  ||  RiskSeverity.MODERATE: ""This trade has moderate risk requiring attention"",  ||  RiskSeverity.HIGH: ""This trade is high risk and requires extreme caution"",  ||  RiskSeverity.CRITICAL: ""This trade is extremely risky and should be avoided""  ||  high_risk_factors = [f for f in risk_factors if f.severity in [RiskSeverity.HIGH, RiskSeverity.CRITICAL]]  ||  if high_risk_factors:  ||  concerns = [f.name for f in high_risk_factors[:2]]  ||  base_summary += f"". Overall risk score: {float(score * 100):.0f}/100""  ||  risk_factors: List[RiskFactor],  ||  trade_context: Dict[str, Any]) -> str:  ||  """"""Generate detailed risk explanation.""""""  ||  critical_factors = [f for f in risk_factors if f.severity == RiskSeverity.CRITICAL]  ||  high_factors = [f for f in risk_factors if f.severity == RiskSeverity.HIGH]  ||  moderate_factors = [f for f in risk_factors if f.severity == RiskSeverity.MODERATE]  ||  explanations.append(""CRITICAL RISKS:"")  ||  explanations.append(""HIGH RISKS:"")  ||  explanations.append(""MODERATE RISKS:"")  ||  strategy_name = trade_context.get(""strategy_name"", ""manual"")  ||  explanations.append(""NEW PAIR CONTEXT: Early trading carries additional risks due to limited price history and potential volatility."")  ||  risk_factors: List[RiskFactor],  ||  overall_severity: RiskSeverity,  ||  trade_context: Dict[str, Any]) -> List[str]:  ||  if overall_severity == RiskSeverity.CRITICAL:  ||  recommendations.append(""❌ AVOID this trade - risks are too high"")  ||  elif overall_severity == RiskSeverity.HIGH:  ||  elif overall_severity == RiskSeverity.MODERATE:  ||  recommendations.append(""⚡ Proceed with caution - use risk management"")  ||  recommendations.append(""✅ Trade appears acceptable with standard precautions"")  ||  # Specific recommendations from risk factors  ||  for factor in risk_factors:  ||  if factor.severity in [RiskSeverity.HIGH, RiskSeverity.CRITICAL]:  ||  trade_size = Decimal(str(trade_context.get(""trade_size_usd"", ""1000"")))  ||  if overall_severity == RiskSeverity.HIGH:  ||  recommended_size = trade_size * Decimal(""0.5"")  ||  elif overall_severity == RiskSeverity.CRITICAL:  ||  liquidity_factor = next((f for f in risk_factors if f.name == ""Liquidity Risk""), None)  ||  if liquidity_factor and liquidity_factor.severity >= RiskSeverity.MODERATE:  ||  if liquidity_factor.severity == RiskSeverity.HIGH:  ||  def _generate_warnings(self, risk_factors: List[RiskFactor]) -> List[str]:  ||  """"""Generate specific warnings for high-risk factors.""""""  ||  for factor in risk_factors:  ||  warnings.append(f""HIGH RISK: {factor.name} - {factor.explanation}"")  ||  def _generate_educational_notes(self, risk_factors: List[RiskFactor]) -> List[str]:  ||  """"""Generate educational content based on detected risks.""""""  ||  risk_categories = set()  ||  for factor in risk_factors:  ||  if factor.severity >= RiskSeverity.MODERATE:  ||  risk_categories.add(""liquidity"")  ||  risk_categories.add(""honeypot"")  ||  risk_categories.add(""contract_security"")  ||  risk_categories.add(""holder_concentration"")  ||  for category in risk_categories:  ||  def _calculate_confidence(self, risk_assessment: Dict[str, Any]) -> float:  ||  if risk_assessment.get(point) is not None:  ||  if risk_assessment.get(""simulation_results""):  ||  if risk_assessment.get(""external_provider_consensus"", 0) >= 2:  ||  # Global risk explainer instance  ||  _risk_explainer: Optional[RiskExplainer] = None  ||  async def get_risk_explainer(style: ExplanationStyle = ExplanationStyle.INTERMEDIATE) -> RiskExplainer:  ||  """"""Get or create global risk explainer instance.""""""  ||  global _risk_explainer  ||  if _risk_explainer is None or _risk_explainer.explanation_style != style:  ||  _risk_explainer = RiskExplainer(style)  ||  return _risk_explainer  ||  async def explain_trade_risk(risk_assessment: Dict[str, Any],  ||  trade_context: Dict[str, Any],  ||  style: ExplanationStyle = ExplanationStyle.INTERMEDIATE) -> RiskExplanation:  ||  """"""Generate comprehensive risk explanation for a trade.  ||  risk_assessment: Risk assessment data from RiskManager  ||  trade_context: Trade context including size, strategy, etc.  ||  Complete risk explanation with natural language output  ||  explainer = await get_risk_explainer(style)  ||  return explainer.generate_comprehensive_explanation(risk_assessment, trade_context)  ||  async def example_risk_explanation() -> None:  ||  """"""Example risk explanation workflow.""""""  ||  # Sample risk assessment data  ||  risk_assessment = {  ||  # Sample trade context  ||  trade_context = {  ||  ""trade_size_usd"": ""2000"",  ||  explanation = await explain_trade_risk(risk_assessment, trade_context, ExplanationStyle.BEGINNER)  ||  print(""=== RISK EXPLANATION ==="")  ||  print(f""Overall Risk: {explanation.overall_risk.value.upper()}"")  ||  print(f""Risk Score: {float(explanation.risk_score * 100):.0f}/100"")  ||  asyncio.run(example_risk_explanation())"
"D:\dex\backend\app\ai\tuner.py","28349","from __future__ import annotations | import asyncio | import json | import logging | import time | from dataclasses import dataclass, field | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Tuple, Union | import numpy as np | from scipy.optimize import minimize | from scipy.stats import norm","to maximize expected PnL while respecting risk constraints.  ||  - Operates within strict guardrails to prevent excessive risk-taking  ||  - Integrates with existing strategy and risk management systems  ||  risk_score: Decimal  ||  simulation_trades: int  ||  risk_budget: Decimal = Decimal(""0.02"")  # 2% max risk per trade  ||  ""gas_price_multiplier"": ParameterBounds(  ||  ""risk_score_threshold"": ParameterBounds(  ||  risk_budget: Decimal = Decimal(""0.02"")) -> str:  ||  risk_budget: Maximum risk per trade during optimization  ||  risk_budget=risk_budget  ||  # Calculate objective value (risk-adjusted PnL)  ||  if result.risk_score > Decimal(""0.8""):  ||  # Penalize high-risk results  ||  ""risk_score"": str(result.risk_score),  ||  ""risk_budget"": str(session.risk_budget),  ||  ""risk_score"": str(session.best_result.risk_score),  ||  ""risk_score"": str(best_result.risk_score),  ||  # Risk assessment  ||  risk_score = float(result.risk_score)  ||  if risk_score < 0.3:  ||  explanations.append(""Low risk configuration with conservative parameters"")  ||  elif risk_score < 0.7:  ||  explanations.append(""Moderate risk configuration balancing opportunity and safety"")  ||  explanations.append(""Higher risk configuration focused on opportunity capture"")  ||  explanations.append(f""Lower win rate of {result.win_rate:.1%} suggests focus on risk management"")  ||  explanations.append(""Low maximum drawdown indicates good risk control"")  ||  explanations.append(""Strong risk-adjusted returns with good Sharpe ratio"")  ||  risk_budget=Decimal(""0.01"")  ||  simulated_risk = Decimal(str(np.random.uniform(0.2, 0.8)))  ||  risk_score=simulated_risk,  ||  simulation_trades=100,"
"D:\dex\backend\app\analytics\metrics.py","26393","from __future__ import annotations | import logging | from datetime import datetime, timedelta | from decimal import Decimal | from typing import Dict, List, Optional, Union | from dataclasses import dataclass | from enum import Enum | from pydantic import BaseModel, Field | from .performance import PerformanceAnalyzer, TradeResult, PerformancePeriod","from .performance import PerformanceAnalyzer, TradeResult, PerformancePeriod  ||  RISK_MANAGEMENT = ""risk_management""  ||  daily_trades: int = Field(..., description=""Trades executed today"")  ||  rolling_24h_trades: int = Field(..., description=""24-hour trade count"")  ||  # Risk indicators  ||  daily_risk_score: float = Field(..., description=""Daily risk score (0-100)"")  ||  failed_trades_today: int = Field(..., description=""Failed trades today"")  ||  gas_spent_today_usd: Decimal = Field(..., description=""Gas costs today"")  ||  sharpe_ratio: Optional[Decimal] = Field(None, description=""Risk-adjusted return"")  ||  average_trade_size_usd: Decimal = Field(..., description=""Average trade size"")  ||  largest_trade_usd: Decimal = Field(..., description=""Largest single trade"")  ||  trades_per_day: float = Field(..., description=""Average trades per day"")  ||  MetricThreshold(""failed_trades_today"", 5, 10, ""gt""),  ||  MetricThreshold(""daily_risk_score"", 70.0, 85.0, ""gt""),  ||  recent_trades: List[TradeResult],  ||  recent_trades: Recent trade results for analysis  ||  f""Calculating real-time metrics for {len(recent_trades)} trades"",  ||  # Filter trades by time periods  ||  today_trades = [t for t in recent_trades if t.timestamp >= today_start]  ||  last_24h_trades = [t for t in recent_trades if t.timestamp >= now - timedelta(hours=24)]  ||  last_7d_trades = [t for t in recent_trades if t.timestamp >= now - timedelta(days=7)]  ||  last_30d_trades = [t for t in recent_trades if t.timestamp >= now - timedelta(days=30)]  ||  daily_pnl = sum((t.pnl_usd for t in today_trades), Decimal(""0""))  ||  daily_pnl_pct = sum((t.pnl_percentage for t in today_trades), Decimal(""0""))  ||  daily_wins = len([t for t in today_trades if t.pnl_usd > 0])  ||  daily_win_rate = (daily_wins / len(today_trades) * 100) if today_trades else 0.0  ||  rolling_7d_pnl = sum((t.pnl_usd for t in last_7d_trades), Decimal(""0""))  ||  rolling_30d_wins = len([t for t in last_30d_trades if t.pnl_usd > 0])  ||  rolling_30d_win_rate = (rolling_30d_wins / len(last_30d_trades) * 100) if last_30d_trades else 0.0  ||  # Risk metrics  ||  current_drawdown = await self._calculate_current_drawdown(recent_trades)  ||  daily_risk_score = await self._calculate_daily_risk_score(today_trades)  ||  sum(t.execution_time_ms for t in today_trades) / len(today_trades)  ||  if today_trades else 0.0  ||  failed_today = len([t for t in today_trades if not t.is_successful])  ||  gas_spent_today = sum((t.gas_cost_usd for t in today_trades), Decimal(""0""))  ||  strategy_performance = await self._calculate_strategy_performance(today_trades)  ||  daily_trades=len(today_trades),  ||  rolling_24h_trades=len(last_24h_trades),  ||  daily_risk_score=daily_risk_score,  ||  failed_trades_today=failed_today,  ||  gas_spent_today_usd=gas_spent_today,  ||  ""daily_trades"": len(today_trades),  ||  extra={""trades_count"": len(recent_trades), ""module"": ""trading_metrics""}  ||  trades: List[TradeResult],  ||  trades: Trade results for KPI calculation  ||  extra={""trades_count"": len(trades), ""module"": ""trading_metrics""}  ||  performance = await self.performance_analyzer.calculate_performance(trades, period)  ||  annualized_return = await self._calculate_annualized_return(trades, period)  ||  volume_metrics = await self._calculate_volume_metrics(trades)  ||  efficiency_metrics = await self._calculate_efficiency_metrics(trades)  ||  cost_metrics = await self._calculate_cost_metrics(trades)  ||  average_trade_size_usd=volume_metrics[""average_size""],  ||  largest_trade_usd=volume_metrics[""largest_trade""],  ||  trades_per_day=efficiency_metrics[""trades_per_day""],  ||  ""failed_trades_today"": metrics.failed_trades_today,  ||  ""daily_risk_score"": metrics.daily_risk_score,  ||  async def _calculate_current_drawdown(self, trades: List[TradeResult]) -> Decimal:  ||  if not trades:  ||  # Sort trades by timestamp  ||  sorted_trades = sorted(trades, key=lambda t: t.timestamp)  ||  for trade in sorted_trades:  ||  running_equity += trade.pnl_usd  ||  async def _calculate_daily_risk_score(self, today_trades: List[TradeResult]) -> float:  ||  """"""Calculate daily risk score based on various factors.""""""  ||  if not today_trades:  ||  # Risk factors (0-100 scale)  ||  risk_factors = []  ||  # Trade frequency risk  ||  trade_frequency_risk = min(len(today_trades) * 2, 30)  # Cap at 30  ||  risk_factors.append(trade_frequency_risk)  ||  # Loss streak risk  ||  for trade in reversed(today_trades):  # Most recent first  ||  if trade.pnl_usd < 0:  ||  loss_streak_risk = min(max_loss_streak * 10, 40)  # Cap at 40  ||  risk_factors.append(loss_streak_risk)  ||  # Large loss risk  ||  largest_loss_pct = max((abs(float(t.pnl_percentage)) for t in today_trades if t.pnl_usd < 0), default=0)  ||  large_loss_risk = min(largest_loss_pct * 2, 30)  # Cap at 30  ||  risk_factors.append(large_loss_risk)  ||  total_risk = sum(risk_factors) / len(risk_factors) if risk_factors else 0  ||  return min(total_risk, 100.0)  ||  async def _calculate_strategy_performance(self, trades: List[TradeResult]) -> Dict[str, Union[str, int]]:  ||  if not trades:  ||  for trade in trades:  ||  if trade.strategy_type not in strategy_pnl:  ||  strategy_pnl[trade.strategy_type] = Decimal(""0"")  ||  strategy_pnl[trade.strategy_type] += trade.pnl_usd  ||  self, trades: List[TradeResult], period: PerformancePeriod  ||  if not trades:  ||  total_pnl_pct = sum((t.pnl_percentage for t in trades), Decimal(""0""))  ||  async def _calculate_volume_metrics(self, trades: List[TradeResult]) -> Dict[str, Decimal]:  ||  if not trades:  ||  ""largest_trade"": Decimal(""0"")  ||  trade_sizes = [t.amount * t.entry_price for t in trades]  ||  total_volume = sum(trade_sizes, Decimal(""0""))  ||  average_size = total_volume / Decimal(len(trades)) if trades else Decimal(""0"")  ||  largest_trade = max(trade_sizes, default=Decimal(""0""))  ||  ""largest_trade"": largest_trade  ||  async def _calculate_efficiency_metrics(self, trades: List[TradeResult]) -> Dict[str, float]:  ||  if not trades:  ||  return {""trades_per_day"": 0.0, ""avg_holding_time"": 0.0}  ||  if len(trades) > 1:  ||  sorted_trades = sorted(trades, key=lambda t: t.timestamp)  ||  time_span = (sorted_trades[-1].timestamp - sorted_trades[0].timestamp).total_seconds()  ||  trades_per_day = len(trades) / days  ||  trades_per_day = 1.0  ||  ""trades_per_day"": trades_per_day,  ||  async def _calculate_cost_metrics(self, trades: List[TradeResult]) -> Dict[str, Decimal]:  ||  if not trades:  ||  total_fees = sum((t.gas_cost_usd for t in trades), Decimal(""0""))  ||  total_volume = sum((t.amount * t.entry_price for t in trades), Decimal(""0""))  ||  ""failed_trades_today"": f""{severity}: {int(current_value)} failed trades today (threshold: {int(threshold_value)})"",  ||  ""daily_risk_score"": f""{severity}: Risk score at {current_value:.1f} (threshold: {threshold_value:.1f})"","
"D:\dex\backend\app\analytics\performance.py","19485","from __future__ import annotations | import logging | from datetime import datetime, timedelta | from decimal import Decimal | from typing import Dict, List, Optional, Union | from dataclasses import dataclass | from enum import Enum | from pydantic import BaseModel, Field","TOTAL_TRADES = ""total_trades""  ||  WINNING_TRADES = ""winning_trades""  ||  LOSING_TRADES = ""losing_trades""  ||  class TradeResult:  ||  """"""Individual trade result for performance calculation.""""""  ||  trade_id: str  ||  gas_cost_usd: Decimal  ||  total_trades: int = Field(..., description=""Total number of trades"")  ||  winning_trades: int = Field(..., description=""Number of winning trades"")  ||  losing_trades: int = Field(..., description=""Number of losing trades"")  ||  # Risk metrics  ||  sharpe_ratio: Optional[Decimal] = Field(None, description=""Risk-adjusted return ratio"")  ||  # Trade analysis  ||  average_win_usd: Decimal = Field(..., description=""Average winning trade USD"")  ||  average_loss_usd: Decimal = Field(..., description=""Average losing trade USD"")  ||  average_win_percentage: Decimal = Field(..., description=""Average winning trade %"")  ||  average_loss_percentage: Decimal = Field(..., description=""Average losing trade %"")  ||  largest_win_usd: Decimal = Field(..., description=""Largest winning trade USD"")  ||  largest_loss_usd: Decimal = Field(..., description=""Largest losing trade USD"")  ||  total_gas_cost_usd: Decimal = Field(..., description=""Total gas costs"")  ||  trades: List[TradeResult],  ||  trades: List of trade results to analyze  ||  f""Calculating performance for {len(trades)} trades"",  ||  # Filter trades by date range  ||  filtered_trades = self._filter_trades_by_date(trades, period_start, period_end)  ||  if not filtered_trades:  ||  basic_metrics = self._calculate_basic_metrics(filtered_trades)  ||  pnl_metrics = self._calculate_pnl_metrics(filtered_trades)  ||  # Calculate risk metrics  ||  risk_metrics = self._calculate_risk_metrics(filtered_trades)  ||  execution_metrics = self._calculate_execution_metrics(filtered_trades)  ||  strategy_breakdown = self._calculate_strategy_breakdown(filtered_trades)  ||  preset_breakdown = self._calculate_preset_breakdown(filtered_trades)  ||  chain_breakdown = self._calculate_chain_breakdown(filtered_trades)  ||  **risk_metrics,  ||  ""total_trades"": metrics.total_trades,  ||  ""trades_count"": len(trades),  ||  def _filter_trades_by_date(  ||  trades: List[TradeResult],  ||  ) -> List[TradeResult]:  ||  """"""Filter trades by date range.""""""  ||  trade for trade in trades  ||  if start_date <= trade.timestamp <= end_date  ||  def _calculate_basic_metrics(self, trades: List[TradeResult]) -> Dict[str, Union[int, float]]:  ||  """"""Calculate basic trade metrics.""""""  ||  winning_trades = [t for t in trades if t.pnl_usd > 0]  ||  losing_trades = [t for t in trades if t.pnl_usd < 0]  ||  ""total_trades"": len(trades),  ||  ""winning_trades"": len(winning_trades),  ||  ""losing_trades"": len(losing_trades),  ||  ""win_rate"": (len(winning_trades) / len(trades)) * 100 if trades else 0.0  ||  def _calculate_pnl_metrics(self, trades: List[TradeResult]) -> Dict[str, Decimal]:  ||  total_pnl_usd = sum((t.pnl_usd for t in trades), Decimal(""0""))  ||  total_pnl_percentage = sum((t.pnl_percentage for t in trades), Decimal(""0""))  ||  winning_trades = [t for t in trades if t.pnl_usd > 0]  ||  losing_trades = [t for t in trades if t.pnl_usd < 0]  ||  gross_profit = sum((t.pnl_usd for t in winning_trades), Decimal(""0""))  ||  gross_loss = abs(sum((t.pnl_usd for t in losing_trades), Decimal(""0"")))  ||  avg_win_usd = gross_profit / Decimal(len(winning_trades)) if winning_trades else Decimal(""0"")  ||  avg_loss_usd = gross_loss / Decimal(len(losing_trades)) if losing_trades else Decimal(""0"")  ||  sum((t.pnl_percentage for t in winning_trades), Decimal(""0"")) / Decimal(len(winning_trades))  ||  if winning_trades else Decimal(""0"")  ||  abs(sum((t.pnl_percentage for t in losing_trades), Decimal(""0""))) / Decimal(len(losing_trades))  ||  if losing_trades else Decimal(""0"")  ||  largest_win = max(winning_trades, key=lambda t: t.pnl_usd).pnl_usd if winning_trades else Decimal(""0"")  ||  largest_loss = abs(min(losing_trades, key=lambda t: t.pnl_usd).pnl_usd) if losing_trades else Decimal(""0"")  ||  def _calculate_risk_metrics(self, trades: List[TradeResult]) -> Dict[str, Union[Decimal, None]]:  ||  """"""Calculate risk-adjusted metrics.""""""  ||  if not trades:  ||  for trade in sorted(trades, key=lambda t: t.timestamp):  ||  running_pnl += trade.pnl_usd  ||  gross_profit = sum(t.pnl_usd for t in trades if t.pnl_usd > 0)  ||  gross_loss = abs(sum(t.pnl_usd for t in trades if t.pnl_usd < 0))  ||  returns = [float(t.pnl_percentage) for t in trades]  ||  def _calculate_execution_metrics(self, trades: List[TradeResult]) -> Dict[str, Union[float, Decimal]]:  ||  if not trades:  ||  ""total_gas_cost_usd"": Decimal(""0"")  ||  avg_execution_time = sum(t.execution_time_ms for t in trades) / len(trades)  ||  successful_trades = sum(1 for t in trades if t.is_successful)  ||  success_rate = (successful_trades / len(trades)) * 100  ||  total_gas_cost = sum(t.gas_cost_usd for t in trades)  ||  ""total_gas_cost_usd"": total_gas_cost  ||  self, trades: List[TradeResult]  ||  for strategy_type in set(t.strategy_type for t in trades):  ||  strategy_trades = [t for t in trades if t.strategy_type == strategy_type]  ||  basic = self._calculate_basic_metrics(strategy_trades)  ||  pnl = self._calculate_pnl_metrics(strategy_trades)  ||  ""total_trades"": basic[""total_trades""],  ||  self, trades: List[TradeResult]  ||  for preset_id in set(t.preset_id for t in trades if t.preset_id):  ||  preset_trades = [t for t in trades if t.preset_id == preset_id]  ||  basic = self._calculate_basic_metrics(preset_trades)  ||  pnl = self._calculate_pnl_metrics(preset_trades)  ||  ""total_trades"": basic[""total_trades""],  ||  self, trades: List[TradeResult]  ||  for chain in set(t.chain for t in trades):  ||  chain_trades = [t for t in trades if t.chain == chain]  ||  basic = self._calculate_basic_metrics(chain_trades)  ||  pnl = self._calculate_pnl_metrics(chain_trades)  ||  execution = self._calculate_execution_metrics(chain_trades)  ||  ""total_trades"": basic[""total_trades""],  ||  ""total_gas_cost_usd"": float(execution[""total_gas_cost_usd""]),  ||  """"""Return empty metrics for periods with no trades.""""""  ||  total_trades=0,  ||  winning_trades=0,  ||  losing_trades=0,  ||  total_gas_cost_usd=Decimal(""0"")"
"D:\dex\backend\app\api\v1\router.py","870","from __future__ import annotations | from fastapi import APIRouter | from app.api.v1 import ( | from app.api import wallet_funding  # Import wallet_funding from app.api","autotrade,  ||  quotes,  ||  trades,  ||  wallets,  ||  from app.api import wallet_funding  # Import wallet_funding from app.api  ||  router.include_router(wallets.router)  ||  router.include_router(quotes.router)  ||  router.include_router(trades.router)  ||  router.include_router(autotrade.router)  ||  router.include_router(wallet_funding.router)  # Add wallet_funding router"
"D:\dex\backend\app\api\v1\wallet_funding.py","17779","from __future__ import annotations | import logging | from datetime import datetime, timezone, timedelta | from decimal import Decimal | from typing import Dict, List, Optional, Any | import uuid | from fastapi import APIRouter, HTTPException, Header, status | from pydantic import BaseModel, Field, validator","DEX Sniper Pro - Wallet Funding API Endpoints.  ||  Secure wallet approval and spending limit management for autotrade operations.  ||  File: backend/app/api/wallet_funding.py  ||  router = APIRouter(prefix=""/wallet-funding"", tags=[""Wallet Funding""])  ||  class WalletApprovalRequest(BaseModel):  ||  """"""Request to approve wallet for autotrade operations.""""""  ||  wallet_address: str = Field(..., description=""Wallet address to approve"")  ||  per_trade_limit_usd: Decimal = Field(..., description=""Maximum per-trade limit in USD"")  ||  approval_duration_hours: int = Field(default=24, description=""Approval duration in hours"")  ||  @validator('wallet_address')  ||  def validate_wallet_address(cls, v):  ||  """"""Validate wallet address format.""""""  ||  raise ValueError('Invalid wallet address')  ||  @validator('daily_limit_usd', 'per_trade_limit_usd')  ||  @validator('approval_duration_hours')  ||  """"""Validate approval duration.""""""  ||  raise ValueError('Approval duration must be between 1 and 168 hours')  ||  class ApprovalConfirmationRequest(BaseModel):  ||  """"""Request to confirm or reject wallet approval.""""""  ||  confirmed: bool = Field(..., description=""Whether user confirms the approval"")  ||  class WalletApprovalResponse(BaseModel):  ||  """"""Response for wallet approval request.""""""  ||  approval_id: str  ||  wallet_address: str  ||  per_trade_limit_usd: str  ||  approval_duration_hours: int  ||  class WalletStatusResponse(BaseModel):  ||  """"""Response showing user's wallet funding status.""""""  ||  wallet_funded: bool  ||  approvals: Dict[str, Dict[str, Any]]  ||  approval_count: int  ||  needs_approvals: bool  ||  per_trade_limit: Optional[str] = None  ||  APPROVED_WALLETS: Dict[str, Dict[str, Any]] = {}  ||  PENDING_APPROVALS: Dict[str, Dict[str, Any]] = {}  ||  @router.get(""/wallet-status"", response_model=WalletStatusResponse)  ||  async def get_wallet_status(  ||  Simple wallet funding status endpoint for frontend compatibility.  ||  logger.info(f""Wallet status requested with trace_id: {x_trace_id}"")  ||  # Return mock data that matches what WalletApproval.jsx expects  ||  return WalletStatusResponse(  ||  wallet_funded=True,  ||  approvals={  ||  approval_count=2,  ||  needs_approvals=True,  ||  logger.error(f""Simple wallet status failed: {e}"")  ||  detail=""Failed to get wallet status""  ||  @router.post(""/approve-wallet"", response_model=WalletApprovalResponse)  ||  async def request_wallet_approval(  ||  request: WalletApprovalRequest,  ||  ) -> WalletApprovalResponse:  ||  Request approval for a wallet to be used in autotrade operations.  ||  Creates a pending approval for demo purposes.  ||  f""Wallet approval requested"",  ||  'wallet_address': request.wallet_address,  ||  # Generate simple approval ID  ||  approval_id = str(uuid.uuid4())[:8]  ||  # Store in pending approvals with all necessary data  ||  PENDING_APPROVALS[approval_id] = {  ||  'wallet_address': request.wallet_address,  ||  'per_trade_limit_usd': float(request.per_trade_limit_usd),  ||  'approval_duration_hours': request.approval_duration_hours,  ||  return WalletApprovalResponse(  ||  approval_id=approval_id,  ||  wallet_address=request.wallet_address,  ||  per_trade_limit_usd=str(request.per_trade_limit_usd),  ||  approval_duration_hours=request.approval_duration_hours,  ||  logger.error(f""Failed to create wallet approval request: {e}"")  ||  detail=f""Failed to create approval request: {str(e)}""  ||  @router.post(""/confirm-approval/{approval_id}"")  ||  async def confirm_wallet_approval(  ||  approval_id: str,  ||  request: ApprovalConfirmationRequest,  ||  Confirm or reject a pending wallet approval.  ||  Returns complete approval details including spending limits.  ||  f""Wallet approval confirmation"",  ||  'approval_id': approval_id,  ||  if approval_id not in PENDING_APPROVALS:  ||  detail=""Approval request not found or expired""  ||  approval = PENDING_APPROVALS[approval_id]  ||  if approval['status'] != 'pending':  ||  detail=""Approval already processed""  ||  # Update approval status  ||  approval['status'] = status_message  ||  approval['confirmed_at'] = datetime.now(timezone.utc)  ||  ""daily_limit_usd"": approval['daily_limit_usd'],  ||  ""per_trade_limit_usd"": approval['per_trade_limit_usd'],  ||  ""approval_expires_at"": (  ||  timedelta(hours=approval['approval_duration_hours'])  ||  # Store approved wallet with spending limits  ||  chain = approval['chain']  ||  if chain not in APPROVED_WALLETS:  ||  APPROVED_WALLETS[chain] = {}  ||  APPROVED_WALLETS[chain][approval['wallet_address']] = {  ||  **approval,  ||  f""Wallet approved with spending limits"",  ||  'approval_id': approval_id,  ||  'wallet_address': approval['wallet_address'],  ||  'per_trade_limit': spending_limits['per_trade_limit_usd']  ||  # Return complete approval response with spending limits  ||  ""approval_id"": approval_id,  ||  ""confirmed_at"": approval['confirmed_at'].isoformat(),  ||  ""message"": f""Wallet approval {status_message} successfully"",  ||  ""wallet_address"": approval['wallet_address'],  ||  ""chain"": approval['chain'],  ||  ""approval_duration_hours"": approval['approval_duration_hours']  ||  logger.error(f""Failed to confirm wallet approval: {e}"")  ||  detail=f""Failed to confirm approval: {str(e)}""  ||  trade_amount_usd: Decimal,  ||  Check if a proposed trade amount is within approved spending limits.  ||  Validates against both per-trade and daily limits.  ||  'trade_amount': str(trade_amount_usd)  ||  # Check if chain has approved wallets  ||  if chain.lower() not in APPROVED_WALLETS or not APPROVED_WALLETS[chain.lower()]:  ||  reason=""No approved wallet for this chain"",  ||  details=""Please approve a wallet for autotrade operations first""  ||  # Get first approved wallet for the chain  ||  wallet_data = list(APPROVED_WALLETS[chain.lower()].values())[0]  ||  spending_limits = wallet_data.get('spending_limits', {})  ||  per_trade_limit = Decimal(str(spending_limits.get('per_trade_limit_usd', 1000)))  ||  # Check per-trade limit  ||  if trade_amount_usd > per_trade_limit:  ||  reason=""Exceeds per-trade limit"",  ||  details=f""Trade amount ${trade_amount_usd} exceeds limit of ${per_trade_limit}"",  ||  per_trade_limit=str(per_trade_limit),  ||  if daily_spent + trade_amount_usd > daily_limit:  ||  details=f""Trade would exceed daily limit of ${daily_limit}"",  ||  per_trade_limit=str(per_trade_limit),  ||  # Trade is within limits  ||  per_trade_limit=str(per_trade_limit),  ||  @router.delete(""/revoke-approval/{chain}"")  ||  async def revoke_wallet_approval(  ||  Revoke wallet approval for a specific chain.  ||  Removes all approved wallets for the specified chain.  ||  if chain.lower() in APPROVED_WALLETS:  ||  del APPROVED_WALLETS[chain.lower()]  ||  f""Wallet approval revoked"",  ||  ""message"": f""Wallet approval revoked for {chain}""  ||  detail=f""No approved wallet found for chain {chain}""  ||  logger.error(f""Failed to revoke wallet approval: {e}"")  ||  detail=f""Failed to revoke approval: {str(e)}""  ||  @router.get(""/approved-wallet/{chain}"")  ||  async def get_approved_wallet(  ||  Get the approved wallet address and spending limits for a specific chain.  ||  Returns the first approved wallet if multiple exist.  ||  if chain.lower() in APPROVED_WALLETS and APPROVED_WALLETS[chain.lower()]:  ||  # Return first approved wallet for the chain  ||  wallet_address = list(APPROVED_WALLETS[chain.lower()].keys())[0]  ||  wallet_data = APPROVED_WALLETS[chain.lower()][wallet_address]  ||  ""wallet_address"": wallet_address,  ||  ""spending_limits"": wallet_data.get('spending_limits'),  ||  ""approved_at"": wallet_data.get('confirmed_at', datetime.now(timezone.utc)).isoformat()  ||  detail=f""No approved wallet found for chain {chain}""  ||  logger.error(f""Failed to get approved wallet: {e}"")  ||  detail=f""Failed to get approved wallet: {str(e)}""  ||  ""Wallet funding API router initialized - %d endpoints registered"","
"D:\dex\backend\app\api\v1\__init__.py","0","",""
"D:\dex\backend\app\api\advanced_orders.py","26524","from __future__ import annotations | import logging | from datetime import datetime | from decimal import Decimal | from typing import Dict, List, Optional | from fastapi import APIRouter, Depends, HTTPException, Query, status | from pydantic import BaseModel, Field | from backend.app.autotrade.position_manager import AdvancedPositionManager, Position | from backend.app.strategy.orders.base import OrderStatus, OrderType |         from backend.app.strategy.orders.base import OrderSide |         from backend.app.strategy.orders.stop_orders import StopLossOrder |         from backend.app.strategy.orders.base import OrderSide |         from backend.app.strategy.orders.stop_orders import TakeProfitOrder |         from backend.app.strategy.orders.advanced_orders import TrailingStopOrder |         from backend.app.strategy.orders.base import OrderSide","from backend.app.autotrade.position_manager import AdvancedPositionManager, Position  ||  risk_profile: str = Field(default=""standard"", description=""Risk profile to use"")  ||  risk_profile: str = Field(default=""standard"", description=""Risk profile"")  ||  risk_profile_id=request.risk_profile  ||  risk_profile_id=request.risk_profile  ||  {""type"": ""market"", ""name"": ""Market Order"", ""description"": ""Execute immediately at market price""},  ||  {""type"": ""limit"", ""name"": ""Limit Order"", ""description"": ""Execute at specific price or better""},"
"D:\dex\backend\app\api\ai.py","50762","from __future__ import annotations | import logging | from datetime import datetime, timedelta | from decimal import Decimal | from typing import Any, Dict, List, Optional | from fastapi import APIRouter, HTTPException, Query, status | from pydantic import BaseModel, Field | from ..ai.tuner import ( | from ..ai.risk_explainer import ( | from ..ai.anomaly_detector import ( | from ..ai.decision_journal import (","auto-tuning, risk explanation, anomaly detection, and decision journaling.  ||  from ..ai.risk_explainer import (  ||  get_risk_explainer, explain_trade_risk, ExplanationStyle  ||  risk_budget: str = Field(""0.02"", description=""Maximum risk per trade during optimization"")  ||  risk_score: str = Field(..., description=""Risk score from testing"")  ||  simulation_trades: int = Field(..., description=""Number of trades simulated"")  ||  # Risk Explanation Models  ||  class RiskExplanationRequest(BaseModel):  ||  """"""Request for risk explanation.""""""  ||  risk_assessment: Dict[str, Any] = Field(..., description=""Risk assessment data"")  ||  trade_context: Dict[str, Any] = Field(..., description=""Trade context information"")  ||  risk_realized: str = Field(..., description=""Risk that was realized"")  ||  risk_expected: str = Field(..., description=""Risk that was expected"")  ||  risk_budget=Decimal(request.risk_budget)  ||  ""risk_budget"": request.risk_budget,  ||  risk_score=Decimal(request.risk_score),  ||  simulation_trades=request.simulation_trades,  ||  # Risk Explanation Endpoints  ||  @router.post(""/risk/explain"", summary=""Generate Risk Explanation"")  ||  async def explain_risk(request: RiskExplanationRequest) -> Dict[str, Any]:  ||  """"""Generate comprehensive risk explanation with natural language output.  ||  request: Risk explanation request  ||  Detailed risk explanation with recommendations  ||  explanation = await explain_trade_risk(  ||  risk_assessment=request.risk_assessment,  ||  trade_context=request.trade_context,  ||  ""overall_risk"": explanation.overall_risk.value,  ||  ""risk_score"": float(explanation.risk_score),  ||  ""risk_factors"": [  ||  for factor in explanation.risk_factors  ||  logger.error(f""Error generating risk explanation: {e}"")  ||  detail=f""Failed to generate risk explanation: {str(e)}""  ||  risk_assessment=request.context.get(""risk_assessment"", {}),  ||  risk_realized=Decimal(request.risk_realized),  ||  risk_expected=Decimal(request.risk_expected),  ||  ""risk_realized"": str(decision.outcome_data.risk_realized),  ||  ""risk_expected"": str(decision.outcome_data.risk_expected),"
"D:\dex\backend\app\api\ai_demo.py","44841","from __future__ import annotations | import asyncio | import json | import logging | import uuid | from datetime import datetime, timedelta | from decimal import Decimal | from typing import Any, Dict, List, Optional | from fastapi import APIRouter, Depends, HTTPException, status | from pydantic import BaseModel, Field | from ..core.ai_dependencies import ( | from ..ai.tuner import TuningMode, ParameterBounds, OptimizationResult | from ..ai.risk_explainer import ExplanationStyle | from ..ai.anomaly_detector import AnomalyType, AnomalySeverity | from ..ai.decision_journal import DecisionType, DecisionOutcome, DecisionContext, DecisionOutcomeData |             import random |             import random","from ..ai.risk_explainer import ExplanationStyle  ||  trade_size_usd: str = Field(""1000"", description=""Demo trade size"")  ||  risk_tolerance: str = Field(""moderate"", description=""Risk tolerance level"")  ||  explanation_style: str = Field(""intermediate"", description=""Risk explanation style"")  ||  ""/ai/demo/risk-explanation"",  ||  risk_budget=Decimal(""0.01"")  ||  simulated_risk = Decimal(str(random.uniform(0.2, 0.8)))  ||  risk_score=simulated_risk,  ||  simulation_trades=100,  ||  ""risk_score"": str(result.risk_score),  ||  @router.post(""/risk-explanation"", summary=""Risk Explanation Demo"")  ||  async def demo_risk_explanation(  ||  """"""Demonstrate risk explanation functionality with realistic risk assessment.""""""  ||  context = await create_ai_context(f""demo_risk_explanation_{uuid.uuid4().hex[:8]}"")  ||  context.add_operation(""risk_explanation_demo_start"", {""scenario"": request.scenario_type})  ||  # Generate realistic demo risk assessment data  ||  if request.scenario_type == ""low_risk"":  ||  risk_assessment = {  ||  elif request.scenario_type == ""high_risk"":  ||  risk_assessment = {  ||  else:  # moderate_risk  ||  risk_assessment = {  ||  # Trade context  ||  trade_context = {  ||  ""trade_size_usd"": ""1000"",  ||  context.add_operation(""risk_data_generated"", {""scenario"": request.scenario_type})  ||  ai_services.risk_explainer.explanation_style = style_enum  ||  explanation = ai_services.risk_explainer.generate_comprehensive_explanation(  ||  risk_assessment, trade_context  ||  ""overall_risk"": explanation.overall_risk.value,  ||  ""risk_score"": float(explanation.risk_score),  ||  ""risk_factors"": [  ||  for factor in explanation.risk_factors  ||  context.add_operation(""explanation_generated"", {""style"": style_name, ""risk_score"": float(explanation.risk_score)})  ||  await record_ai_operation(""risk_explanation_demo"", ""risk_explainer"", duration, True)  ||  ai_services.metrics.increment_operation(""risk_explanations"")  ||  ""demo_type"": ""risk_explanation"",  ||  ""risk_assessment_input"": {k: str(v) if isinstance(v, Decimal) else v for k, v in risk_assessment.items()},  ||  ""trade_context"": trade_context,  ||  await record_ai_operation(""risk_explanation_demo"", ""risk_explainer"", duration, False)  ||  ai_services.metrics.increment_error(""risk_explainer"")  ||  logger.error(f""Error in risk explanation demo: {e}"")  ||  detail=f""Risk explanation demo failed: {str(e)}""  ||  decision_id = f""demo_trade_{uuid.uuid4().hex[:8]}""  ||  if request.scenario_type == ""successful_trade"":  ||  risk_assessment={""overall_risk_score"": 0.3, ""liquidity_score"": 0.8},  ||  expected_outcome = {""expected_pnl"": ""150"", ""expected_risk"": ""0.02"", ""time_horizon"": ""12h""}  ||  elif request.scenario_type == ""failed_trade"":  ||  risk_assessment={""overall_risk_score"": 0.7, ""liquidity_score"": 0.4},  ||  expected_outcome = {""expected_pnl"": ""100"", ""expected_risk"": ""0.05"", ""time_horizon"": ""6h""}  ||  risk_assessment={""overall_risk_score"": 0.5, ""liquidity_score"": 0.6},  ||  expected_outcome = {""expected_pnl"": ""75"", ""expected_risk"": ""0.03"", ""time_horizon"": ""24h""}  ||  decision_type=DecisionType.TRADE_ENTRY,  ||  ""gas_price_multiplier"": ""1.2""  ||  if request.scenario_type == ""successful_trade"":  ||  risk_realized=Decimal(""0.015""),  ||  risk_expected=Decimal(""0.02""),  ||  elif request.scenario_type == ""failed_trade"":  ||  risk_realized=Decimal(""0.08""),  ||  risk_expected=Decimal(""0.05""),  ||  lessons_learned=[""Should have waited for better conditions"", ""Risk assessment was inadequate""]  ||  risk_realized=Decimal(""0.03""),  ||  risk_expected=Decimal(""0.03""),  ||  # Phase 1: Risk Analysis  ||  context.add_operation(""phase_1_risk_analysis"", {})  ||  # Generate risk assessment based on risk tolerance  ||  if request.risk_tolerance == ""low"":  ||  risk_data = {  ||  elif request.risk_tolerance == ""high"":  ||  risk_data = {  ||  risk_data = {  ||  # Get risk explanation  ||  ai_services.risk_explainer.explanation_style = ExplanationStyle(request.explanation_style)  ||  risk_explanation = ai_services.risk_explainer.generate_comprehensive_explanation(  ||  risk_data,  ||  {""trade_size_usd"": request.trade_size_usd, ""strategy_name"": request.strategy_name}  ||  demo_results[""risk_analysis""] = {  ||  ""overall_risk"": risk_explanation.overall_risk.value,  ||  ""risk_score"": float(risk_explanation.risk_score),  ||  ""summary"": risk_explanation.summary,  ||  ""recommendations"": risk_explanation.recommendations[:3],  ||  ""confidence"": risk_explanation.confidence  ||  risk_budget=Decimal(""0.015"")  ||  # Simulate result based on risk level  ||  if risk_explanation.overall_risk.value in [""safe"", ""low""]:  ||  elif risk_explanation.overall_risk.value in [""high"", ""critical""]:  ||  risk_score=risk_explanation.risk_score,  ||  simulation_trades=50,  ||  ""market_stress"": market_stress[""risk_level""],  ||  risk_assessment={  ||  ""overall_risk_score"": float(risk_explanation.risk_score),  ||  confidence_level=risk_explanation.confidence,  ||  decision_type=DecisionType.TRADE_ENTRY,  ||  rationale=""Entry based on AI risk analysis, optimized parameters, and monitoring signals"",  ||  expected_outcome={""expected_pnl"": ""120"", ""expected_risk"": ""0.025""}  ||  ""risk_informed"": True,  ||  ""/ai/demo/risk-explanation"",  ||  ""risk_budget"": ""0.02""  ||  ""Find optimal position sizing for risk-adjusted returns"",  ||  ""Tune gas price multipliers for execution speed vs cost""  ||  ""risk_explanation"": {  ||  ""description"": ""Get natural language explanations of trading risks"",  ||  ""endpoint"": ""POST /api/v1/ai/risk/explain"",  ||  ""risk_assessment"": {""liquidity_usd"": 50000, ""honeypot_confidence"": 0.1},  ||  ""trade_context"": {""trade_size_usd"": ""1000"", ""strategy_name"": ""new_pair_sniper""},  ||  ""Help users understand why trades are risky"",  ||  ""decision_id"": ""trade_001"",  ||  ""decision_type"": ""trade_entry"",  ||  ""Learn from successful and failed trades"",  ||  ""sequential"": ""Use AI systems one after another (risk → optimization → monitoring → decision)"","
"D:\dex\backend\app\api\ai_intelligence.py","13418","from __future__ import annotations | import logging | from typing import Dict, Any, Optional | from datetime import datetime | from decimal import Decimal | from fastapi import APIRouter, HTTPException, Query, Depends | from pydantic import BaseModel, Field | from app.core.logging import get_logger | from app.strategy.risk_scoring import RiskScorer, RiskFactors | from app.ai.market_intelligence import get_market_intelligence_engine","Provides market intelligence and risk scoring through FastAPI endpoints.  ||  from app.strategy.risk_scoring import RiskScorer, RiskFactors  ||  include_risk_score: bool = Field(True, description=""Include risk scoring"")  ||  # Risk scoring  ||  risk_score: Optional[Dict[str, Any]] = None  ||  risk_score_data = None  ||  # Perform risk scoring  ||  if request.include_risk_score:  ||  risk_factors = RiskFactors(  ||  scorer = RiskScorer(trace_id=f""api_{datetime.utcnow().isoformat()}"")  ||  risk_score = await scorer.calculate_risk_score(risk_factors)  ||  risk_score_data = {  ||  ""total_score"": risk_score.total_score,  ||  ""risk_level"": risk_score.risk_level,  ||  ""confidence"": risk_score.confidence,  ||  ""recommendation"": risk_score.recommendation,  ||  ""suggested_position_percent"": float(risk_score.suggested_position_percent),  ||  ""suggested_slippage"": float(risk_score.suggested_slippage),  ||  ""risk_reasons"": risk_score.risk_reasons,  ||  ""positive_signals"": risk_score.positive_signals,  ||  ""liquidity"": risk_score.liquidity_score,  ||  ""distribution"": risk_score.distribution_score,  ||  ""age"": risk_score.age_score,  ||  ""volume"": risk_score.volume_score,  ||  ""volatility"": risk_score.volatility_score,  ||  ""security"": risk_score.security_score  ||  logger.error(f""Risk scoring failed: {e}"", extra={""module"": ""ai_intelligence_api""})  ||  risk_score_data = {""error"": ""Risk scoring unavailable""}  ||  risk_score_data, market_intelligence_data  ||  key_insights = _extract_key_insights(risk_score_data, market_intelligence_data)  ||  action_items = _generate_action_items(risk_score_data, market_intelligence_data)  ||  risk_score=risk_score_data,  ||  ""risk_scoring"": ""active"",  ||  risk_score: Optional[Dict[str, Any]],  ||  if not risk_score and not market_intelligence:  ||  risk_rec = risk_score.get(""recommendation"", ""monitor"") if risk_score else ""monitor""  ||  risk_confidence = risk_score.get(""confidence"", 0.5) if risk_score else 0.5  ||  if risk_rec == ""avoid"" or market_health == ""critical"":  ||  recommendation = ""AVOID - High risk detected""  ||  elif risk_rec == ""trade"" and market_health in [""excellent"", ""good""]:  ||  confidence = (risk_confidence + intel_score) / 2  ||  elif risk_rec == ""consider"" and market_health == ""good"":  ||  confidence = (risk_confidence + intel_score) / 2 * 0.8  ||  risk_score: Optional[Dict[str, Any]],  ||  if risk_score:  ||  risk_level = risk_score.get(""risk_level"", ""unknown"")  ||  insights.append(f""Risk Level: {risk_level.upper()}"")  ||  if risk_score.get(""positive_signals""):  ||  insights.append(f""Positive: {risk_score['positive_signals'][0]}"")  ||  if risk_score.get(""risk_reasons""):  ||  insights.append(f""Concern: {risk_score['risk_reasons'][0]}"")  ||  risk_score: Optional[Dict[str, Any]],  ||  if risk_score:  ||  position_size = risk_score.get(""suggested_position_percent"", 0)  ||  slippage = risk_score.get(""suggested_slippage"", 1)"
"D:\dex\backend\app\api\analytics.py","41886","from __future__ import annotations | import logging | import random | from datetime import datetime, timedelta | from decimal import Decimal | from typing import Any, Dict, List, Optional, Tuple | from fastapi import APIRouter, Depends, HTTPException, Query | from pydantic import BaseModel, Field |     from app.core.dependencies import get_current_user, CurrentUser  # type: ignore |     from app.storage.repositories import TransactionRepository  # type: ignore","total_trades: int = Field(..., description=""Total number of trades"")  ||  last_trade_time: Optional[str] = Field(None, description=""Last trade timestamp"")  ||  average_trade_duration: str = Field(..., description=""Average trade duration (hours)"")  ||  risk_adjusted_return: str = Field(..., description=""Risk-adjusted return"")  ||  first_trade_at: datetime = Field(..., description=""First trade timestamp"")  ||  last_trade_at: datetime = Field(..., description=""Last trade timestamp"")  ||  trade_count: int = Field(..., description=""Number of trades"")  ||  total_trades: int = Field(..., description=""Total number of trades"")  ||  successful_trades: int = Field(..., description=""Number of profitable trades"")  ||  failed_trades: int = Field(..., description=""Number of losing trades"")  ||  average_win: Decimal = Field(..., description=""Average winning trade"")  ||  average_loss: Decimal = Field(..., description=""Average losing trade"")  ||  trades_count: int = Field(..., description=""Number of trades with this preset"")  ||  avg_trade_size: Decimal = Field(..., description=""Average trade size"")  ||  first_trade: Optional[datetime] = None  ||  last_trade: Optional[datetime] = None  ||  trade_count = len(transactions)  ||  if first_trade is None or ts < first_trade:  ||  first_trade = ts  ||  if last_trade is None or ts > last_trade:  ||  last_trade = ts  ||  first_trade = first_trade or datetime.utcnow()  ||  last_trade = last_trade or first_trade  ||  first_trade_at=first_trade,  ||  last_trade_at=last_trade,  ||  trade_count=trade_count,  ||  first_trade_at=first_trade,  ||  last_trade_at=last_trade,  ||  trade_count=trade_count,  ||  total_trades=0,  ||  successful_trades=0,  ||  failed_trades=0,  ||  pair_trades: Dict[str, List[Any]] = {}  ||  pair_trades.setdefault(addr, []).append(tx)  ||  successful_trades = 0  ||  failed_trades = 0  ||  for token_address, token_txs in pair_trades.items():  ||  successful_trades += 1  ||  failed_trades += 1  ||  total_trades = successful_trades + failed_trades  ||  (Decimal(successful_trades) / Decimal(total_trades) * 100)  ||  if total_trades > 0  ||  total_trades=total_trades,  ||  successful_trades=successful_trades,  ||  failed_trades=failed_trades,  ||  total_unrealized_pnl=Decimal(""0""),  # TODO: compute from live quotes  ||  total_trades=0,  ||  successful_trades=0,  ||  failed_trades=0,  ||  preset_trades: Dict[str, List[Any]] = {}  ||  preset_trades.setdefault(pname, []).append(tx)  ||  for pname, trades in preset_trades.items():  ||  if not trades:  ||  for t in trades  ||  for t in trades  ||  tokens = list({getattr(t, ""token_address"", ""unknown"") for t in trades})  ||  trades_count = len(tokens)  ||  for t in trades:  ||  avg_trade_size = (  ||  (Decimal(total_invested) / Decimal(len(trades)))  ||  if trades  ||  tok_trades = [t for t in trades if getattr(t, ""token_address"", """") == addr]  ||  if len(tok_trades) >= 2:  ||  first_ts = min(getattr(t, ""timestamp"", datetime.utcnow()) for t in tok_trades)  ||  last_ts = max(getattr(t, ""timestamp"", first_ts) for t in tok_trades)  ||  (getattr(t, ""timestamp"", datetime.utcnow()) for t in trades),  ||  trades_count=trades_count,  ||  avg_trade_size=avg_trade_size,  ||  total_trades=143,  ||  last_trade_time=(datetime.utcnow() - timedelta(minutes=8)).isoformat(),  ||  average_trade_duration=""14.5"",  ||  risk_adjusted_return=""18.4"",  ||  ""Recent trades experiencing higher than expected slippage on Ethereum""  ||  type=""risk"","
"D:\dex\backend\app\api\autotrade.py","46545","from __future__ import annotations | import logging | import uuid | import asyncio | import time | from datetime import datetime, timezone, timedelta | from typing import Dict, List, Optional, Any | from enum import Enum | from decimal import Decimal | from fastapi import APIRouter, HTTPException, Query, status | from pydantic import BaseModel, Field | from app.ws.intelligence_handler import manager as intelligence_manager | from app.strategy.risk_scoring import RiskScorer, RiskFactors | from app.core.bootstrap_autotrade import ( | from app.autotrade.integration import get_ai_pipeline, get_wallet_funding_manager","DEX Sniper Pro - Autotrade API Router.  ||  File: backend/app/api/autotrade.py  ||  # --- NEW: AI intelligence + risk scoring imports ---  ||  from app.strategy.risk_scoring import RiskScorer, RiskFactors  ||  from app.core.bootstrap_autotrade import (  ||  initialize_autotrade_system,  ||  shutdown_autotrade_system,  ||  get_autotrade_system_status,  ||  from app.autotrade.integration import get_ai_pipeline, get_wallet_funding_manager  ||  router = APIRouter(prefix=""/autotrade"", tags=[""autotrade""])  ||  class AutotradeMode(str, Enum):  ||  """"""Autotrade operation modes.""""""  ||  class AutotradeStartRequest(BaseModel):  ||  """"""Request to start autotrade engine.""""""  ||  mode: str = Field(default=""standard"", description=""Autotrade mode"")  ||  class AutotradeModeRequest(BaseModel):  ||  """"""Request to change autotrade mode.""""""  ||  mode: str = Field(..., description=""New autotrade mode"")  ||  class AutotradeStatusResponse(BaseModel):  ||  """"""Autotrade engine status response.""""""  ||  active_trades: int  ||  risk_stats: Dict[str, Any]  ||  ""active_trades"": [],  ||  ""total_trades"": 0,  ||  ""successful_trades"": 0,  ||  ""failed_trades"": 0,  ||  ""max_concurrent_trades"": 3,  ||  ""gas_multiplier"": 1.2,  ||  async def get_autotrade_engine():  ||  """"""Mock autotrade engine getter for development.""""""  ||  self.active_trades = _engine_state[""active_trades""]  ||  ""active_trades"": len(_engine_state[""active_trades""]),  ||  async def evaluate_trade_opportunity(opportunity: dict, wallet_address: str) -> bool:  ||  Evaluate a trade opportunity and stream AI thinking/decision to the frontend.  ||  This uses the Intelligence WebSocket manager to push interim ""thinking""  ||  updates and a final decision payload to the client identified by wallet_address.  ||  await intelligence_manager.send_to_wallet(wallet_address, {  ||  # Calculate risk score  ||  scorer = RiskScorer()  ||  risk_factors = RiskFactors(  ||  risk_score = await scorer.calculate_risk_score(risk_factors)  ||  # Send risk assessment  ||  await intelligence_manager.send_to_wallet(wallet_address, {  ||  ""message"": f""📊 Risk Score: {risk_score.total_score}/100 ({risk_score.risk_level})"",  ||  decision = ""approved"" if risk_score.total_score < 60 else ""blocked""  ||  await intelligence_manager.send_to_wallet(wallet_address, {  ||  ""risk_score"": risk_score.total_score,  ||  ""message"": f""{'✅ Approved' if decision == 'approved' else '❌ Blocked'}: {risk_score.recommendation}"",  ||  # NEW: System management & AI pipeline / wallet-funding endpoints (added)  ||  @router.post(""/system/initialize"", summary=""Initialize AI-Enhanced Autotrade System"")  ||  Initialize the complete AI-enhanced autotrade system including:  ||  - Autotrade engine with secure wallet funding  ||  - WebSocket streaming to dashboard  ||  trace_id = f""autotrade_init_{int(time.time())}""  ||  ""Initializing AI-enhanced autotrade system"",  ||  extra={""trace_id"": trace_id, ""module"": ""autotrade_api""},  ||  result = await initialize_autotrade_system()  ||  ""Autotrade system initialization completed successfully"",  ||  extra={""trace_id"": trace_id, ""module"": ""autotrade_api""},  ||  f""Autotrade system initialization failed: {result.get('message')}"",  ||  extra={""trace_id"": trace_id, ""module"": ""autotrade_api""},  ||  logger.error(f""Error initializing autotrade system: {e}"")  ||  detail=f""Failed to initialize autotrade system: {str(e)}"",  ||  @router.post(""/system/shutdown"", summary=""Shutdown Autotrade System"")  ||  """"""Gracefully shutdown the autotrade system.""""""  ||  trace_id = f""autotrade_shutdown_{int(time.time())}""  ||  ""Shutting down autotrade system"",  ||  extra={""trace_id"": trace_id, ""module"": ""autotrade_api""},  ||  result = await shutdown_autotrade_system()  ||  logger.error(f""Error shutting down autotrade system: {e}"")  ||  detail=f""Failed to shutdown autotrade system: {str(e)}"",  ||  """"""Get comprehensive status of the autotrade system including AI pipeline.""""""  ||  system_status = get_autotrade_system_status()  ||  @router.get(""/wallet-funding/status/{user_id}"", summary=""Get Wallet Funding Status"")  ||  async def get_wallet_funding_status(user_id: str) -> Dict[str, Any]:  ||  """"""Get wallet funding and approval status for a user.""""""  ||  wallet_manager = await get_wallet_funding_manager()  ||  status_info = wallet_manager.get_wallet_status(user_id)  ||  logger.error(f""Error getting wallet funding status for {user_id}: {e}"")  ||  detail=f""Failed to get wallet funding status: {str(e)}"",  ||  @router.post(""/wallet-funding/request-approval"", summary=""Request Wallet Approval"")  ||  async def request_wallet_approval(  ||  wallet_address: str = Query(..., description=""Wallet address to approve""),  ||  per_trade_limit_usd: float = Query(..., gt=0, description=""Per-trade limit in USD""),  ||  approval_duration_hours: int = Query(24, gt=0, le=168, description=""Approval duration in hours""),  ||  """"""Request approval for a wallet to be used in autotrade.""""""  ||  wallet_manager = await get_wallet_funding_manager()  ||  approval_id = await wallet_manager.request_wallet_approval(  ||  wallet_address=wallet_address,  ||  per_trade_limit_usd=Decimal(str(per_trade_limit_usd)),  ||  approval_duration_hours=approval_duration_hours,  ||  ""approval_id"": approval_id,  ||  ""message"": f""Wallet approval requested for {wallet_address} on {chain}"",  ||  ""next_steps"": ""User must confirm approval via /wallet-funding/confirm-approval endpoint"",  ||  logger.error(f""Error requesting wallet approval: {e}"")  ||  detail=f""Failed to request wallet approval: {str(e)}"",  ||  @router.post(""/wallet-funding/confirm-approval"", summary=""Confirm Wallet Approval"")  ||  async def confirm_wallet_approval(  ||  approval_id: str = Query(..., description=""Approval request ID""),  ||  """"""Confirm or reject a wallet approval request.""""""  ||  wallet_manager = await get_wallet_funding_manager()  ||  success = await wallet_manager.confirm_wallet_approval(approval_id, user_confirmation)  ||  ""message"": f""Wallet approval {action} successfully"",  ||  ""approval_id"": approval_id,  ||  ""message"": f""Approval request {approval_id} not found or expired"",  ||  logger.error(f""Error confirming wallet approval: {e}"")  ||  detail=f""Failed to confirm wallet approval: {str(e)}"",  ||  @router.get(""/status"", response_model=AutotradeStatusResponse)  ||  async def get_autotrade_status() -> AutotradeStatusResponse:  ||  Get current autotrade engine status.  ||  engine = await get_autotrade_engine()  ||  ""Autotrade status requested"",  ||  ""module"": ""autotrade_api"",  ||  return AutotradeStatusResponse(**status_data)  ||  ""Failed to get autotrade status: %s"",  ||  ""module"": ""autotrade_api"",  ||  detail={""error"": ""Failed to get autotrade status"", ""trace_id"": trace_id},  ||  async def start_autotrade(request: AutotradeStartRequest) -> Dict[str, str]:  ||  Start the autotrade engine with specified mode.  ||  engine = await get_autotrade_engine()  ||  ""Invalid autotrade mode requested: %s"",  ||  ""module"": ""autotrade_api"",  ||  ""Attempted to start autotrade engine while already running"",  ||  ""module"": ""autotrade_api"",  ||  detail=""Autotrade engine is already running"",  ||  ""Autotrade engine started in %s mode"",  ||  ""module"": ""autotrade_api"",  ||  ""message"": f""Autotrade engine started in {request.mode} mode"",  ||  ""Failed to start autotrade engine: %s"",  ||  ""module"": ""autotrade_api"",  ||  ""error"": ""Failed to start autotrade engine"",  ||  async def stop_autotrade() -> Dict[str, str]:  ||  Stop the autotrade engine.  ||  engine = await get_autotrade_engine()  ||  ""Attempted to stop autotrade engine that is not running"",  ||  ""module"": ""autotrade_api"",  ||  detail=""Autotrade engine is not running"",  ||  ""Autotrade engine stopped"",  ||  ""module"": ""autotrade_api"",  ||  return {""status"": ""success"", ""message"": ""Autotrade engine stopped"", ""trace_id"": trace_id}  # noqa: E501  ||  ""Failed to stop autotrade engine: %s"",  ||  ""module"": ""autotrade_api"",  ||  detail={""error"": ""Failed to stop autotrade engine"", ""trace_id"": trace_id},  ||  engine = await get_autotrade_engine()  ||  _engine_state[""active_trades""].clear()  ||  ""module"": ""autotrade_api"",  ||  ""message"": ""Emergency stop executed - all operations halted"",  ||  ""module"": ""autotrade_api"",  ||  async def change_mode(request: AutotradeModeRequest) -> Dict[str, str]:  ||  Change autotrade engine mode.  ||  engine = await get_autotrade_engine()  ||  ""module"": ""autotrade_api"",  ||  ""Autotrade engine stopped due to mode change to 'disabled'"",  ||  ""module"": ""autotrade_api"",  ||  ""Autotrade mode changed to %s"",  ||  ""module"": ""autotrade_api"",  ||  ""Failed to change autotrade mode: %s"",  ||  ""module"": ""autotrade_api"",  ||  ""module"": ""autotrade_api"",  ||  ""module"": ""autotrade_api"",  ||  ""module"": ""autotrade_api"",  ||  ""module"": ""autotrade_api"",  ||  Get current autotrade configuration.  ||  extra={""extra_data"": {""trace_id"": trace_id, ""module"": ""autotrade_api""}},  ||  ""module"": ""autotrade_api"",  ||  Get current autotrade settings (alias for config endpoint).  ||  ""module"": ""autotrade_api"",  ||  ""autotrade_enabled"": config.get(""enabled"", False),  ||  ""max_concurrent_trades"": config.get(""max_concurrent_trades"", 5),  ||  ""gas_multiplier"": config.get(""gas_multiplier"", 1.2),  ||  ""module"": ""autotrade_api"",  ||  Update autotrade settings.  ||  ""module"": ""autotrade_api"",  ||  ""module"": ""autotrade_api"",  ||  Validate autotrade configuration.  ||  if engine_config.get(""max_concurrent_trades"", 0) > 20:  ||  ""High concurrent trades limit may impact performance""  ||  ""risk_score"": 25.0 if len(errors) == 0 else 75.0,  ||  ""module"": ""autotrade_api"",  ||  ""module"": ""autotrade_api"",  ||  ""module"": ""autotrade_api"",  ||  ""module"": ""autotrade_api"",  ||  Get recent autotrade activities.  ||  ""description"": ""Autotrade engine started in standard mode"",  ||  ""module"": ""autotrade_api"",  ||  ""module"": ""autotrade_api"",  ||  Get autotrade performance metrics.  ||  ""avg_trade_time"": 0.0,  ||  risk_stats = {  ||  ""risk_score"": 25.0,  ||  ""module"": ""autotrade_api"",  ||  ""total_trades"": metrics.get(""total_trades"", 0),  ||  metrics=metrics, performance=performance, risk_stats=risk_stats  ||  ""module"": ""autotrade_api"",  ||  async def autotrade_health() -> Dict[str, Any]:  ||  Health check for autotrade system.  ||  engine = await get_autotrade_engine()  ||  ""Autotrade health check failed: %s"",  ||  ""module"": ""autotrade_api"",  ||  ""Autotrade API router initialized successfully"",  ||  ""module"": ""autotrade_api"","
"D:\dex\backend\app\api\autotrade_ai.py","2801","from fastapi import APIRouter, WebSocket | from app.strategy.risk_scoring import RiskScorer, RiskFactors | from app.ai.market_intelligence import get_market_intelligence_engine | from decimal import Decimal | import logging","AI integration for autotrade decisions.  ||  from fastapi import APIRouter, WebSocket  ||  from app.strategy.risk_scoring import RiskScorer, RiskFactors  ||  router = APIRouter(prefix=""/api/autotrade-ai"", tags=[""Autotrade AI""])  ||  @router.websocket(""/ws"")  ||  async def autotrade_ai_stream(websocket: WebSocket):  ||  """"""WebSocket endpoint for AI thinking during autotrade.""""""  ||  await websocket.accept()  ||  scorer = RiskScorer()  ||  # Receive trade opportunity from autotrade  ||  data = await websocket.receive_json()  ||  await websocket.send_json({  ||  ""message"": ""Analyzing token risk factors...""  ||  # Calculate risk score  ||  risk_factors = RiskFactors(  ||  risk_score = await scorer.calculate_risk_score(risk_factors)  ||  await websocket.send_json({  ||  ""message"": f""Risk score: {risk_score.total_score}/100 ({risk_score.risk_level})""  ||  await websocket.send_json({  ||  should_trade = risk_score.total_score < 60  ||  await websocket.send_json({  ||  ""approved"": should_trade,  ||  ""risk_score"": risk_score.total_score,  ||  ""risk_level"": risk_score.risk_level,  ||  ""reasons"": risk_score.risk_reasons[:3],  ||  ""recommendation"": risk_score.recommendation,  ||  ""message"": f""{'✅ Approved' if should_trade else '❌ Blocked'}: {risk_score.recommendation}""  ||  logger.error(f""AI WebSocket error: {e}"")"
"D:\dex\backend\app\api\basic_endpoints.py","7182","from __future__ import annotations | import logging | import uuid | from datetime import datetime | from typing import Dict, Any, List, Optional | from fastapi import APIRouter, HTTPException, Query | from ..ws.hub import ws_hub, WebSocketMessage, MessageType, Channel |         import random","These provide the core functionality while the WebSocket system is being updated.  ||  from ..ws.hub import ws_hub, WebSocketMessage, MessageType, Channel  ||  logger.warning(""WebSocket hub not available for system broadcast"")  ||  ws_message = WebSocketMessage(  ||  ""total_trades"": 143,  ||  ""active_trades"": random.randint(2, 8),  ||  ""last_trade"": {  ||  ""risk_score"": 20.0,  ||  ""risk_score"": 50.0,  ||  ""risk_score"": 80.0,  ||  ""description"": ""Execute immediately at current market price"",  ||  ""description"": ""Execute at specified price or better"","
"D:\dex\backend\app\api\copytrade.py","24998","from __future__ import annotations | import logging | from datetime import datetime, timedelta | from decimal import Decimal | from typing import Any, Dict, List, Optional | from fastapi import APIRouter, Depends, HTTPException, Query | from pydantic import BaseModel, Field |     from ..core.dependencies import get_current_user, CurrentUser |     from ..strategy.copytrade import (","- Trader discovery and performance metrics  ||  - Performance analytics for copy trades  ||  File: backend/app/api/copytrade.py  ||  from ..strategy.copytrade import (  ||  get_copy_trade_manager,  ||  CopyTradeConfig,  ||  TraderTier,  ||  TraderMetrics,  ||  CopyTradeSignal  ||  class TraderTier:  ||  class CopyTradeConfig(BaseModel):  ||  async def get_copy_trade_manager():  ||  router = APIRouter(prefix=""/copytrade"", tags=[""Copy Trading""])  ||  class CopyTradeConfigRequest(BaseModel):  ||  max_copy_amount_gbp: Decimal = Field(Decimal(""100""), gt=0, description=""Maximum amount per copy trade in GBP"")  ||  # Trader filtering  ||  min_trader_tier: str = Field(""experienced"", description=""Minimum trader tier to copy"")  ||  min_total_trades: int = Field(50, ge=1, description=""Minimum total trades"")  ||  max_risk_score: Decimal = Field(Decimal(""7""), ge=1, le=10, description=""Maximum risk score"")  ||  # Trade filtering  ||  min_trade_amount_usd: Decimal = Field(Decimal(""100""), gt=0, description=""Minimum trade amount in USD"")  ||  max_trade_amount_usd: Decimal = Field(Decimal(""10000""), gt=0, description=""Maximum trade amount in USD"")  ||  # Risk management  ||  class CopyTradeConfigResponse(BaseModel):  ||  min_trader_tier: str  ||  min_total_trades: int  ||  max_risk_score: Decimal  ||  min_trade_amount_usd: Decimal  ||  max_trade_amount_usd: Decimal  ||  class TraderMetricsResponse(BaseModel):  ||  """"""Response model for trader metrics.""""""  ||  trader_address: str  ||  total_trades: int  ||  winning_trades: int  ||  risk_score: Decimal  ||  """"""Response model for copy trade signals.""""""  ||  trader_address: str  ||  trade_type: str  ||  risk_score: Decimal  ||  """"""Response model for copy trade positions.""""""  ||  class CopyTradeStatsResponse(BaseModel):  ||  """"""Response model for copy trade statistics.""""""  ||  total_copy_trades: int  ||  best_performing_trader: Optional[str]  ||  @router.get(""/config"", response_model=CopyTradeConfigResponse)  ||  manager = await get_copy_trade_manager()  ||  return CopyTradeConfigResponse(  ||  min_trader_tier=""experienced"",  ||  min_total_trades=50,  ||  max_risk_score=Decimal(""7""),  ||  min_trade_amount_usd=Decimal(""100""),  ||  max_trade_amount_usd=Decimal(""10000""),  ||  return CopyTradeConfigResponse(  ||  min_trader_tier=""experienced"",  ||  min_total_trades=50,  ||  max_risk_score=Decimal(""7""),  ||  min_trade_amount_usd=Decimal(""100""),  ||  max_trade_amount_usd=Decimal(""10000""),  ||  return CopyTradeConfigResponse(  ||  min_trader_tier=config.min_trader_tier.value if hasattr(config.min_trader_tier, 'value') else str(config.min_trader_tier),  ||  min_total_trades=config.min_total_trades,  ||  max_risk_score=config.max_risk_score,  ||  min_trade_amount_usd=config.min_trade_amount_usd,  ||  max_trade_amount_usd=config.max_trade_amount_usd,  ||  logger.error(f""Error getting copy trade config: {e}"")  ||  raise HTTPException(status_code=500, detail=""Failed to get copy trade configuration"")  ||  @router.post(""/config"", response_model=CopyTradeConfigResponse)  ||  config_request: CopyTradeConfigRequest,  ||  manager = await get_copy_trade_manager()  ||  config = CopyTradeConfig(  ||  min_trader_tier=config_request.min_trader_tier,  ||  min_total_trades=config_request.min_total_trades,  ||  max_risk_score=config_request.max_risk_score,  ||  min_trade_amount_usd=config_request.min_trade_amount_usd,  ||  max_trade_amount_usd=config_request.max_trade_amount_usd,  ||  return CopyTradeConfigResponse(  ||  min_trader_tier=config.min_trader_tier,  ||  min_total_trades=config.min_total_trades,  ||  max_risk_score=config.max_risk_score,  ||  min_trade_amount_usd=config.min_trade_amount_usd,  ||  max_trade_amount_usd=config.max_trade_amount_usd,  ||  logger.error(f""Error updating copy trade config: {e}"")  ||  raise HTTPException(status_code=500, detail=""Failed to update copy trade configuration"")  ||  @router.get(""/traders"", response_model=List[TraderMetricsResponse])  ||  async def get_top_traders(  ||  limit: int = Query(20, ge=1, le=100, description=""Number of traders to return""),  ||  """"""Get top performing traders available for copying.""""""  ||  manager = await get_copy_trade_manager()  ||  # Return sample traders for demo  ||  TraderMetricsResponse(  ||  trader_address=""0x1234567890123456789012345678901234567890"",  ||  total_trades=150,  ||  winning_trades=120,  ||  risk_score=Decimal(""6.2""),  ||  TraderMetricsResponse(  ||  trader_address=""0x9876543210987654321098765432109876543210"",  ||  total_trades=89,  ||  winning_trades=65,  ||  risk_score=Decimal(""5.1""),  ||  traders = await manager.get_top_traders(limit)  ||  TraderMetricsResponse(  ||  trader_address=trader.trader_address,  ||  total_trades=trader.total_trades,  ||  winning_trades=trader.winning_trades,  ||  win_rate=trader.win_rate,  ||  total_pnl=trader.total_pnl,  ||  max_drawdown=trader.max_drawdown,  ||  sharpe_ratio=trader.sharpe_ratio,  ||  avg_hold_time_hours=trader.avg_hold_time_hours,  ||  tier=trader.tier.value if hasattr(trader.tier, 'value') else str(trader.tier),  ||  risk_score=trader.risk_score,  ||  last_updated=trader.last_updated  ||  for trader in traders  ||  logger.error(f""Error getting top traders: {e}"")  ||  raise HTTPException(status_code=500, detail=""Failed to get top traders"")  ||  trader_address: Optional[str] = Query(None, description=""Filter by trader address""),  ||  """"""Get recent copy trade signals.""""""  ||  manager = await get_copy_trade_manager()  ||  trader_address=""0x1234567890123456789012345678901234567890"",  ||  trade_type=""buy"",  ||  risk_score=Decimal(""6.2""),  ||  # Filter by trader if specified  ||  if trader_address:  ||  signals = [s for s in signals if s.trader_address == trader_address]  ||  trader_address=signal.trader_address,  ||  trade_type=signal.trade_type,  ||  risk_score=signal.risk_score,  ||  """"""Get active copy trade positions.""""""  ||  manager = await get_copy_trade_manager()  ||  @router.get(""/stats"", response_model=CopyTradeStatsResponse)  ||  manager = await get_copy_trade_manager()  ||  return CopyTradeStatsResponse(  ||  total_copy_trades=25,  ||  best_performing_trader=""0x1234567890123456789012345678901234567890"",  ||  total_copy_trades = 25  ||  win_rate = (Decimal(successful_copies) / Decimal(total_copy_trades)) * Decimal(""100"")  ||  return CopyTradeStatsResponse(  ||  total_copy_trades=total_copy_trades,  ||  best_performing_trader=""0x1234567890123456789012345678901234567890"",  ||  manager = await get_copy_trade_manager()  ||  raise HTTPException(status_code=500, detail=""Failed to execute emergency stop"")  ||  ""description"": ""Copy trades with a fixed amount per trade""  ||  ""description"": ""Scale trades based on portfolio size ratio""  ||  ""description"": ""Mirror exact percentage of trader's portfolio""  ||  ""description"": ""New traders with limited track record""  ||  ""description"": ""Proven traders with consistent performance""  ||  ""description"": ""High-performing traders with excellent metrics""  ||  ""description"": ""Elite traders with exceptional long-term performance"""
"D:\dex\backend\app\api\core_endpoints.py","14811","from __future__ import annotations | import asyncio | import logging | import time | from typing import Any, Dict, List, Optional | from fastapi import APIRouter, Request |             from ..api.intelligence import router as intelligence_router |             from ..core.config import settings |             from ..api.intelligence import router as intelligence_router |         from ..api.intelligence import router as intelligence_router","""websocket_test"": ""/ws/test"",  ||  ""wallet_management"": ""/api/v1/wallets/test"",  ||  ""quote_aggregation"": ""/api/v1/quotes/test"",  ||  ""trade_execution"": ""/api/v1/trades/test"",  ||  ""risk_assessment"": ""/api/v1/risk/test"",  ||  ""ledger_positions"": ""/api/v1/ledger/positions"",  ||  ""ledger_transactions"": ""/api/v1/ledger/transactions"",  ||  ""portfolio_summary"": ""/api/v1/ledger/portfolio-summary"",  ||  ""websocket_status"": ""/ws/status"",  ||  ""websocket_connection"": ""/ws/{client_id}"",  ||  ""websocket_intelligence"": ""/ws/intelligence/{user_id}""  ||  ""wallet_registry"": getattr(app.state, 'wallet_registry_status', 'unknown'),  ||  ""risk_manager"": getattr(app.state, 'risk_manager_status', 'unknown'),  ||  ""websocket_hub"": getattr(app.state, 'websocket_status', 'unknown'),  ||  websocket_routes_registered = any('/ws/' in str(route.path) for route in app.routes)  ||  ledger_routes_registered = any('/ledger/' in str(route.path) for route in app.routes)  ||  ""websocket_routes_registered"": websocket_routes_registered,  ||  ""ledger_routes_registered"": ledger_routes_registered,  ||  ""websocket_test_page"": ""/ws/test"",  ||  ""ledger_endpoints"": [  ||  ""/api/v1/ledger/positions"",  ||  ""/api/v1/ledger/transactions"",  ||  ""/api/v1/ledger/portfolio-summary""  ||  websocket_routes = []  ||  route_info[""type""] = ""websocket""  ||  websocket_routes.append(route_info)  ||  websocket_paths = [r for r in routes + websocket_routes if '/ws/' in r['path']]  ||  ledger_routes = [r for r in routes if 'ledger' in r['path']]  ||  ""websocket_routes"": len(websocket_routes),  ||  ""ledger_routes"": len(ledger_routes),  ||  ""websocket_endpoints"": websocket_paths,  ||  ""wallet_management"": ""/api/v1/wallets/"",  ||  ""quote_aggregation"": ""/api/v1/quotes/"",  ||  ""trade_execution"": ""/api/v1/trades/"",  ||  ""risk_assessment"": ""/api/v1/risk/"",  ||  ""ledger_positions"": ""/api/v1/ledger/positions"",  ||  ""ledger_transactions"": ""/api/v1/ledger/transactions"",  ||  ""portfolio_summary"": ""/api/v1/ledger/portfolio-summary"",  ||  ""websocket_main"": ""/ws/{client_id}"",  ||  ""websocket_intelligence"": ""/ws/intelligence/{user_id}"",  ||  ""websocket_status"": ""/ws/status"""
"D:\dex\backend\app\api\database.py","16165","from __future__ import annotations | from datetime import datetime | from decimal import Decimal | from typing import Annotated, Dict, List, Optional | from fastapi import APIRouter, Depends, HTTPException, status | from pydantic import BaseModel | from sqlalchemy import func, select | from ..core.settings import settings | from ..ledger.ledger_writer import ledger_writer | from ..storage.models import LedgerEntry, TokenMetadata, Transaction, User, Wallet | from ..storage.repositories import ( |     import uuid |         from ..storage.database import db_manager |         import logging |         from ..storage.database import get_session_context |         from sqlalchemy import text |         import logging |         from ..storage.database import db_manager |         from ..core.settings import settings","from ..ledger.ledger_writer import ledger_writer  ||  from ..storage.models import LedgerEntry, TokenMetadata, Transaction, User, Wallet  ||  LedgerRepository,  ||  WalletRepository,  ||  get_ledger_repository,  ||  get_wallet_repository,  ||  default_trade_amount_gbp: Optional[Decimal] = None  ||  risk_tolerance: Optional[str] = None  ||  class CreateWalletRequest(BaseModel):  ||  """"""Request model for creating a wallet.""""""  ||  wallet_type: str  ||  is_hot_wallet: bool = False  ||  class CreateTestTradeRequest(BaseModel):  ||  """"""Request model for creating a test trade.""""""  ||  wallet_address: str  ||  trade_type: str  # buy, sell  ||  default_trade_amount_gbp: Optional[Decimal]  ||  risk_tolerance: Optional[str]  ||  total_wallets: int  ||  total_ledger_entries: int  ||  WalletRepositoryDep = Annotated[WalletRepository, Depends(get_wallet_repository)]  ||  LedgerRepositoryDep = Annotated[LedgerRepository, Depends(get_ledger_repository)]  ||  default_trade_amount_gbp=request.default_trade_amount_gbp,  ||  risk_tolerance=request.risk_tolerance,  ||  default_trade_amount_gbp=user.default_trade_amount_gbp,  ||  risk_tolerance=user.risk_tolerance,  ||  @router.post(""/wallets"")  ||  async def create_test_wallet(  ||  request: CreateWalletRequest,  ||  wallet_repo: WalletRepositoryDep,  ||  Create a test wallet for database testing.  ||  request: Wallet creation request  ||  wallet_repo: Wallet repository dependency  ||  Success message with wallet ID  ||  wallet = await wallet_repo.create_wallet(  ||  wallet_type=request.wallet_type,  ||  is_hot_wallet=request.is_hot_wallet,  ||  ""message"": ""Wallet created successfully"",  ||  ""wallet_id"": str(wallet.id),  ||  ""address"": wallet.address,  ||  ""chain"": wallet.chain,  ||  @router.post(""/test-trade"")  ||  async def create_test_trade(  ||  request: CreateTestTradeRequest,  ||  wallet_repo: WalletRepositoryDep,  ||  Create a test trade entry with ledger logging.  ||  request: Test trade request  ||  wallet_repo: Wallet repository dependency  ||  # Get user's wallet for the chain  ||  wallets = await wallet_repo.get_user_wallets(  ||  wallet = None  ||  for w in wallets:  ||  if w.address.lower() == request.wallet_address.lower():  ||  wallet = w  ||  if not wallet:  ||  detail=f""Wallet {request.wallet_address} not found for user {request.user_id} on {request.chain}""  ||  wallet_id=wallet.id,  ||  tx_type=request.trade_type,  ||  amount_in=request.amount_native if request.trade_type == ""buy"" else request.amount_tokens,  ||  amount_out=request.amount_tokens if request.trade_type == ""buy"" else request.amount_native,  ||  # Create ledger entry  ||  await ledger_writer.write_trade_entry(  ||  trade_type=request.trade_type,  ||  wallet_address=request.wallet_address,  ||  notes=""Test trade via API"",  ||  ""message"": ""Test trade created successfully"",  ||  ""trade_type"": request.trade_type,  ||  users_result = await session.execute(select(func.count(User.id)))  ||  wallets_result = await session.execute(select(func.count(Wallet.id)))  ||  total_wallets = wallets_result.scalar()  ||  transactions_result = await session.execute(select(func.count(Transaction.id)))  ||  ledger_result = await session.execute(select(func.count(LedgerEntry.id)))  ||  total_ledger_entries = ledger_result.scalar()  ||  tokens_result = await session.execute(select(func.count(TokenMetadata.id)))  ||  total_wallets=total_wallets or 0,  ||  total_ledger_entries=total_ledger_entries or 0,  ||  default_trade_amount_gbp=user.default_trade_amount_gbp,  ||  risk_tolerance=user.risk_tolerance,  ||  @router.post(""/export-ledger/{user_id}"")  ||  async def export_user_ledger(  ||  Export user's ledger to file.  ||  filepath = await ledger_writer.export_user_ledger_csv(user_id)  ||  filepath = await ledger_writer.export_user_ledger_xlsx(user_id)  ||  ""message"": f""Ledger exported successfully"",  ||  ""wallets"",  ||  ""ledger_entries"",  ||  result = await session.execute(text(""SELECT 1 as test""))  ||  tables_result = await session.execute(text(""SELECT name FROM sqlite_master WHERE type='table'""))  ||  # Add these to backend/app/api/quotes.py  ||  async def quotes_health():  ||  """"""Health check for quotes service.""""""  ||  ""message"": ""Quotes service is operational"",  ||  ""note"": ""Ready for quote aggregation""  ||  async def simple_quotes_test():  ||  """"""Simple test of quote service without dependencies.""""""  ||  ""message"": ""Quote service basic functionality is working"",  ||  ""mock_quote"": {"
"D:\dex\backend\app\api\diagnostics.py","19159","from __future__ import annotations | import logging | from datetime import datetime | from typing import Any, Dict, List, Optional | from fastapi import APIRouter, HTTPException, Query | from pydantic import BaseModel | from ..core.self_test import (",""
"D:\dex\backend\app\api\discovery.py","42922","from __future__ import annotations | import asyncio | import logging | import time | from datetime import datetime, timedelta, timezone | from decimal import Decimal | from typing import Dict, Any, List, Optional, Set, Tuple | from enum import Enum | import re | import httpx | from fastapi import APIRouter, HTTPException, Query, BackgroundTasks | from pydantic import BaseModel, Field, validator | from ..core.settings import get_settings","risk_score: Optional[Decimal] = None  ||  risk_flags: List[str] = []  ||  max_risk_score: int = Field(default=70, description=""Maximum risk score (0-100)"")  ||  exclude_risk_flags: List[str] = Field(default=[""honeypot""], description=""Risk flags to exclude"")  ||  ""arbitrum"": {""uniswap_v3"", ""sushiswap"", ""curve"", ""balancer"", ""camelot"", ""trader_joe""},  ||  def calculate_enhanced_risk_score(pair_data: Dict[str, Any]) -> Tuple[float, List[str]]:  ||  Enhanced risk scoring with more granular precision and validation.  ||  Tuple of (risk_score_0_to_1, risk_flags)  ||  risk_score = 0.3  # Start at lower baseline  ||  risk_flags = []  ||  risk_score += 0.4  ||  risk_flags.append(""very_low_liquidity"")  ||  risk_score += 0.25  ||  risk_flags.append(""low_liquidity"")  ||  risk_score += 0.15  ||  risk_flags.append(""medium_liquidity"")  ||  risk_score += 0.05  ||  risk_flags.append(""moderate_liquidity"")  ||  # High liquidity reduces risk  ||  risk_score -= 0.1  ||  risk_flags.append(""high_liquidity"")  ||  risk_score += 0.2  ||  risk_flags.append(""low_volume"")  ||  risk_score += 0.15  ||  risk_flags.append(""high_turnover_risk"")  ||  risk_score += 0.1  ||  risk_flags.append(""stagnant_trading"")  ||  risk_score += 0.3  ||  risk_flags.append(""extremely_new_pair"")  ||  risk_score += 0.2  ||  risk_flags.append(""very_new_pair"")  ||  risk_score += 0.1  ||  risk_flags.append(""new_pair"")  ||  risk_score -= 0.05  # Established pairs are less risky  ||  risk_flags.append(""established_pair"")  ||  risk_score += 0.1  ||  risk_flags.append(""unknown_age"")  ||  risk_score += 0.2  ||  risk_flags.append(""extreme_volatility"")  ||  risk_score += 0.1  ||  risk_flags.append(""high_volatility"")  ||  risk_score += 0.15  ||  risk_flags.append(""recent_volatility"")  ||  risk_score += 0.15  ||  risk_flags.append(""low_activity"")  ||  risk_score -= 0.05  ||  risk_flags.append(""high_activity"")  ||  risk_score += 0.1  ||  risk_flags.append(""imbalanced_trading"")  ||  risk_score += 0.15  ||  risk_flags.append(""micro_cap"")  ||  risk_score -= 0.05  ||  risk_flags.append(""large_cap"")  ||  risk_score += 0.3  ||  risk_flags.append(""suspicious_name"")  ||  # Cap risk score between 0 and 1  ||  risk_score = max(0.0, min(1.0, risk_score))  ||  return risk_score, risk_flags  ||  quote_token_addr = pair.get(""quoteToken"", {}).get(""address"", """").lower()  ||  token_addresses = tuple(sorted([base_token_addr, quote_token_addr]))  ||  existing_quote = existing_pair.get(""quoteToken"", {}).get(""address"", """").lower()  ||  quote_token_addr == existing_quote and  ||  ""trading_health"": ""healthy"" if (activity_score > 20 and liquidity_score > 10 and stability_score > 50) else ""risky"",  ||  def calculate_risk_score(pair_data: Dict[str, Any]) -> tuple[float, List[str]]:  ||  Calculate risk score and flags for a trading pair.  ||  Tuple of (risk_score, risk_flags)  ||  risk_score = 0.5  # Start at medium risk  ||  risk_flags = []  ||  risk_score += 0.3  ||  risk_flags.append(""low_liquidity"")  ||  risk_score += 0.1  ||  risk_flags.append(""medium_liquidity"")  ||  risk_score += 0.2  ||  risk_flags.append(""low_volume"")  ||  risk_score += 0.2  ||  risk_flags.append(""very_new_pair"")  ||  risk_score += 0.1  ||  risk_flags.append(""new_pair"")  ||  risk_flags.append(""unknown_age"")  ||  risk_score += 0.2  ||  risk_flags.append(""high_volatility"")  ||  # Cap risk score at 1.0  ||  risk_score = min(risk_score, 1.0)  ||  return risk_score, risk_flags  ||  # Calculate enhanced risk score  ||  risk_score, risk_flags = calculate_enhanced_risk_score(pair_data)  ||  quote_token = pair_data.get(""quoteToken"", {})  ||  ""address"": quote_token.get(""address"", f""0x{'0' * 40}""),  ||  ""symbol"": quote_token.get(""symbol"", ""UNKNOWN""),  ||  ""name"": quote_token.get(""name"", ""Unknown Token""),  ||  ""risk_score"": int(risk_score * 100),  ||  ""risk_flags"": risk_flags,  ||  # Sort by opportunity score (inverse of risk)  ||  unique_pairs.sort(key=lambda p: (1 - p.get(""risk_score"", 50) / 100), reverse=True)  ||  risk_score, risk_flags = calculate_enhanced_risk_score(pair_data)  ||  quote_token = pair_data.get(""quoteToken"", {})  ||  token1_address=quote_token.get(""address"", """"),  ||  token1_symbol=quote_token.get(""symbol""),  ||  token1_name=quote_token.get(""name""),  ||  opportunity_level=OpportunityLevel.HIGH if risk_score < 0.3 else OpportunityLevel.MEDIUM if risk_score < 0.7 else OpportunityLevel.LOW,  ||  risk_score=Decimal(str(risk_score)),  ||  risk_flags=risk_flags,  ||  ""risk_assessment"": True,  ||  ""enhanced_risk_scoring"": True,"
"D:\dex\backend\app\api\health.py","11745","from __future__ import annotations | import platform | import time | from datetime import datetime | from typing import Any, Dict | from fastapi import APIRouter, Request | from pydantic import BaseModel | import logging | from ..core.settings import settings | from ..storage.database import db_manager |     from fastapi import HTTPException, status as http_status  # noqa: WPS433","autotrade_enabled = getattr(settings, ""autotrade_enabled"", False)  ||  autotrade_enabled = False  ||  ""autotrade_enabled"": autotrade_enabled,"
"D:\dex\backend\app\api\intelligence.py","21166","from __future__ import annotations | import asyncio | import logging | from typing import Dict, List, Optional, Any | from datetime import datetime, timezone | from decimal import Decimal | from fastapi import APIRouter, Depends, HTTPException, status, Query | from pydantic import BaseModel, Field | from ..core.dependencies import get_current_user, CurrentUser, rate_limiter | from ..discovery.event_processor import event_processor, ProcessedPair, OpportunityLevel | from ..ai.market_intelligence import MarketIntelligenceEngine | import logging","risk_factors: List[str] = Field(..., description=""Identified risk factors"")  ||  risk_level: str = Field(..., description=""Risk level of detected patterns"")  ||  risk_warnings: List[str] = Field(..., description=""AI-identified risk warnings"")  ||  risk_level=coordination_data.get(""risk_level"", ""low""),  ||  risk_factors=score_data.get(""risk_factors"", []),  ||  warning for warning in processed_pair.risk_warnings  ||  risk_warnings=ai_warnings"
"D:\dex\backend\app\api\ledger.py","26059","from __future__ import annotations | from fastapi import APIRouter, Depends, HTTPException, Query, status | import logging | import uuid | from datetime import datetime, timedelta | from decimal import Decimal | from typing import Any, Dict, List, Optional | from fastapi import APIRouter, Depends, HTTPException, Query, status | from starlette import status as http_status  # Alternative import if needed | from pydantic import BaseModel, Field | from sqlalchemy.exc import SQLAlchemyError | from ..core.dependencies import get_current_user, CurrentUser | from ..storage.repositories import (","Ledger API endpoints for DEX Sniper Pro.  ||  File: backend/app/api/ledger.py  ||  LedgerRepository,  ||  get_ledger_repository,  ||  router = APIRouter(prefix=""/ledger"", tags=[""Ledger""])  ||  trade_type: str = Field(..., description=""Trade type (buy/sell)"")  ||  gas_fee: Optional[str] = Field(None, description=""Gas fee in native token"")  ||  total_trades: int = Field(..., description=""Total number of trades"")  ||  last_trade_date: Optional[str] = Field(None, description=""Last trade timestamp"")  ||  wallet_address: str = Query(..., description=""Wallet address to query""),  ||  ledger_repo: LedgerRepository = Depends(get_ledger_repository),  ||  Get user positions by wallet address.  ||  Retrieves all active positions for a specific wallet with current  ||  wallet_address: Wallet address to query positions for  ||  ledger_repo: Ledger repository dependency  ||  trace_id = f""ledger_positions_{uuid.uuid4().hex[:12]}""  ||  f""Fetching positions for wallet"",  ||  'wallet_address': wallet_address[:10] + '...' if len(wallet_address) > 10 else wallet_address,  ||  # Get user's ledger entries for position calculation  ||  ledger_entries = await ledger_repo.get_user_ledger(  ||  # Filter entries for the specific wallet address  ||  wallet_entries = [  ||  entry for entry in ledger_entries  ||  if entry.wallet_address.lower() == wallet_address.lower()  ||  f""Retrieved ledger entries for position calculation"",  ||  'total_entries': len(ledger_entries),  ||  'wallet_entries': len(wallet_entries),  ||  # Calculate positions from ledger entries  ||  positions = _calculate_positions_from_entries(wallet_entries, trace_id)  ||  'wallet_address': wallet_address[:10] + '...',  ||  'wallet_address': wallet_address[:10] + '...',  ||  'wallet_address': wallet_address[:10] + '...',  ||  wallet_address: str = Query(..., description=""Wallet address to query""),  ||  ledger_repo: LedgerRepository = Depends(get_ledger_repository),  ||  Retrieves transaction history for a specific wallet with comprehensive  ||  wallet_address: Wallet address to query transactions for  ||  ledger_repo: Ledger repository dependency  ||  trace_id = f""ledger_transactions_{uuid.uuid4().hex[:12]}""  ||  'wallet_address': wallet_address[:10] + '...' if len(wallet_address) > 10 else wallet_address,  ||  # Get ledger entries with filters  ||  ledger_entries = await ledger_repo.get_user_ledger(  ||  # Filter entries for the specific wallet and criteria  ||  ledger_entries,  ||  wallet_address=wallet_address,  ||  trade_type=entry.trade_type,  ||  gas_fee=entry.transaction_fee,  ||  'total_entries': len(ledger_entries),  ||  'wallet_address': wallet_address[:10] + '...',  ||  wallet_address: str = Query(..., description=""Wallet address to query""),  ||  ledger_repo: LedgerRepository = Depends(get_ledger_repository),  ||  wallet_address: Wallet address to analyze  ||  ledger_repo: Ledger repository dependency  ||  'wallet_address': wallet_address[:10] + '...' if len(wallet_address) > 10 else wallet_address,  ||  # Get all user's ledger entries for comprehensive analysis  ||  ledger_entries = await ledger_repo.get_user_ledger(  ||  # Filter entries for the specific wallet  ||  wallet_entries = [  ||  entry for entry in ledger_entries  ||  if entry.wallet_address.lower() == wallet_address.lower()  ||  summary = _calculate_portfolio_summary(wallet_entries, trace_id)  ||  'total_entries': len(ledger_entries),  ||  'wallet_entries': len(wallet_entries),  ||  'total_trades': summary.total_trades,  ||  'wallet_address': wallet_address[:10] + '...'  ||  'wallet_address': wallet_address[:10] + '...'  ||  """"""Calculate current positions from ledger entries.""""""  ||  if entry.trade_type == 'buy':  ||  elif entry.trade_type == 'sell':  ||  wallet_address: str,  ||  # Wallet address filter  ||  if entry.wallet_address.lower() != wallet_address.lower():  ||  """"""Calculate comprehensive portfolio summary from ledger entries.""""""  ||  total_trades = len(entries)  ||  winning_trades = 0  ||  last_trade_date = None  ||  if entry.trade_type == 'buy' and hasattr(entry, 'price_usd') and entry.price_usd:  ||  winning_trades += 1  ||  # Track last trade date  ||  if not last_trade_date or entry.timestamp > last_trade_date:  ||  last_trade_date = entry.timestamp  ||  win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0  ||  total_trades=total_trades,  ||  last_trade_date=last_trade_date.isoformat() if last_trade_date else None,"
"D:\dex\backend\app\api\monitoring.py","23551","from __future__ import annotations | import logging | from datetime import datetime, timedelta | from typing import Any, Dict, List, Optional, Union | from fastapi import APIRouter, HTTPException, Query, Depends | from pydantic import BaseModel, Field | from ..monitoring.alerts import ( | from ..core.self_test import ( |         from ..monitoring.alerts import record_response_time |         from ..monitoring.alerts import record_error_rate |         from ..monitoring.alerts import record_rpc_failure",""
"D:\dex\backend\app\api\orders.py","2581","from __future__ import annotations | import logging | from typing import Dict, Any, List | from enum import Enum | from fastapi import APIRouter | from pydantic import BaseModel",""
"D:\dex\backend\app\api\pairs.py","1617","from __future__ import annotations | import logging | from typing import Dict, Any, List | from fastapi import APIRouter | from pydantic import BaseModel",""
"D:\dex\backend\app\api\presets.py","35021","from __future__ import annotations | import logging | import uuid | from typing import Dict, List, Optional, Any | from decimal import Decimal | from enum import Enum | from fastapi import APIRouter, HTTPException, status, Query | from pydantic import BaseModel, Field, field_validator | from typing import Dict, List, Optional, Any |     from datetime import datetime, timezone |     from datetime import datetime, timezone |     from datetime import datetime, timezone","""""""Trade trigger conditions.""""""  ||  # Risk management  ||  max_daily_trades: int = Field(default=10, ge=1, le=100)  ||  gas_price_limit_gwei: Optional[float] = Field(default=None, ge=1.0, le=1000.0)  ||  risk_score: float = Field(..., description=""Calculated risk score"")  ||  total_trades: int = Field(..., description=""Total trades executed"")  ||  successful_trades: int = Field(..., description=""Number of successful trades"")  ||  risk_score: Optional[float] = Field(default=None, description=""Risk score (0-100)"")  ||  description=""Low-risk new pair snipe with minimal position sizes"",  ||  risk_score=20.0,  ||  description=""Low-risk new pair snipe with minimal position sizes"",  ||  max_daily_trades=5,  ||  gas_price_limit_gwei=50.0,  ||  risk_score=25.0,  ||  max_daily_trades=8,  ||  gas_price_limit_gwei=75.0,  ||  description=""Balanced new pair snipe with moderate risk"",  ||  risk_score=50.0,  ||  description=""Balanced new pair snipe with moderate risk"",  ||  max_daily_trades=15,  ||  gas_price_limit_gwei=100.0,  ||  risk_score=45.0,  ||  max_daily_trades=20,  ||  gas_price_limit_gwei=150.0,  ||  description=""High-risk new pair snipe with large positions"",  ||  risk_score=80.0,  ||  description=""High-risk new pair snipe with large positions"",  ||  max_daily_trades=50,  ||  gas_price_limit_gwei=500.0,  ||  description=""High-risk trending plays with maximum leverage"",  ||  risk_score=85.0,  ||  description=""High-risk trending plays with maximum leverage"",  ||  max_daily_trades=100,  ||  gas_price_limit_gwei=1000.0,  ||  def _calculate_risk_score(config: PresetConfig) -> float:  ||  """"""Calculate risk score for a preset configuration.""""""  ||  risk_score = 0.0  ||  risk_score += 5.0  ||  risk_score += 15.0  ||  risk_score += 20.0  ||  risk_score += 25.0  ||  risk_score += 5.0  ||  risk_score += 10.0  ||  risk_score += 15.0  ||  risk_score += 20.0  ||  risk_score += 0.0  ||  risk_score += 5.0  ||  risk_score += 10.0  ||  risk_score += 15.0  ||  risk_score += 0.0  ||  risk_score += 3.0  ||  risk_score += 7.0  ||  risk_score += 10.0  ||  if config.max_daily_trades <= 10:  ||  risk_score += 2.0  ||  elif config.max_daily_trades <= 25:  ||  risk_score += 5.0  ||  elif config.max_daily_trades <= 50:  ||  risk_score += 8.0  ||  risk_score += 10.0  ||  risk_score += 5.0  ||  risk_score += 5.0  ||  # Gas price factor (0-10 points)  ||  if config.gas_price_limit_gwei and config.gas_price_limit_gwei >= 500.0:  ||  risk_score += 10.0  ||  elif config.gas_price_limit_gwei and config.gas_price_limit_gwei >= 200.0:  ||  risk_score += 5.0  ||  return min(risk_score, 100.0)  ||  warnings.append(""Low liquidity requirement increases execution risk"")  ||  # Check daily trade limits  ||  if config.max_daily_trades > 100:  ||  warnings.append(""High daily trade limit may lead to overtrading"")  ||  # Check gas limits  ||  if config.gas_price_limit_gwei and config.gas_price_limit_gwei > 500.0:  ||  warnings.append(""High gas price limit may result in expensive transactions"")  ||  # Calculate risk score  ||  risk_score = _calculate_risk_score(config)  ||  risk_score=risk_score,  ||  risk_score=preset.risk_score,  ||  risk_score=preset.risk_score,  ||  risk_score=validation.risk_score,  ||  logger.info(f""Created preset: {preset_id} with risk score {validation.risk_score}"")  ||  risk_score=validation.risk_score,  ||  Validation result with risk score and warnings  ||  logger.info(f""Validation result for {preset_id}: {validation.status}, risk={validation.risk_score}"")  ||  risk_tolerance: Optional[str] = Query(None, description=""Risk tolerance (low, medium, high)""),  ||  risk_tolerance: Optional risk tolerance (low, medium, high)  ||  logger.info(f""Getting recommendations: strategy={strategy_type}, risk={risk_tolerance}"")  ||  # Adjust for risk tolerance  ||  if risk_tolerance:  ||  preset_risk = preset.risk_score or 50.0  ||  if risk_tolerance == ""low"" and preset_risk <= 30.0:  ||  elif risk_tolerance == ""medium"" and 30.0 < preset_risk <= 70.0:  ||  elif risk_tolerance == ""high"" and preset_risk > 70.0:  ||  reason_parts.append(""Low risk approach"")  ||  reason_parts.append(""Balanced risk/reward"")  ||  Performance summary with preset and trade statistics  ||  # Mock trade data (will be replaced with actual data)  ||  total_trades = 0  ||  successful_trades = 0  ||  win_rate = (successful_trades / total_trades * 100) if total_trades > 0 else 0.0  ||  total_trades=total_trades,  ||  successful_trades=successful_trades,  ||  ""description"": ""Use a fixed USD amount for all trades""  ||  ""description"": ""Execute trade immediately when opportunity detected"""
"D:\dex\backend\app\api\project_status.py","33526","from __future__ import annotations | import logging | from datetime import datetime | from typing import Any, Dict, List | from fastapi import APIRouter | from pydantic import BaseModel","name=""Wallet Management & Security"",  ||  notes=""Cross-chain token operations and approvals""  ||  name=""DEX Adapters & Quote Aggregation"",  ||  name=""Trade Execution Engine"",  ||  notes=""Complete trade lifecycle with status tracking""  ||  # Phase 4: Risk Management & Discovery  ||  name=""Risk Management Framework"",  ||  notes=""10-category risk assessment with external providers""  ||  notes=""Real-time pair monitoring with WebSocket feeds""  ||  name=""Safety Controls & Circuit Breakers"",  ||  # Phase 6: Autotrade Engine  ||  name=""Core Autotrade Engine"",  ||  # Phase 7: Enhanced Ledger & Reporting  ||  name=""Enhanced Ledger System"",  ||  notes=""Complete AI suite with auto-tuning and risk explanation""  ||  notes=""Trader tracking, signal detection, and portfolio mirroring""  ||  name=""Risk Management & Discovery"",  ||  name=""Autotrade Engine"",  ||  name=""Enhanced Ledger & Reporting"",  ||  ""quote_aggregation"": {""status"": ""complete"", ""description"": ""Multi-DEX quote comparison""},  ||  ""trade_execution"": {""status"": ""complete"", ""description"": ""Complete trade lifecycle management""},  ||  # Risk & Discovery  ||  ""risk_management"": {""status"": ""complete"", ""description"": ""10-category risk assessment framework""},  ||  ""safety_controls"": {""status"": ""complete"", ""description"": ""Emergency stops and circuit breakers""},  ||  ""autotrade_engine"": {""status"": ""complete"", ""description"": ""Automated trading with queue management""},  ||  ""enhanced_ledger"": {""status"": ""complete"", ""description"": ""Advanced export and archival system""},  ||  ""ai_integration"": {""status"": ""complete"", ""description"": ""Auto-tuning and risk explanation AI""},  ||  ""copy_trading"": {""status"": ""complete"", ""description"": ""Trader tracking and portfolio mirroring""},  ||  ""approval_tracking"": {""target"": ""limits enforced"", ""actual"": ""implemented"", ""passed"": True}  ||  ""quote_response_time"": {""target"": ""< 200ms"", ""actual"": ""125ms"", ""passed"": True},  ||  ""trade_execution"": {""target"": ""lifecycle complete"", ""actual"": ""implemented"", ""passed"": True},  ||  ""risk_assessment_time"": {""target"": ""< 100ms"", ""actual"": ""80ms"", ""passed"": True},  ||  ""websocket_delivery"": {""target"": ""< 100ms"", ""actual"": ""80ms"", ""passed"": True}  ||  ""autotrade_response"": {""target"": ""< 200ms"", ""actual"": ""25ms"", ""passed"": True},  ||  ""ledger_export"": {""target"": ""< 2s for 10K entries"", ""actual"": ""< 1s"", ""passed"": True},  ||  ""backtesting_throughput"": {""target"": ""> 100 trades/s"", ""actual"": ""> 150 trades/s"", ""passed"": True},  ||  ""copy_trading_system"": {""target"": ""trader tracking"", ""actual"": ""full implementation"", ""passed"": True},  ||  ""wallet"": {""endpoints"": 5, ""status"": ""operational"", ""description"": ""Wallet integration and operations""},  ||  ""quotes"": {""endpoints"": 3, ""status"": ""operational"", ""description"": ""Multi-DEX quote aggregation""},  ||  ""trades"": {""endpoints"": 4, ""status"": ""operational"", ""description"": ""Trade execution and tracking""},  ||  ""risk"": {""endpoints"": 2, ""status"": ""operational"", ""description"": ""Risk assessment and scoring""},  ||  ""safety"": {""endpoints"": 3, ""status"": ""operational"", ""description"": ""Safety controls and circuit breakers""},  ||  ""autotrade"": {""endpoints"": 5, ""status"": ""operational"", ""description"": ""Automated trading engine""},  ||  ""copytrade"": {""endpoints"": 6, ""status"": ""operational"", ""description"": ""Copy trading system""},"
"D:\dex\backend\app\api\quotes.py","38327","from __future__ import annotations | import asyncio | import logging | import time | import uuid | from decimal import Decimal | from datetime import datetime, timedelta | from typing import List, Optional, Dict, Any | from fastapi import APIRouter, HTTPException, Query, Request | from pydantic import BaseModel, Field, validator |         from ..dex import DEXAdapterRegistry |     import re |     from decimal import InvalidOperation","Quotes API with real DEX integration and token address resolution.  ||  to provide real quotes instead of mock data. Includes automatic token  ||  Updated to use DEXAdapterRegistry for multiple quotes from all available adapters.  ||  File: backend/app/api/quotes.py  ||  router = APIRouter(prefix=""/quotes"", tags=[""quotes""])  ||  class QuoteRequest(BaseModel):  ||  """"""Request model for getting quotes.""""""  ||  amount_in: Decimal = Field(..., description=""Amount to trade"", gt=0)  ||  class FrontendQuoteRequest(BaseModel):  ||  wallet_address: Optional[str] = Field(None, description=""Wallet address for gas estimation"")  ||  class DexQuote(BaseModel):  ||  """"""Individual DEX quote.""""""  ||  gas_estimate: int  ||  estimated_gas_cost_usd: Optional[Decimal] = None  ||  class FrontendQuote(BaseModel):  ||  """"""Quote in frontend-expected format.""""""  ||  gas_estimate: int = Field(..., description=""Gas estimate in wei"")  ||  confidence: float = Field(default=1.0, description=""Quote confidence score"")  ||  class QuoteResponse(BaseModel):  ||  """"""Comprehensive quote response.""""""  ||  quotes: List[DexQuote]  ||  best_quote: Optional[DexQuote] = None  ||  risk_score: Optional[Decimal] = None  ||  risk_flags: List[str] = []  ||  class FrontendQuoteResponse(BaseModel):  ||  """"""Quote response matching frontend expectations.""""""  ||  quotes: List[FrontendQuote] = Field(default_factory=list, description=""Available quotes"")  ||  best_quote: Optional[FrontendQuote] = Field(default=None, description=""Best quote by output"")  ||  async def _get_real_quote_from_adapter(  ||  ) -> Optional[DexQuote]:  ||  Get real quote from DEX adapter with enhanced error handling and logging.  ||  DexQuote or None if failed.  ||  quote_start_time = time.time()  ||  ""Requesting real quote"",  ||  if not hasattr(adapter, 'get_quote'):  ||  logger.error(f""Adapter {dex_name} missing get_quote method"")  ||  if asyncio.iscoroutinefunction(adapter.get_quote):  ||  result = await adapter.get_quote(  ||  result = adapter.get_quote(  ||  if asyncio.iscoroutinefunction(adapter.get_quote):  ||  result = await adapter.get_quote(  ||  result = adapter.get_quote(  ||  quote_execution_time_ms = int((time.time() - quote_start_time) * 1000)  ||  # Parse result into DexQuote  ||  quote = DexQuote(  ||  gas_estimate=int(result.get('gas_estimate', 150000)),  ||  estimated_gas_cost_usd=Decimal(str(result.get('gas_cost_usd', '10.0'))) if result.get('gas_cost_usd') else None  ||  if quote.amount_out <= 0:  ||  logger.error(f""Invalid quote from {dex_name}: zero output"")  ||  logger.info(f""Real quote successful from {dex_name}: {quote.amount_out}"")  ||  return quote  ||  logger.error(f""Error parsing quote from {dex_name}: {e}"")  ||  logger.error(f""Critical error getting quote from {dex_name}: {e}"", exc_info=True)  ||  def _convert_to_frontend_format(quotes: List[DexQuote]) -> List[FrontendQuote]:  ||  """"""Convert internal DexQuote format to frontend-expected format.""""""  ||  frontend_quotes = []  ||  for quote in quotes:  ||  frontend_quote = FrontendQuote(  ||  dex=f""{quote.dex_name}_{quote.dex_version}"" if quote.dex_version and quote.dex_version != 'unknown' else quote.dex_name,  ||  output_amount=str(quote.amount_out),  ||  price_impact=float(quote.price_impact),  ||  gas_estimate=quote.gas_estimate,  ||  route=quote.route_path,  ||  confidence=float(quote.confidence_score)  ||  frontend_quotes.append(frontend_quote)  ||  logger.error(f""Error converting quote to frontend format: {e}"")  ||  return frontend_quotes  ||  @router.post(""/aggregate"", response_model=FrontendQuoteResponse)  ||  async def get_aggregate_quotes(request: Request, quote_request: FrontendQuoteRequest) -> FrontendQuoteResponse:  ||  Get aggregated quotes from multiple DEXs using DEXAdapterRegistry.  ||  logger.info(f""Frontend aggregate quote request: {request_id}"")  ||  token_in_address = _resolve_token_address(quote_request.from_token, quote_request.chain, trace_id)  ||  token_out_address = _resolve_token_address(quote_request.to_token, quote_request.chain, trace_id)  ||  logger.info(f""Tokens resolved: {quote_request.from_token}->{token_in_address}, {quote_request.to_token}->{token_out_address}"")  ||  return FrontendQuoteResponse(  ||  quotes=[],  ||  best_quote=None,  ||  chain=quote_request.chain,  ||  amount_decimal = Decimal(quote_request.amount)  ||  slippage_decimal = Decimal(str(quote_request.slippage / 100))  ||  return FrontendQuoteResponse(  ||  quotes=[],  ||  best_quote=None,  ||  chain=quote_request.chain,  ||  supported_dexs = _get_supported_dexs_from_registry(quote_request.chain, trace_id)  ||  return FrontendQuoteResponse(  ||  quotes=[],  ||  best_quote=None,  ||  chain=quote_request.chain,  ||  message=f""Chain {quote_request.chain} not supported""  ||  # Create quote tasks  ||  quote_tasks = []  ||  task = _get_real_quote_from_adapter(  ||  chain=quote_request.chain,  ||  quote_tasks.append(task)  ||  if not quote_tasks:  ||  return FrontendQuoteResponse(  ||  quotes=[],  ||  best_quote=None,  ||  chain=quote_request.chain,  ||  logger.info(f""Executing {len(quote_tasks)} quote requests"")  ||  # Execute quotes  ||  quote_results = await asyncio.wait_for(  ||  asyncio.gather(*quote_tasks, return_exceptions=True),  ||  return FrontendQuoteResponse(  ||  quotes=[],  ||  best_quote=None,  ||  chain=quote_request.chain,  ||  message=""Quote requests timed out""  ||  quotes = []  ||  for i, result in enumerate(quote_results):  ||  if isinstance(result, DexQuote):  ||  quotes.append(result)  ||  logger.info(f""Quote {i+1} successful: {dex_name} -> {result.amount_out}"")  ||  logger.warning(f""Quote {i+1} failed: {dex_name} returned None"")  ||  logger.warning(f""Quote {i+1} exception: {dex_name} - {str(result)}"")  ||  if not quotes:  ||  return FrontendQuoteResponse(  ||  quotes=[],  ||  best_quote=None,  ||  chain=quote_request.chain,  ||  message=""No quotes available from any DEX""  ||  frontend_quotes = _convert_to_frontend_format(quotes)  ||  best_quote = max(frontend_quotes, key=lambda q: Decimal(q.output_amount)) if frontend_quotes else None  ||  logger.info(f""Aggregate quote completed: {len(quotes)} quotes in {processing_time_ms}ms"")  ||  return FrontendQuoteResponse(  ||  quotes=frontend_quotes,  ||  best_quote=best_quote,  ||  chain=quote_request.chain,  ||  message=f""Retrieved {len(quotes)} quotes from {len(frontend_quotes)} DEXs""  ||  logger.error(f""Unexpected error in aggregate quotes: {e}"", exc_info=True)  ||  return FrontendQuoteResponse(  ||  quotes=[],  ||  best_quote=None,  ||  chain=quote_request.chain,  ||  ""real_quotes"": len(supported_dexs) > 0,  ||  ""total_chains"": len([c for c in chains_data if c[""real_quotes""]])  ||  async def get_quotes_health() -> Dict[str, Any]:  ||  """"""Get health status of quote services.""""""  ||  @router.get(""/"", response_model=QuoteResponse)  ||  async def get_quote(  ||  amount_in: Decimal = Query(..., description=""Amount to trade"", gt=0),  ||  ) -> QuoteResponse:  ||  """"""Get comprehensive trading quotes from real DEX contracts.""""""  ||  request_id = f""quote_{int(start_time)}""  ||  logger.info(f""Processing quote request: {request_id}"")  ||  quote_request = QuoteRequest(  ||  supported_dexs = _get_supported_dexs_from_registry(quote_request.chain, trace_id)  ||  raise HTTPException(status_code=400, detail=f""Chain {quote_request.chain} not supported"")  ||  # Get quotes  ||  quote_tasks = []  ||  dex_order = quote_request.dex_preference or supported_dexs  ||  task = _get_real_quote_from_adapter(  ||  chain=quote_request.chain,  ||  token_in_address=quote_request.token_in,  ||  token_out_address=quote_request.token_out,  ||  amount_in=quote_request.amount_in,  ||  slippage_tolerance=quote_request.slippage,  ||  quote_tasks.append(task)  ||  # Execute quotes  ||  quote_results = await asyncio.gather(*quote_tasks, return_exceptions=True)  ||  # Filter successful quotes  ||  quotes = [r for r in quote_results if isinstance(r, DexQuote)]  ||  if not quotes:  ||  raise HTTPException(status_code=404, detail=""No quotes available"")  ||  # Add frontend-compatible field names to each quote for compatibility  ||  for quote in quotes:  ||  quote.__dict__['dex'] = quote.dex_name  ||  quote.__dict__['output_amount'] = str(quote.amount_out)  ||  quote.__dict__['route'] = quote.route_path  ||  # Find best quote and add frontend fields to it as well  ||  best_quote = max(quotes, key=lambda q: q.amount_out)  ||  if best_quote:  ||  best_quote.__dict__['dex'] = best_quote.dex_name  ||  best_quote.__dict__['output_amount'] = str(best_quote.amount_out)  ||  best_quote.__dict__['route'] = best_quote.route_path  ||  aggregate_liquidity = sum(q.amount_out for q in quotes)  ||  return QuoteResponse(  ||  chain=quote_request.chain,  ||  token_in=quote_request.token_in,  ||  token_out=quote_request.token_out,  ||  amount_in=quote_request.amount_in,  ||  quotes=quotes,  ||  best_quote=best_quote,  ||  risk_score=Decimal('0.2'),  ||  risk_flags=[],"
"D:\dex\backend\app\api\risk.py","21329","from __future__ import annotations | import asyncio | import logging | import time | import uuid | from decimal import Decimal | from typing import Any, Dict, List, Optional | from datetime import datetime, timedelta | from enum import Enum | from fastapi import APIRouter, Depends, HTTPException, status, Query | from pydantic import BaseModel, Field |         import random |         import random","DEX Sniper Pro - Risk Management API.  ||  Comprehensive risk assessment, safety controls, and canary testing for secure trading.  ||  router = APIRouter(prefix=""/risk"", tags=[""Risk Management""])  ||  class RiskLevel(str, Enum):  ||  """"""Risk level classifications.""""""  ||  class SafetyLevel(str, Enum):  ||  """"""Safety control levels.""""""  ||  class RiskAssessmentRequest(BaseModel):  ||  """"""Request model for token risk assessment.""""""  ||  trade_amount_usd: Optional[Decimal] = Field(None, description=""Proposed trade amount in USD"")  ||  ""trade_amount_usd"": ""100.0""  ||  class RiskFactors(BaseModel):  ||  """"""Individual risk factor scores.""""""  ||  honeypot_risk: float = Field(..., description=""Honeypot detection score (0-1)"")  ||  ownership_risk: float = Field(..., description=""Contract ownership risk (0-1)"")  ||  class RiskAssessmentResponse(BaseModel):  ||  """"""Risk assessment response model.""""""  ||  overall_score: float = Field(..., description=""Overall risk score (0-1)"")  ||  overall_risk: RiskLevel = Field(..., description=""Risk level classification"")  ||  risk_factors: RiskFactors  ||  is_tradeable: bool = Field(..., description=""Whether token is safe to trade"")  ||  wallet_address: str = Field(..., description=""Wallet to execute canary from"")  ||  ""wallet_address"": ""0x9876543210987654321098765432109876543210""  ||  gas_used: Optional[int] = None  ||  class SafetyStatusResponse(BaseModel):  ||  """"""Safety controls status response.""""""  ||  safety_level: SafetyLevel  ||  safety_checks_performed: int  ||  trades_blocked: int  ||  class MockRiskEngine:  ||  """"""Mock risk assessment engine for testing.""""""  ||  """"""Initialize mock risk engine.""""""  ||  self.safety_level = SafetyLevel.STANDARD  ||  self.safety_checks = 0  ||  self.trades_blocked = 0  ||  # Risk scoring weights  ||  self.risk_weights = {  ||  ""honeypot_risk"": 0.25,  ||  ""ownership_risk"": 0.05  ||  async def assess_token_risk(  ||  trade_amount_usd: Optional[Decimal] = None  ||  ) -> RiskAssessmentResponse:  ||  """"""Perform comprehensive token risk assessment.""""""  ||  self.safety_checks += 1  ||  # Generate mock risk factors (would integrate with real services)  ||  risk_factors = await self._generate_risk_factors(token_address, chain)  ||  # Calculate overall risk score  ||  overall_score = self._calculate_overall_score(risk_factors)  ||  # Determine risk level  ||  overall_risk = RiskLevel.CRITICAL  ||  overall_risk = RiskLevel.HIGH  ||  overall_risk = RiskLevel.MEDIUM  ||  overall_risk = RiskLevel.LOW  ||  if risk_factors.honeypot_risk > 0.7:  ||  elif risk_factors.honeypot_risk > 0.4:  ||  warnings.append(""Potential honeypot risk - proceed with caution"")  ||  if risk_factors.tax_analysis > 0.8:  ||  elif risk_factors.tax_analysis > 0.5:  ||  if risk_factors.liquidity_score < 0.3:  ||  if not risk_factors.contract_verified:  ||  # Determine if tradeable  ||  is_tradeable = len(blocking_issues) == 0 and overall_risk != RiskLevel.CRITICAL  ||  if not is_tradeable:  ||  recommended_action = ""DO NOT TRADE - Critical risks identified""  ||  elif overall_risk == RiskLevel.HIGH:  ||  recommended_action = ""High risk - Consider canary testing first""  ||  elif overall_risk == RiskLevel.MEDIUM:  ||  recommended_action = ""Medium risk - Use conservative position sizing""  ||  recommended_action = ""Low risk - Safe to trade with standard controls""  ||  return RiskAssessmentResponse(  ||  overall_risk=overall_risk,  ||  risk_factors=risk_factors,  ||  is_tradeable=is_tradeable  ||  async def _generate_risk_factors(self, token_address: str, chain: str) -> RiskFactors:  ||  """"""Generate mock risk factor scores.""""""  ||  # Simulate realistic risk distributions  ||  return RiskFactors(  ||  honeypot_risk=max(0.0, min(1.0, random.normalvariate(0.2, 0.15))),  ||  ownership_risk=max(0.0, min(1.0, random.normalvariate(0.3, 0.2))),  ||  def _calculate_overall_score(self, risk_factors: RiskFactors) -> float:  ||  """"""Calculate weighted overall risk score.""""""  ||  # Convert factors to risk scores (higher = more risky)  ||  risk_scores = {  ||  ""contract_verified"": 0.0 if risk_factors.contract_verified else 1.0,  ||  ""liquidity_score"": 1.0 - risk_factors.liquidity_score,  ||  ""holder_distribution"": 1.0 - risk_factors.holder_distribution,  ||  ""trading_activity"": 1.0 - risk_factors.trading_activity,  ||  ""honeypot_risk"": risk_factors.honeypot_risk,  ||  ""tax_analysis"": risk_factors.tax_analysis,  ||  ""ownership_risk"": risk_factors.ownership_risk  ||  for factor, weight in self.risk_weights.items():  ||  score += risk_scores[factor] * weight  ||  async def execute_canary_test(  ||  wallet_address: str  ||  """"""Execute canary test for token safety validation.""""""  ||  gas_used=180000,  ||  ""DO NOT TRADE - Canary test failed"",  ||  # Initialize mock risk engine  ||  mock_risk_engine = MockRiskEngine()  ||  @router.post(""/assess"", response_model=RiskAssessmentResponse)  ||  async def assess_token_risk(  ||  request: RiskAssessmentRequest  ||  ) -> RiskAssessmentResponse:  ||  Perform comprehensive risk assessment on a token.  ||  Analyzes contract security, liquidity, holder distribution, honeypot risks,  ||  f""Risk assessment request: {request.token_address} on {request.chain}"",  ||  ""trade_amount_usd"": str(request.trade_amount_usd) if request.trade_amount_usd else None  ||  result = await mock_risk_engine.assess_token_risk(  ||  request.trade_amount_usd  ||  f""Risk assessment completed: {result.overall_risk.value} risk ({result.overall_score:.2f})"",  ||  ""overall_risk"": result.overall_risk.value,  ||  ""is_tradeable"": result.is_tradeable  ||  logger.error(f""Risk assessment failed: {e}"")  ||  detail=f""Risk assessment failed: {str(e)}""  ||  async def execute_canary_test(  ||  Execute canary test to validate token trading safety.  ||  Performs a small test trade to verify the token can be bought and sold  ||  ""wallet_address"": request.wallet_address  ||  result = await mock_risk_engine.execute_canary_test(  ||  request.wallet_address  ||  @router.get(""/safety-status"", response_model=SafetyStatusResponse)  ||  async def get_safety_status() -> SafetyStatusResponse:  ||  Get current safety controls status and statistics.  ||  Returns information about safety level, active protections,  ||  and recent safety activity.  ||  uptime = (time.time() - mock_risk_engine.start_time) / 3600  # hours  ||  return SafetyStatusResponse(  ||  safety_level=mock_risk_engine.safety_level,  ||  emergency_stop=mock_risk_engine.emergency_stop,  ||  blacklisted_tokens=len(mock_risk_engine.blacklisted_tokens),  ||  recent_canaries=mock_risk_engine.canary_tests,  ||  safety_checks_performed=mock_risk_engine.safety_checks,  ||  trades_blocked=mock_risk_engine.trades_blocked,  ||  Prevents the token from being traded until manually removed  ||  mock_risk_engine.blacklisted_tokens.add(token_key)  ||  mock_risk_engine.blacklisted_tokens.discard(token_key)  ||  async def test_risk_system():  ||  """"""Test endpoint for risk management system.""""""  ||  ""message"": ""Risk management system is working"",  ||  ""Comprehensive token risk assessment"",  ||  ""Dynamic safety controls"",  ||  ""risk_factors"": [  ||  ""Ownership risks""  ||  async def risk_health() -> Dict:  ||  """"""Health check for risk management service.""""""  ||  ""service"": ""Risk Management"",  ||  ""safety_level"": mock_risk_engine.safety_level.value,  ||  ""emergency_stop"": mock_risk_engine.emergency_stop,  ||  ""assessments_performed"": mock_risk_engine.safety_checks,  ||  ""canary_tests_run"": mock_risk_engine.canary_tests,  ||  ""tokens_blacklisted"": len(mock_risk_engine.blacklisted_tokens),  ||  ""risk_assessment"": ""operational"",  ||  ""safety_controls"": ""operational"",  ||  ""assess"": ""/api/v1/risk/assess"",  ||  ""canary"": ""/api/v1/risk/canary"",  ||  ""safety_status"": ""/api/v1/risk/safety-status"",  ||  ""blacklist"": ""/api/v1/risk/blacklist"""
"D:\dex\backend\app\api\safety.py","3861","from __future__ import annotations | import logging | from typing import Dict, Any, List | from fastapi import APIRouter | from pydantic import BaseModel","Minimal safety controls API router.  ||  File: backend/app/api/safety.py  ||  prefix=""/safety"",  ||  tags=[""Safety Controls""]  ||  class SafetyRule(BaseModel):  ||  """"""Safety rule definition.""""""  ||  async def test_safety() -> Dict[str, Any]:  ||  """"""Test endpoint for safety router.""""""  ||  ""service"": ""safety_api"",  ||  ""message"": ""Safety router is working!"",  ||  async def safety_health() -> Dict[str, Any]:  ||  """"""Health check for safety service.""""""  ||  ""service"": ""safety_controls"",  ||  ""risk_limits"": ""enforced""  ||  async def get_safety_rules() -> Dict[str, Any]:  ||  """"""Get active safety rules.""""""  ||  ""description"": ""Prevent trades with excessive slippage""  ||  ""message"": ""Mock safety rules""  ||  async def toggle_safety_rule(rule_id: str) -> Dict[str, Any]:  ||  """"""Toggle safety rule on/off.""""""  ||  ""gas_price"": {""enabled"": True, ""triggered"": False, ""threshold"": ""500 gwei""},  ||  ""loss_streak"": {""enabled"": True, ""triggered"": False, ""threshold"": ""5 failed trades""},  ||  logger.info(""Safety Controls API router initialized (minimal stub)"")"
"D:\dex\backend\app\api\sim.py","3962","from __future__ import annotations | import logging | from typing import Dict, Any, List | from enum import Enum | from fastapi import APIRouter | from pydantic import BaseModel","total_trades: int  ||  total_trades=25,  ||  ""description"": ""Low risk, steady gains"",  ||  ""description"": ""High risk, high reward"","
"D:\dex\backend\app\api\trades.py","6883","from __future__ import annotations | import logging | import uuid | from decimal import Decimal | from datetime import datetime, timedelta | from enum import Enum | from typing import List, Optional, Dict, Any | from fastapi import APIRouter, HTTPException, Query | from pydantic import BaseModel, Field","Minimal working trades API that loads successfully.  ||  This version provides basic trade endpoints without complex dependencies  ||  File: backend/app/api/trades.py  ||  router = APIRouter(prefix=""/trades"", tags=[""trades""])  ||  class TradeStatus(str, Enum):  ||  """"""Trade execution status.""""""  ||  class TradeType(str, Enum):  ||  """"""Types of trades supported.""""""  ||  """"""Trade execution modes.""""""  ||  class TradeRequest(BaseModel):  ||  """"""Request model for trade execution.""""""  ||  quote_id: str = Field(..., description=""Quote ID from /quotes endpoint"")  ||  amount_in: Decimal = Field(..., description=""Amount to trade"", gt=0)  ||  gas_price_gwei: Optional[Decimal] = Field(None, description=""Custom gas price"")  ||  deadline_minutes: int = Field(default=10, ge=1, le=60, description=""Trade deadline"")  ||  enable_canary: bool = Field(default=True, description=""Enable canary trade"")  ||  class TradeResponse(BaseModel):  ||  """"""Basic trade response.""""""  ||  trade_id: str  ||  status: TradeStatus  ||  active_trades: Dict[str, TradeResponse] = {}  ||  @router.post(""/execute"", response_model=TradeResponse)  ||  async def execute_trade(request: TradeRequest) -> TradeResponse:  ||  Execute a trade (minimal implementation for testing).  ||  This endpoint provides a minimal trade execution interface  ||  trade_id = f""trade_{int(datetime.utcnow().timestamp())}""  ||  # Create trade response  ||  trade_response = TradeResponse(  ||  trade_id=trade_id,  ||  status=TradeStatus.PENDING,  ||  message=f""Trade created successfully in {request.execution_mode.value} mode""  ||  # Store trade for tracking  ||  active_trades[trade_id] = trade_response  ||  f""Trade created: {trade_id}"",  ||  ""trade_id"": trade_id,  ||  return trade_response  ||  @router.get(""/{trade_id}"", response_model=TradeResponse)  ||  async def get_trade_status(trade_id: str) -> TradeResponse:  ||  """"""Get current status of a specific trade.""""""  ||  trade = active_trades.get(trade_id)  ||  if not trade:  ||  detail=f""Trade not found: {trade_id}""  ||  return trade  ||  @router.get(""/"", response_model=List[TradeResponse])  ||  async def get_trades(  ||  status: Optional[TradeStatus] = None,  ||  ) -> List[TradeResponse]:  ||  """"""Get list of trades with optional filtering.""""""  ||  trades = list(active_trades.values())  ||  trades = [t for t in trades if t.status == status]  ||  trades = [t for t in trades if t.chain == chain]  ||  trades.sort(key=lambda t: t.created_at, reverse=True)  ||  return trades[:limit]  ||  @router.post(""/{trade_id}/cancel"")  ||  async def cancel_trade(trade_id: str) -> Dict[str, Any]:  ||  """"""Cancel a pending trade.""""""  ||  trade = active_trades.get(trade_id)  ||  if not trade:  ||  detail=f""Trade not found: {trade_id}""  ||  if trade.status not in [TradeStatus.PENDING]:  ||  detail=f""Cannot cancel trade with status: {trade.status}""  ||  trade.status = TradeStatus.CANCELLED  ||  trade.updated_at = datetime.utcnow()  ||  trade.message = ""Trade cancelled by user""  ||  logger.info(f""Trade cancelled: {trade_id}"")  ||  ""trade_id"": trade_id,  ||  ""cancelled_at"": trade.updated_at,  ||  ""message"": ""Trade cancelled successfully""  ||  async def get_trades_health() -> Dict[str, Any]:  ||  """"""Get health status of trade services.""""""  ||  ""active_trades"": len(active_trades),  ||  # Clear old trades periodically (simple cleanup)  ||  def _cleanup_old_trades():  ||  """"""Remove trades older than 24 hours.""""""  ||  trade_id for trade_id, trade in active_trades.items()  ||  if trade.created_at < cutoff  ||  for trade_id in to_remove:  ||  del active_trades[trade_id]  ||  logger.info(f""Cleaned up {len(to_remove)} old trades"")"
"D:\dex\backend\app\api\trades_enhanced.py","15172","from __future__ import annotations | import logging | import uuid | from decimal import Decimal | from datetime import datetime, timedelta | from enum import Enum | from typing import List, Optional, Dict, Any | from fastapi import APIRouter, HTTPException, Query, Depends | from pydantic import BaseModel, Field | from ..trading.executor import TradeExecutor, ExecutionMode, execute_live_trade, execute_paper_trade | from ..trading.models import TradeRequest as CoreTradeRequest, TradeResult, TradeStatus, TradeType |     from unittest.mock import AsyncMock |     from unittest.mock import AsyncMock","Enhanced trades API with dual-mode execution support.  ||  Extends your existing trades API to support both live and paper trading.  ||  File: backend/app/api/trades_enhanced.py  ||  from ..trading.executor import TradeExecutor, ExecutionMode, execute_live_trade, execute_paper_trade  ||  from ..trading.models import TradeRequest as CoreTradeRequest, TradeResult, TradeStatus, TradeType  ||  router = APIRouter(prefix=""/trades"", tags=[""Enhanced Trades""])  ||  class EnhancedTradeRequest(BaseModel):  ||  """"""Enhanced trade request with execution mode selection.""""""  ||  quote_id: str = Field(..., description=""Quote ID from /quotes endpoint"")  ||  amount_in: Decimal = Field(..., description=""Amount to trade"", gt=0)  ||  gas_price_gwei: Optional[Decimal] = Field(None, description=""Custom gas price"")  ||  deadline_minutes: int = Field(default=10, ge=1, le=60, description=""Trade deadline"")  ||  enable_canary: bool = Field(default=True, description=""Enable canary trade"")  ||  class EnhancedTradeResponse(BaseModel):  ||  """"""Enhanced trade response with execution mode tracking.""""""  ||  trade_id: str  ||  status: TradeStatus  ||  gas_used: Optional[str] = None  ||  paper_trade_metrics: Optional[Dict[str, Any]] = None  ||  total_paper_trades: int  ||  successful_paper_trades: int  ||  enhanced_trades: Dict[str, EnhancedTradeResponse] = {}  ||  async def get_trade_executor() -> TradeExecutor:  ||  Dependency injection for trade executor.  ||  mock_nonce_manager = AsyncMock()  ||  mock_ledger_writer = AsyncMock()  ||  return TradeExecutor(  ||  nonce_manager=mock_nonce_manager,  ||  ledger_writer=mock_ledger_writer,  ||  @router.post(""/execute-enhanced"", response_model=EnhancedTradeResponse)  ||  async def execute_enhanced_trade(  ||  request: EnhancedTradeRequest,  ||  executor: TradeExecutor = Depends(get_trade_executor),  ||  ) -> EnhancedTradeResponse:  ||  Execute trade with dual-mode support (live or paper trading).  ||  This endpoint demonstrates the enhanced trade execution with:  ||  trade_id = f""trade_{int(datetime.utcnow().timestamp())}_{uuid.uuid4().hex[:8]}""  ||  f""Executing enhanced trade: {trade_id} (mode: {request.execution_mode.value})"",  ||  ""trade_id"": trade_id,  ||  # Convert to core trade request format  ||  core_request = CoreTradeRequest(  ||  wallet_address=""0x1234567890123456789012345678901234567890"",  # Mock wallet  ||  trade_type=TradeType.MANUAL,  ||  # Execute based on mode  ||  result = await execute_paper_trade(  ||  result = await execute_live_trade(  ||  response = EnhancedTradeResponse(  ||  trade_id=trade_id,  ||  gas_used=result.gas_used,  ||  paper_trade_metrics=paper_metrics,  ||  enhanced_trades[trade_id] = response  ||  f""Enhanced trade completed: {trade_id} - {result.status.value}"",  ||  ""trade_id"": trade_id,  ||  logger.error(f""Enhanced trade execution failed: {trade_id}: {e}"")  ||  error_response = EnhancedTradeResponse(  ||  trade_id=trade_id,  ||  status=TradeStatus.FAILED,  ||  message=f""Trade execution failed: {str(e)}"",  ||  enhanced_trades[trade_id] = error_response  ||  @router.get(""/{trade_id}/enhanced"", response_model=EnhancedTradeResponse)  ||  async def get_enhanced_trade_status(trade_id: str) -> EnhancedTradeResponse:  ||  """"""Get detailed status of an enhanced trade.""""""  ||  trade = enhanced_trades.get(trade_id)  ||  if not trade:  ||  detail=f""Enhanced trade not found: {trade_id}""  ||  return trade  ||  @router.get(""/enhanced"", response_model=List[EnhancedTradeResponse])  ||  async def get_enhanced_trades(  ||  status: Optional[TradeStatus] = None,  ||  ) -> List[EnhancedTradeResponse]:  ||  """"""Get list of enhanced trades with filtering.""""""  ||  trades = list(enhanced_trades.values())  ||  trades = [t for t in trades if t.execution_mode == execution_mode.value]  ||  trades = [t for t in trades if t.status == status]  ||  trades = [t for t in trades if t.chain == chain]  ||  trades.sort(key=lambda t: t.created_at, reverse=True)  ||  return trades[:limit]  ||  executor: TradeExecutor = Depends(get_trade_executor)  ||  total_paper_trades=metrics[""total_paper_trades""],  ||  successful_paper_trades=metrics[""successful_paper_trades""],  ||  executor: TradeExecutor = Depends(get_trade_executor),  ||  sample_trade: EnhancedTradeRequest,  ||  executor: TradeExecutor = Depends(get_trade_executor),  ||  Executes the same trade in both modes for comparison.  ||  # Execute paper trade  ||  logger.info(""Demo: Executing paper trade..."")  ||  sample_trade.execution_mode = ExecutionModeChoice.PAPER  ||  paper_response = await execute_enhanced_trade(sample_trade, executor, chain_clients)  ||  results[""paper_trade""] = paper_response  ||  # Execute live trade (simulation for demo)  ||  logger.info(""Demo: Executing live trade (simulated)..."")  ||  sample_trade.execution_mode = ExecutionModeChoice.LIVE  ||  live_response = await execute_enhanced_trade(sample_trade, executor, chain_clients)  ||  results[""live_trade""] = live_response  ||  ""both_completed"": paper_response.status != TradeStatus.FAILED and live_response.status != TradeStatus.FAILED,  ||  def _create_success_message(result: TradeResult, mode: ExecutionModeChoice) -> str:  ||  if result.status == TradeStatus.CONFIRMED:  ||  return f""Paper trade executed successfully with realistic simulation (no real funds used)""  ||  return f""Live trade executed successfully on blockchain""  ||  elif result.status == TradeStatus.FAILED:  ||  return f""Trade failed: {result.error_message or 'Unknown error'}""  ||  elif result.status == TradeStatus.REVERTED:  ||  return f""Trade reverted: {result.error_message or 'Transaction reverted'}""  ||  return f""Trade status: {result.status.value}"""
"D:\dex\backend\app\api\validation_enhancements.py","16464","from __future__ import annotations | import re | from decimal import Decimal, InvalidOperation | from typing import Any, Dict, List, Optional, Union | from fastapi import HTTPException, status | from pydantic import BaseModel, Field, validator","SUPPORTED_TRADE_TYPES = {""buy"", ""sell"", ""swap""}  ||  def validate_gas_price(cls, gas_price: Union[str, float, int], chain: str) -> int:  ||  """"""Validate gas price in Gwei.""""""  ||  if gas_price is None:  ||  raise ValidationError(""gas_price"", ""Gas price is required"")  ||  gwei_value = int(float(gas_price))  ||  # Chain-specific gas price ranges  ||  gas_ranges = {  ||  min_gas, max_gas = gas_ranges.get(chain, (1, 1000))  ||  if gwei_value < min_gas:  ||  raise ValidationError(""gas_price"", f""Gas price too low for {chain} (minimum: {min_gas} Gwei)"", gwei_value)  ||  if gwei_value > max_gas:  ||  raise ValidationError(""gas_price"", f""Gas price too high for {chain} (maximum: {max_gas} Gwei)"", gwei_value)  ||  raise ValidationError(""gas_price"", f""Invalid gas price format: {str(e)}"", gas_price)  ||  gas_price: Optional[int] = Field(None, ge=1, le=1000, description=""Gas price in Gwei"")  ||  @validator('gas_price')  ||  def validate_gas_price(cls, v, values):  ||  return TradingParameterValidator.validate_gas_price(v, chain)  ||  class ValidatedWalletRequest(BaseModel):  ||  """"""Validated wallet operation request.""""""  ||  wallet_address: str = Field(..., description=""Wallet address"")  ||  @validator('wallet_address')  ||  def validate_wallet_address(cls, v, values):  ||  class ValidatedQuoteRequest(BaseModel):  ||  """"""Validated quote request.""""""  ||  if key == ""wallet_address"":  ||  elif key == ""gas_price"":  ||  validated[key] = TradingParameterValidator.validate_gas_price(value, chain)  ||  'ValidatedWalletRequest',  ||  'ValidatedQuoteRequest',"
"D:\dex\backend\app\api\wallet.py","33987","from __future__ import annotations | import json | import logging | import secrets | from datetime import datetime, timezone | from decimal import Decimal | from pathlib import Path | from typing import Dict, List, Optional, Any | from eth_account import Account | from fastapi import APIRouter, HTTPException, Body, Header, BackgroundTasks | from pydantic import BaseModel, Field, validator |         from time import time |         import random |         import string |         import uuid |         import asyncio","DEX Sniper Pro - Wallet Management API Endpoints (EVM-focused).  ||  Enhanced version with wallet registration for frontend integration.  ||  router = APIRouter(prefix=""/wallets"", tags=[""Wallet Management""])  ||  # Simple in-memory wallet storage (replace with proper registry when Solana is installed)  ||  WALLET_STORAGE = {}  ||  REGISTERED_WALLETS = {}  # New storage for frontend wallet registrations  ||  KEYSTORE_DIR = Path(""data/wallets"")  ||  logger.info(""🔧 Wallet router created with prefix: /wallets"")  ||  class CreateWalletRequest(BaseModel):  ||  """"""Request model for wallet creation.""""""  ||  passphrase: str = Field(..., description=""Encryption passphrase for the wallet"")  ||  label: str = Field(default=""hot_wallet"", description=""Human-readable wallet label"")  ||  class WalletBalanceRequest(BaseModel):  ||  """"""Request model for checking wallet balance.""""""  ||  address: str = Field(..., description=""Wallet address"")  ||  # NEW: Frontend wallet registration models  ||  class WalletRegistrationRequest(BaseModel):  ||  """"""Request model for frontend wallet registration.""""""  ||  address: str = Field(..., description=""Wallet address"")  ||  wallet_type: str = Field(..., description=""Type of wallet (metamask, phantom, etc.)"")  ||  """"""Validate wallet address format with comprehensive error handling.""""""  ||  @validator('wallet_type')  ||  def validate_wallet_type(cls, v):  ||  """"""Validate wallet type with comprehensive error handling.""""""  ||  raise ValueError('Wallet type must be a non-empty string')  ||  valid_types = ['metamask', 'phantom', 'walletconnect', 'coinbase', 'trust', 'injected']  ||  raise ValueError(f'Unsupported wallet type. Supported: {"", "".join(valid_types)}')  ||  logger.error(f""Wallet type validation failed: {e}"", extra={  ||  'provided_wallet_type': str(v) if v else 'None',  ||  'valid_types': ['metamask', 'phantom', 'walletconnect', 'coinbase', 'trust', 'injected']  ||  raise ValueError(f""Invalid wallet type: {str(e)}"")  ||  class WalletRegistrationResponse(BaseModel):  ||  """"""Response model for wallet registration.""""""  ||  wallet_id: Optional[str] = Field(None, description=""Internal wallet ID"")  ||  return f""wallet_{timestamp}_{random_suffix}""  ||  return f""wallet_{str(uuid.uuid4())[:8]}""  ||  def log_wallet_operation(level: str, message: str, **kwargs) -> str:  ||  """"""Log wallet operation with structured data and comprehensive error handling.""""""  ||  'component': 'wallet_api',  ||  'module': 'wallet.py',  ||  async def log_registration_metrics(trace_id: str, wallet_type: str, chain: str) -> None:  ||  """"""Background task to log wallet registration metrics with error handling.""""""  ||  log_wallet_operation('info', 'Wallet registration metrics logged',  ||  metric_type='wallet_registration',  ||  wallet_type=wallet_type,  ||  log_wallet_operation('error', 'Failed to log registration metrics',  ||  async def test_wallet_router():  ||  """"""Simple test endpoint to verify wallet router is working.""""""  ||  log_wallet_operation('info', 'Wallet test endpoint accessed', trace_id=trace_id)  ||  ""message"": ""Wallet router is working!"",  ||  ""router_prefix"": ""/wallets"",  ||  log_wallet_operation('error', 'Test endpoint failed',  ||  async def wallet_root():  ||  """"""Root wallet endpoint with enhanced error handling.""""""  ||  log_wallet_operation('info', 'Wallet root endpoint accessed', trace_id=trace_id)  ||  ""service"": ""Wallet Management"",  ||  ""GET /wallets/test"",  ||  ""GET /wallets/list"",  ||  ""POST /wallets/create"",  ||  ""POST /wallets/register"",  # NEW  ||  ""POST /wallets/balance"",  ||  ""POST /wallets/load""  ||  ""supported_wallets"": [""metamask"", ""phantom"", ""walletconnect"", ""coinbase"", ""trust"", ""injected""],  ||  log_wallet_operation('error', 'Root endpoint failed',  ||  # NEW: Frontend wallet registration endpoint  ||  @router.post(""/register"", response_model=WalletRegistrationResponse)  ||  async def register_wallet(  ||  request: WalletRegistrationRequest,  ||  ) -> WalletRegistrationResponse:  ||  Register a wallet with the backend system for frontend integration.  ||  1. Validates wallet address and metadata  ||  2. Stores wallet information for tracking  ||  request: Wallet registration request data  ||  WalletRegistrationResponse with success status and trace ID  ||  log_wallet_operation('info', 'Wallet registration request received',  ||  wallet_address=f""{request.address[:6]}...{request.address[-4:]}"",  ||  wallet_type=request.wallet_type,  ||  # Generate unique wallet ID  ||  wallet_key = f""{request.address}_{request.chain}""  ||  wallet_id = f""wallet_{hash(wallet_key) % 1000000:06d}""  ||  'wallet_id': wallet_id,  ||  'wallet_type': request.wallet_type,  ||  REGISTERED_WALLETS[wallet_key] = registration_data  ||  wallet_type=request.wallet_type,  ||  response = WalletRegistrationResponse(  ||  message=""Wallet registered successfully"",  ||  wallet_id=wallet_id,  ||  log_wallet_operation('info', 'Wallet registration completed successfully',  ||  wallet_id=wallet_id,  ||  wallet_address=f""{request.address[:6]}...{request.address[-4:]}"",  ||  total_registered=len(REGISTERED_WALLETS)  ||  log_wallet_operation('warn', 'Wallet registration validation failed',  ||  wallet_address=request.address[:10] if hasattr(request, 'address') and request.address else 'invalid',  ||  log_wallet_operation('error', 'Wallet registration failed with unexpected error',  ||  ""message"": ""Internal server error during wallet registration"",  ||  async def create_wallet(request: CreateWalletRequest):  ||  """"""Create a new EVM wallet with enhanced error handling.""""""  ||  log_wallet_operation('info', 'Wallet creation request received',  ||  wallet_file = KEYSTORE_DIR / f""{request.chain}_{request.label}_{account.address[:8]}.json""  ||  with open(wallet_file, 'w') as f:  ||  log_wallet_operation('error', 'Failed to save keystore file',  ||  file_path=str(wallet_file)  ||  raise HTTPException(status_code=500, detail=""Failed to save wallet keystore"")  ||  wallet_key = f""{request.chain}:{account.address}""  ||  WALLET_STORAGE[wallet_key] = {  ||  ""keystore_path"": str(wallet_file),  ||  log_wallet_operation('info', 'Wallet created successfully',  ||  wallet_address=f""{account.address[:10]}..."",  ||  ""keystore_path"": str(wallet_file),  ||  ""created_at"": WALLET_STORAGE[wallet_key][""created_at""],  ||  log_wallet_operation('error', 'Wallet creation failed',  ||  ""message"": f""Failed to create wallet: {str(e)}"",  ||  async def list_wallets():  ||  """"""List all wallets with enhanced error handling.""""""  ||  log_wallet_operation('info', 'Wallet list request received', trace_id=trace_id)  ||  wallets = []  ||  for wallet_info in WALLET_STORAGE.values():  ||  wallets.append(wallet_info)  ||  wallet_key = f""{chain}:{address}""  ||  if wallet_key not in WALLET_STORAGE:  ||  wallets.append({  ||  log_wallet_operation('warn', 'Failed to read keystore file',  ||  log_wallet_operation('warn', 'Failed to scan keystore directory',  ||  log_wallet_operation('info', 'Wallet list completed',  ||  wallet_count=len(wallets),  ||  ""wallets"": wallets,  ||  ""total_count"": len(wallets),  ||  ""memory_storage_count"": len(WALLET_STORAGE),  ||  ""registered_wallets_count"": len(REGISTERED_WALLETS),  ||  ""storage_keys"": list(WALLET_STORAGE.keys()),  ||  log_wallet_operation('error', 'Wallet list failed',  ||  ""message"": ""Failed to list wallets"",  ||  async def check_balance(request: WalletBalanceRequest):  ||  """"""Check wallet balance with enhanced error handling.""""""  ||  log_wallet_operation('info', 'Balance check request received',  ||  wallet_address=f""{request.address[:6]}...{request.address[-4:]}"",  ||  raise ValueError(""Invalid wallet address format"")  ||  log_wallet_operation('info', 'Balance check completed',  ||  wallet_address=f""{request.address[:6]}...{request.address[-4:]}"",  ||  log_wallet_operation('warn', 'Balance check validation failed',  ||  wallet_address=request.address[:10] if hasattr(request, 'address') else 'invalid'  ||  log_wallet_operation('error', 'Balance check failed',  ||  async def load_wallet(keystore_path: str = Body(...), passphrase: str = Body(...)):  ||  """"""Load a wallet from keystore with enhanced error handling.""""""  ||  log_wallet_operation('info', 'Wallet load request received',  ||  log_wallet_operation('error', 'Invalid keystore file format',  ||  log_wallet_operation('warn', 'Invalid passphrase for keystore',  ||  wallet_key = f""{chain}:{account.address}""  ||  WALLET_STORAGE[wallet_key] = {  ||  log_wallet_operation('info', 'Wallet loaded successfully',  ||  wallet_address=f""{account.address[:10]}..."",  ||  log_wallet_operation('error', 'Wallet load failed',  ||  ""message"": ""Failed to load wallet"",  ||  logger.info(""🔧 Enhanced wallet router endpoints registered:"")  ||  logger.info(f""🔧 Total wallet endpoints: {len(router.routes)}"")  ||  logger.info(f""🔧 Storage initialized: WALLET_STORAGE and REGISTERED_WALLETS"")  ||  """"""Check if wallet connection is still active.""""""  ||  log_wallet_operation('info', 'Wallet connection check',  ||  wallet_address=f""{address[:6]}...{address[-4:]}"",  ||  # Simple connection check - verify wallet is in registry  ||  wallet_key = f""{address}_{chain}""  ||  is_connected = wallet_key in REGISTERED_WALLETS  ||  log_wallet_operation('error', 'Connection check failed',  ||  @router.get(""/funding/wallet-status"")  ||  async def get_wallet_funding_status(  ||  """"""Get wallet funding and approval status for autotrade interface.""""""  ||  log_wallet_operation('info', 'Wallet funding status check',  ||  # Mock wallet funding status - replace with real logic  ||  ""wallet_funded"": True,  ||  ""approvals"": {  ||  ""approval_count"": 2,  ||  ""needs_approvals"": True,  ||  log_wallet_operation('info', 'Wallet funding status completed',  ||  wallet_funded=funding_status[""wallet_funded""],  ||  approval_count=funding_status[""approval_count""],  ||  log_wallet_operation('error', 'Wallet funding status check failed',  ||  ""message"": ""Failed to check wallet funding status"","
"D:\dex\backend\app\api\wallets.py","21280","import asyncio | import logging | from datetime import datetime, timezone | from typing import Dict, List, Optional, Any | from decimal import Decimal | from fastapi import APIRouter, HTTPException, Header, Request, Depends, BackgroundTasks | from pydantic import BaseModel, Field, validator | import httpx |     from time import time |     import random |     import string |     import hashlib","Wallet API Router for DEX Sniper Pro Backend  ||  Handles wallet registration, balance fetching, and wallet management operations.  ||  Provides endpoints for frontend wallet service integration.  ||  File: backend/app/api/wallets.py  ||  router = APIRouter(prefix=""/api/v1/wallets"", tags=[""wallets""])  ||  class WalletRegistrationRequest(BaseModel):  ||  """"""Request model for wallet registration""""""  ||  address: str = Field(..., description=""Wallet address"")  ||  wallet_type: str = Field(..., description=""Type of wallet (metamask, phantom, etc.)"")  ||  """"""Validate wallet address format""""""  ||  @validator('wallet_type')  ||  def validate_wallet_type(cls, v):  ||  """"""Validate wallet type""""""  ||  raise ValueError('Wallet type must be a non-empty string')  ||  valid_types = ['metamask', 'phantom', 'walletconnect', 'coinbase', 'trust', 'injected']  ||  raise ValueError(f'Unsupported wallet type. Supported: {"", "".join(valid_types)}')  ||  class WalletUnregistrationRequest(BaseModel):  ||  """"""Request model for wallet unregistration""""""  ||  address: str = Field(..., description=""Wallet address to unregister"")  ||  address: str = Field(..., description=""Wallet address"")  ||  class WalletRegistrationResponse(BaseModel):  ||  """"""Response model for wallet registration""""""  ||  wallet_id: Optional[str] = Field(None, description=""Internal wallet ID"")  ||  balances: Optional[Dict[str, Any]] = Field(None, description=""Wallet balances"")  ||  registered_wallets: Dict[str, Dict[str, Any]] = {}  ||  wallet_balances: Dict[str, Dict[str, Any]] = {}  ||  return f""wallet_api_{timestamp}_{random_suffix}""  ||  def log_wallet_operation(level: str, message: str, **kwargs) -> str:  ||  """"""Log wallet operation with structured data""""""  ||  'component': 'wallet_api',  ||  @router.post(""/register"", response_model=WalletRegistrationResponse)  ||  async def register_wallet(  ||  request: WalletRegistrationRequest,  ||  ) -> WalletRegistrationResponse:  ||  Register a wallet with the backend system  ||  1. Validates wallet address and metadata  ||  2. Stores wallet information for tracking  ||  log_wallet_operation('info', 'Wallet registration request received',  ||  wallet_address=f""{request.address[:6]}...{request.address[-4:]}"",  ||  wallet_type=request.wallet_type,  ||  # Generate wallet ID  ||  wallet_key = f""{request.address}_{request.chain}""  ||  wallet_id = f""wallet_{hash(wallet_key) % 1000000:06d}""  ||  # Prepare wallet registration data  ||  'wallet_id': wallet_id,  ||  'wallet_type': request.wallet_type,  ||  registered_wallets[wallet_key] = registration_data  ||  log_wallet_metrics,  ||  wallet_type=request.wallet_type,  ||  response = WalletRegistrationResponse(  ||  message=""Wallet registered successfully"",  ||  wallet_id=wallet_id,  ||  log_wallet_operation('info', 'Wallet registration completed successfully',  ||  wallet_id=wallet_id,  ||  wallet_address=f""{request.address[:6]}...{request.address[-4:]}"",  ||  total_registered_wallets=len(registered_wallets)  ||  log_wallet_operation('warn', 'Wallet registration validation failed',  ||  wallet_address=request.address[:10] if request.address else 'invalid'  ||  log_wallet_operation('error', 'Wallet registration failed with unexpected error',  ||  ""message"": ""Internal server error during wallet registration"",  ||  async def unregister_wallet(  ||  request: WalletUnregistrationRequest,  ||  Unregister a wallet from the backend system  ||  log_wallet_operation('info', 'Wallet unregistration request received',  ||  wallet_address=f""{request.address[:6]}...{request.address[-4:]}"",  ||  # Find and remove wallet registration  ||  for key, data in registered_wallets.items():  ||  del registered_wallets[key]  ||  balance_keys_to_remove = [k for k in wallet_balances.keys() if request.address in k]  ||  del wallet_balances[key]  ||  log_wallet_operation('info', 'Wallet unregistration completed',  ||  wallet_address=f""{request.address[:6]}...{request.address[-4:]}"",  ||  ""message"": f""Wallet unregistered successfully ({removed_count} registrations removed)"",  ||  log_wallet_operation('error', 'Wallet unregistration failed',  ||  ""message"": ""Internal server error during wallet unregistration"",  ||  async def get_wallet_balances(  ||  Get wallet balances for native and token assets  ||  log_wallet_operation('info', 'Balance request received',  ||  wallet_address=f""{request.address[:6]}...{request.address[-4:]}"",  ||  raise ValueError(""Invalid wallet address"")  ||  if balance_key in wallet_balances:  ||  cached_data = wallet_balances[balance_key]  ||  log_wallet_operation('debug', 'Returning cached balance data',  ||  wallet_balances[balance_key] = {  ||  log_wallet_operation('info', 'Balance request completed',  ||  wallet_address=f""{request.address[:6]}...{request.address[-4:]}"",  ||  log_wallet_operation('warn', 'Balance request validation failed',  ||  wallet_address=request.address[:10] if request.address else 'invalid'  ||  log_wallet_operation('error', 'Balance request failed',  ||  async def get_wallet_status(  ||  """"""Get wallet service status and statistics""""""  ||  total_wallets = len(registered_wallets)  ||  wallet_types = {}  ||  for wallet_data in registered_wallets.values():  ||  wallet_type = wallet_data.get('wallet_type', 'unknown')  ||  chain = wallet_data.get('chain', 'unknown')  ||  wallet_types[wallet_type] = wallet_types.get(wallet_type, 0) + 1  ||  ""service"": ""wallet_api"",  ||  ""total_registered_wallets"": total_wallets,  ||  ""wallet_types"": wallet_types,  ||  ""cached_balances"": len(wallet_balances)  ||  log_wallet_operation('debug', 'Wallet status requested',  ||  total_wallets=total_wallets  ||  log_wallet_operation('error', 'Status request failed',  ||  ""message"": ""Failed to get wallet service status"",  ||  async def log_wallet_metrics(trace_id: str, wallet_type: str, chain: str) -> None:  ||  """"""Background task to log wallet registration metrics""""""  ||  log_wallet_operation('debug', 'Wallet metrics logged',  ||  wallet_type=wallet_type,  ||  log_wallet_operation('error', 'Metrics logging failed',"
"D:\dex\backend\app\api\wallet_funding.py","17705","from __future__ import annotations | import logging | from datetime import datetime, timezone, timedelta | from decimal import Decimal | from typing import Dict, List, Optional, Any | import uuid | from fastapi import APIRouter, HTTPException, Header, status | from pydantic import BaseModel, Field, validator","DEX Sniper Pro - Wallet Funding API Endpoints.  ||  Secure wallet approval and spending limit management for autotrade operations.  ||  File: backend/app/api/wallet_funding.py  ||  router = APIRouter(prefix=""/wallet-funding"", tags=[""Wallet Funding""])  ||  class WalletApprovalRequest(BaseModel):  ||  """"""Request to approve wallet for autotrade operations.""""""  ||  wallet_address: str = Field(..., description=""Wallet address to approve"")  ||  per_trade_limit_usd: Decimal = Field(..., description=""Maximum per-trade limit in USD"")  ||  approval_duration_hours: int = Field(default=24, description=""Approval duration in hours"")  ||  @validator('wallet_address')  ||  def validate_wallet_address(cls, v):  ||  """"""Validate wallet address format.""""""  ||  raise ValueError('Invalid wallet address')  ||  @validator('daily_limit_usd', 'per_trade_limit_usd')  ||  @validator('approval_duration_hours')  ||  """"""Validate approval duration.""""""  ||  raise ValueError('Approval duration must be between 1 and 168 hours')  ||  class ApprovalConfirmationRequest(BaseModel):  ||  """"""Request to confirm or reject wallet approval.""""""  ||  confirmed: bool = Field(..., description=""Whether user confirms the approval"")  ||  class WalletApprovalResponse(BaseModel):  ||  """"""Response for wallet approval request.""""""  ||  approval_id: str  ||  wallet_address: str  ||  per_trade_limit_usd: str  ||  approval_duration_hours: int  ||  class WalletStatusResponse(BaseModel):  ||  """"""Response showing user's wallet funding status.""""""  ||  wallet_funded: bool  ||  approvals: Dict[str, Dict[str, Any]]  ||  approval_count: int  ||  needs_approvals: bool  ||  per_trade_limit: Optional[str] = None  ||  APPROVED_WALLETS: Dict[str, Dict[str, Any]] = {}  ||  PENDING_APPROVALS: Dict[str, Dict[str, Any]] = {}  ||  @router.get(""/wallet-status"", response_model=WalletStatusResponse)  ||  async def get_wallet_status(  ||  Simple wallet funding status endpoint for frontend compatibility.  ||  logger.info(f""Wallet status requested with trace_id: {x_trace_id}"")  ||  # Return mock data that matches what WalletApproval.jsx expects  ||  return WalletStatusResponse(  ||  wallet_funded=True,  ||  approvals={  ||  approval_count=2,  ||  needs_approvals=True,  ||  logger.error(f""Simple wallet status failed: {e}"")  ||  detail=""Failed to get wallet status""  ||  @router.post(""/approve-wallet"", response_model=WalletApprovalResponse)  ||  async def request_wallet_approval(  ||  request: WalletApprovalRequest,  ||  ) -> WalletApprovalResponse:  ||  Request approval for a wallet to be used in autotrade operations.  ||  Creates a pending approval for demo purposes.  ||  f""Wallet approval requested"",  ||  'wallet_address': request.wallet_address,  ||  # Generate simple approval ID  ||  approval_id = str(uuid.uuid4())[:8]  ||  # Store in pending approvals with float conversion for limits  ||  PENDING_APPROVALS[approval_id] = {  ||  'wallet_address': request.wallet_address,  ||  'per_trade_limit_usd': float(request.per_trade_limit_usd),  ||  'approval_duration_hours': request.approval_duration_hours,  ||  return WalletApprovalResponse(  ||  approval_id=approval_id,  ||  wallet_address=request.wallet_address,  ||  per_trade_limit_usd=str(request.per_trade_limit_usd),  ||  approval_duration_hours=request.approval_duration_hours,  ||  logger.error(f""Failed to create wallet approval request: {e}"")  ||  detail=f""Failed to create approval request: {str(e)}""  ||  @router.post(""/confirm-approval/{approval_id}"")  ||  async def confirm_wallet_approval(  ||  approval_id: str,  ||  request: ApprovalConfirmationRequest,  ||  Confirm or reject a pending wallet approval.  ||  Returns complete approval details including spending limits.  ||  f""Wallet approval confirmation"",  ||  'approval_id': approval_id,  ||  if approval_id not in PENDING_APPROVALS:  ||  detail=""Approval request not found or expired""  ||  approval = PENDING_APPROVALS[approval_id]  ||  # Update approval status  ||  approval['status'] = status_message  ||  approval['confirmed_at'] = datetime.now(timezone.utc)  ||  ""daily_limit_usd"": approval['daily_limit_usd'],  ||  ""per_trade_limit_usd"": approval['per_trade_limit_usd'],  ||  ""approval_expires_at"": (  ||  timedelta(hours=approval['approval_duration_hours'])  ||  # Store approved wallet with spending limits  ||  chain = approval['chain']  ||  if chain not in APPROVED_WALLETS:  ||  APPROVED_WALLETS[chain] = {}  ||  APPROVED_WALLETS[chain][approval['wallet_address']] = {  ||  **approval,  ||  f""Wallet approved with spending limits"",  ||  'approval_id': approval_id,  ||  'wallet_address': approval['wallet_address'],  ||  'per_trade_limit': spending_limits['per_trade_limit_usd']  ||  # Remove from pending approvals after processing  ||  PENDING_APPROVALS.pop(approval_id)  ||  # Return complete approval response with spending limits  ||  ""approval_id"": approval_id,  ||  ""confirmed_at"": approval['confirmed_at'].isoformat(),  ||  ""message"": f""Wallet approval {status_message} successfully"",  ||  ""wallet_address"": approval['wallet_address'],  ||  ""chain"": approval['chain'],  ||  ""approval_duration_hours"": approval['approval_duration_hours']  ||  logger.error(f""Failed to confirm wallet approval: {e}"")  ||  detail=f""Failed to confirm approval: {str(e)}""  ||  trade_amount_usd: Decimal,  ||  Check if a proposed trade amount is within approved spending limits.  ||  Validates against both per-trade and daily limits.  ||  'trade_amount': str(trade_amount_usd)  ||  # Check if chain has approved wallets  ||  if chain.lower() not in APPROVED_WALLETS or not APPROVED_WALLETS[chain.lower()]:  ||  reason=""No approved wallet for this chain"",  ||  details=""Please approve a wallet for autotrade operations first""  ||  # Get first approved wallet for the chain  ||  wallet_data = list(APPROVED_WALLETS[chain.lower()].values())[0]  ||  spending_limits = wallet_data.get('spending_limits', {})  ||  per_trade_limit = Decimal(str(spending_limits.get('per_trade_limit_usd', 1000)))  ||  # Check per-trade limit  ||  if trade_amount_usd > per_trade_limit:  ||  reason=""Exceeds per-trade limit"",  ||  details=f""Trade amount ${trade_amount_usd} exceeds limit of ${per_trade_limit}"",  ||  per_trade_limit=str(per_trade_limit),  ||  if daily_spent + trade_amount_usd > daily_limit:  ||  details=f""Trade would exceed daily limit of ${daily_limit}"",  ||  per_trade_limit=str(per_trade_limit),  ||  # Trade is within limits  ||  per_trade_limit=str(per_trade_limit),  ||  @router.delete(""/revoke-approval/{chain}"")  ||  async def revoke_wallet_approval(  ||  Revoke wallet approval for a specific chain.  ||  Removes all approved wallets for the specified chain.  ||  if chain.lower() in APPROVED_WALLETS:  ||  del APPROVED_WALLETS[chain.lower()]  ||  f""Wallet approval revoked"",  ||  ""message"": f""Wallet approval revoked for {chain}""  ||  detail=f""No approved wallet found for chain {chain}""  ||  logger.error(f""Failed to revoke wallet approval: {e}"")  ||  detail=f""Failed to revoke approval: {str(e)}""  ||  @router.get(""/approved-wallet/{chain}"")  ||  async def get_approved_wallet(  ||  Get the approved wallet address and spending limits for a specific chain.  ||  Returns the first approved wallet if multiple exist.  ||  if chain.lower() in APPROVED_WALLETS and APPROVED_WALLETS[chain.lower()]:  ||  # Return first approved wallet for the chain  ||  wallet_address = list(APPROVED_WALLETS[chain.lower()].keys())[0]  ||  wallet_data = APPROVED_WALLETS[chain.lower()][wallet_address]  ||  ""wallet_address"": wallet_address,  ||  ""spending_limits"": wallet_data.get('spending_limits'),  ||  ""approved_at"": wallet_data.get('confirmed_at', datetime.now(timezone.utc)).isoformat()  ||  detail=f""No approved wallet found for chain {chain}""  ||  logger.error(f""Failed to get approved wallet: {e}"")  ||  detail=f""Failed to get approved wallet: {str(e)}""  ||  ""Wallet funding API router initialized - %d endpoints registered"","
"D:\dex\backend\app\api\websocket.py","30609","from __future__ import annotations | import logging | import uuid | from typing import Optional | from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Query, Path | from fastapi.responses import HTMLResponse | from ..ws.hub import ws_hub, Channel, MessageType, WebSocketMessage","WebSocket API routes for DEX Sniper Pro.  ||  Provides clean, unified WebSocket endpoints replacing all existing WebSocket routes.  ||  File: backend/app/api/websocket.py  ||  from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Query, Path  ||  from ..ws.hub import ws_hub, Channel, MessageType, WebSocketMessage  ||  router = APIRouter(prefix=""/ws"", tags=[""websocket""])  ||  @router.websocket(""/{client_id}"")  ||  async def websocket_endpoint(  ||  websocket: WebSocket,  ||  Main WebSocket endpoint for DEX Sniper Pro.  ||  Handles all WebSocket connections through a single, clean endpoint.  ||  websocket: WebSocket connection  ||  # Accept the WebSocket connection first  ||  await websocket.accept()  ||  logger.info(f""WebSocket connection attempt: {client_id}"")  ||  connected = await ws_hub.connect_client(client_id, websocket)  ||  logger.error(f""Failed to connect WebSocket client: {client_id}"")  ||  await websocket.close(code=1011, reason=""Server error: failed to register client"")  ||  logger.info(f""WebSocket client {client_id} connected successfully"")  ||  data = await websocket.receive_text()  ||  except WebSocketDisconnect:  ||  logger.info(f""WebSocket client {client_id} disconnected normally"")  ||  error_message = WebSocketMessage(  ||  await websocket.send_text(error_message.to_json())  ||  except WebSocketDisconnect:  ||  logger.info(f""WebSocket client {client_id} disconnected during setup"")  ||  logger.error(f""Critical WebSocket error for client {client_id}: {e}"", exc_info=True)  ||  logger.debug(f""WebSocket client {client_id} cleanup completed"")  ||  logger.error(f""Error during WebSocket cleanup for {client_id}: {cleanup_error}"")  ||  async def websocket_status():  ||  Get WebSocket hub status and connection statistics.  ||  ""legacy"": ""/ws/autotrade"",  ||  ""description"": ""Single WebSocket endpoint with channel subscriptions""  ||  logger.error(f""Error getting WebSocket status: {e}"")  ||  async def websocket_test_page():  ||  Production-ready WebSocket test page with proper heartbeat handling.  ||  HTML page with enhanced WebSocket test client  ||  <title>DEX Sniper Pro - WebSocket Test Client</title>  ||  <h1>DEX Sniper Pro - WebSocket Test Client</h1>  ||  <option value=""autotrade"">Autotrade</option>  ||  if (ws && ws.readyState === WebSocket.OPEN) {  ||  ws = new WebSocket(wsUrl);  ||  addMessage('WebSocket connected successfully', 'system');  ||  addMessage(`WebSocket closed: ${event.code} - ${event.reason || 'No reason provided'}`, 'error');  ||  addMessage(`WebSocket error: ${error}`, 'error');  ||  addMessage(`Failed to create WebSocket: ${error}`, 'error');  ||  if (ws && ws.readyState === WebSocket.OPEN) {  ||  if (ws && ws.readyState === WebSocket.OPEN) {  ||  if (!ws || ws.readyState !== WebSocket.OPEN) {  ||  if (!ws || ws.readyState !== WebSocket.OPEN) {  ||  a.download = `websocket-log-${clientId}.json`;  ||  addMessage('DEX Sniper Pro WebSocket Test Client loaded', 'system');  ||  async def broadcast_autotrade_message(message_type: MessageType, data: dict) -> int:  ||  Broadcast a message to all autotrade channel subscribers.  ||  logger.error(""WebSocket hub not available for autotrade broadcast"")  ||  message = WebSocketMessage(  ||  channel=Channel.AUTOTRADE,  ||  sent_count = await ws_hub.broadcast_to_channel(Channel.AUTOTRADE, message)  ||  logger.debug(f""Autotrade message broadcast to {sent_count} clients"")  ||  logger.error(f""Failed to broadcast autotrade message: {e}"")  ||  logger.error(""WebSocket hub not available for discovery broadcast"")  ||  message = WebSocketMessage(  ||  logger.error(""WebSocket hub not available for system broadcast"")  ||  message = WebSocketMessage(  ||  @router.websocket(""/autotrade"")  ||  async def websocket_autotrade_endpoint(websocket: WebSocket):  ||  Legacy autotrade WebSocket endpoint for frontend compatibility.  ||  # Accept the WebSocket connection  ||  await websocket.accept()  ||  client_id = f""autotrade_{uuid.uuid4().hex[:8]}""  ||  logger.info(f""Legacy autotrade WebSocket connection: {client_id}"")  ||  connected = await ws_hub.connect_client(client_id, websocket)  ||  logger.error(f""Failed to connect legacy autotrade client: {client_id}"")  ||  await websocket.close(code=1011, reason=""Server error"")  ||  # Auto-subscribe to autotrade channel for legacy clients  ||  await ws_hub.subscribe_to_channel(client_id, Channel.AUTOTRADE)  ||  logger.info(f""Legacy client {client_id} auto-subscribed to autotrade channel"")  ||  data = await websocket.receive_text()  ||  except WebSocketDisconnect:  ||  logger.info(f""Legacy autotrade client {client_id} disconnected"")  ||  logger.error(f""Error in legacy autotrade endpoint for {client_id}: {e}"")  ||  logger.error(f""Critical error in legacy autotrade endpoint: {e}"")  ||  # Health check endpoint for WebSocket system  ||  async def websocket_health():  ||  Detailed health check for WebSocket system components.  ||  health_info[""error""] = ""WebSocket hub not available""  ||  logger.error(f""WebSocket health check failed: {e}"")"
"D:\dex\backend\app\api\__init__.py","7203","from __future__ import annotations | import logging | from typing import Dict, Any | from fastapi import APIRouter | from fastapi.routing import APIRoute |         import importlib |     from .wallet_funding import router as wallet_funding_router |     from .presets import router as presets_router","Updated version with working quotes router registration.  ||  # Register wallet router with debugging  ||  logger.info(""Attempting to register wallet router..."")  ||  wallet_success = _register_router(""wallet"", description=""Wallet Management"")  ||  logger.info(f""Wallet router registration result: {wallet_success}"")  ||  # Register wallet funding router - NEW ADDITION  ||  logger.info(""Attempting to register wallet funding router..."")  ||  wallet_funding_success = _register_router(""wallet_funding"", description=""Wallet Funding & Approvals"")  ||  logger.info(f""Wallet funding router registration result: {wallet_funding_success}"")  ||  # Direct wallet funding router registration with error details  ||  logger.info(""Attempting direct wallet funding router registration..."")  ||  from .wallet_funding import router as wallet_funding_router  ||  api_router.include_router(wallet_funding_router)  ||  logger.info(""✅ Wallet funding router registered directly"")  ||  wallet_funding_success = True  ||  logger.error(f""❌ Direct wallet funding registration failed: {e}"")  ||  wallet_funding_success = False  ||  # Register quotes router with token resolution - CRITICAL FOR TRADING  ||  logger.info(""Attempting to register quotes router with token resolution..."")  ||  quotes_success = _register_router(""quotes"", description=""Price Quotes with Token Resolution"")  ||  if quotes_success:  ||  logger.info(""🎯 Quotes router registered successfully - real trading data now available"")  ||  logger.error(""🚨 Quotes router registration failed - trading will use mock data"")  ||  _register_router(""trades"", description=""Trade Execution"")  ||  _register_router(""risk"", description=""Risk Assessment"")  ||  _register_router(""safety"", description=""Safety Controls"")  ||  _register_router(""autotrade"", description=""Automated Trading"")  ||  # Register ledger and portfolio tracking - NEW ADDITION  ||  ledger_success = _register_router(""ledger"", description=""Ledger & Portfolio Tracking"")  ||  logger.info(f""🎯 Quotes router enabled: {quotes_success}"")  ||  logger.info(f""💰 Wallet router enabled: {wallet_success}"")  ||  logger.info(f""🔐 Wallet funding router enabled: {wallet_funding_success}"")  ||  logger.info(f""📋 Ledger router enabled: {ledger_success}"")  ||  # Log key endpoints including new ledger endpoints  ||  ""/quotes/aggregate"",  ||  ""/quotes/health"",  ||  ""/wallets/register"",  ||  ""/wallet-funding/wallet-status"",  ||  ""/risk/assess"",  ||  ""/ledger/positions"",  ||  ""/ledger/transactions"",  ||  ""/ledger/portfolio-summary""  ||  if quotes_success:  ||  logger.info(""🎉 TRADING READY: Real quotes with token resolution enabled"")  ||  logger.error(""🚨 TRADING LIMITED: Quotes router failed - check logs above"")  ||  if ledger_success:  ||  logger.info(""📊 PORTFOLIO TRACKING: Ledger endpoints enabled for real portfolio data"")  ||  logger.error(""🚨 PORTFOLIO LIMITED: Ledger router failed - portfolio will use demo data"")  ||  if wallet_funding_success:  ||  logger.info(""🔐 WALLET FUNDING: Approval system enabled for autotrade operations"")  ||  logger.info(""🔧 Features: Spending limits, approval management, funding status"")  ||  logger.error(""🚨 WALLET FUNDING LIMITED: Approval system failed - autotrade may be restricted"")"
"D:\dex\backend\app\autotrade\ai_pipeline.py","22986","from __future__ import annotations | import asyncio | import logging | import time | import uuid | from datetime import datetime, timezone, timedelta | from decimal import Decimal | from typing import Dict, Any, List, Optional, Callable | from enum import Enum | from dataclasses import dataclass | from ..ai.market_intelligence import MarketIntelligenceEngine | from ..ai.tuner import StrategyAutoTuner, TuningMode | from ..discovery.event_processor import ProcessedPair, OpportunityLevel | from ..ws.intelligence_hub import IntelligenceWebSocketHub, IntelligenceEvent, IntelligenceEventType | from ..autotrade.engine import AutotradeEngine, TradeOpportunity, OpportunityType, OpportunityPriority | from ..core.settings import get_settings |     from ..ai.market_intelligence import get_market_intelligence_engine |     from ..ai.tuner import get_auto_tuner |     from ..ws.intelligence_hub import get_intelligence_hub |     from ..autotrade.engine import get_autotrade_engine","DEX Sniper Pro - AI-Enhanced Autotrade Pipeline.  ||  and the autotrade opportunity queue. It integrates with the WebSocket hub to stream  ||  opportunities to the dashboard for user monitoring before autotrade activation.  ||  File: backend/app/autotrade/ai_pipeline.py  ||  from ..ws.intelligence_hub import IntelligenceWebSocketHub, IntelligenceEvent, IntelligenceEventType  ||  from ..autotrade.engine import AutotradeEngine, TradeOpportunity, OpportunityType, OpportunityPriority  ||  """"""AI decision outcomes for trade opportunities.""""""  ||  risk_score: float  ||  coordination_risk: float  ||  class AIAutotradesPipeline:  ||  autotrade opportunities with intelligent filtering and optimization.  ||  websocket_hub: IntelligenceWebSocketHub,  ||  autotrade_engine: AutotradeEngine  ||  """"""Initialize the AI autotrade pipeline.""""""  ||  self.websocket_hub = websocket_hub  ||  self.autotrade_engine = autotrade_engine  ||  ""max_coordination_risk"": 40.0,  ||  ""max_whale_dump_risk"": 70.0,  ||  ""max_manipulation_risk"": 50.0  ||  logger.info(""AI Autotrade Pipeline initialized"")  ||  """"""Start the AI-enhanced autotrade pipeline.""""""  ||  # Start WebSocket hub if not running  ||  if not self.websocket_hub.is_running:  ||  await self.websocket_hub.start_hub()  ||  # Register as autotrade bridge callback  ||  self.websocket_hub.register_autotrade_callback(self._on_intelligence_event)  ||  ""AI Autotrade Pipeline started"",  ||  """"""Stop the AI autotrade pipeline.""""""  ||  logger.info(""AI Autotrade Pipeline stopped"")  ||  async def process_discovery_event(self, processed_pair: ProcessedPair) -> Optional[TradeOpportunity]:  ||  and create autotrade opportunities.  ||  TradeOpportunity if approved by AI, None if rejected  ||  # Step 5: Add to Autotrade Queue (if autotrade is active)  ||  if self.autotrade_engine.is_running:  ||  await self.autotrade_engine.add_opportunity(opportunity)  ||  # Step 4: Monitor Decision (stream but don't auto-trade)  ||  coordination_risk = intelligence_data.get(""coordination_risk"", 0.0)  ||  if coordination_risk > self.ai_thresholds[""max_coordination_risk""]:  ||  block_reasons.append(f""High coordination risk: {coordination_risk:.1f}%"")  ||  if whale_activity > self.ai_thresholds[""max_whale_dump_risk""]:  ||  block_reasons.append(f""Whale dump risk: {whale_activity:.1f}%"")  ||  risk_score=coordination_risk,  ||  coordination_risk=coordination_risk,  ||  ) -> TradeOpportunity:  ||  """"""Create AI-enhanced trade opportunity.""""""  ||  opportunity = TradeOpportunity(  ||  risk_score=ai_analysis.risk_score,  ||  opportunity: TradeOpportunity,  ||  """"""Stream the opportunity to dashboard via WebSocket.""""""  ||  ""coordination_risk"": ai_analysis.coordination_risk,  ||  await self.websocket_hub.broadcast_intelligence_event(event)  ||  ""coordination_risk"": ai_analysis.coordination_risk,  ||  await self.websocket_hub.broadcast_intelligence_event(event)  ||  """"""Handle AI monitor decisions (stream but don't auto-trade).""""""  ||  await self.websocket_hub.broadcast_intelligence_event(event)  ||  """"""Handle intelligence events from WebSocket hub for autotrade coordination.""""""  ||  # Temporarily increase whale dump risk threshold  ||  self.ai_thresholds[""max_whale_dump_risk""] *= 0.8  ||  self.ai_thresholds[""max_coordination_risk""] = 30.0  ||  self.ai_thresholds[""max_coordination_risk""] = 50.0  ||  ""approval_rate"": self.approved_opportunities / max(1, self.processed_pairs) * 100,  ||  async def get_ai_autotrade_pipeline() -> AIAutotradesPipeline:  ||  """"""Get AI autotrade pipeline instance.""""""  ||  from ..autotrade.engine import get_autotrade_engine  ||  return AIAutotradesPipeline(  ||  websocket_hub=await get_intelligence_hub(),  ||  autotrade_engine=await get_autotrade_engine()"
"D:\dex\backend\app\autotrade\engine.py","21829","from __future__ import annotations | from typing import Dict, List, Optional, Set, Tuple | import asyncio | import logging | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Dict, List, Optional, Set, Tuple | from pydantic import BaseModel, Field | from ..api.analytics import PerformanceAnalytics | from ..api.presets import get_builtin_preset | from ..strategy.risk_manager import RiskManager | from ..strategy.safety_controls import SafetyControls |     from typing import Dict, List, Optional, Set, Tuple, Any |         import random","DEX Sniper Pro - Autotrade Core Engine.  ||  Automated trade decision engine with queue management and execution.  ||  from ..strategy.risk_manager import RiskManager  ||  from ..strategy.safety_controls import SafetyControls  ||  class AutotradeMode(str, Enum):  ||  """"""Autotrade operation modes.""""""  ||  ADVISORY = ""advisory""  # Recommend but don't execute  ||  CONSERVATIVE = ""conservative""  # Execute low-risk only  ||  STANDARD = ""standard""  # Execute normal risk levels  ||  AGGRESSIVE = ""aggressive""  # Execute all risk levels  ||  CRITICAL = ""critical""  # Must execute immediately  ||  HIGH = ""high""  # Execute within 1 block  ||  MEDIUM = ""medium""  # Execute within 5 blocks  ||  LOW = ""low""  # Execute when convenient  ||  class TradeOpportunity(BaseModel):  ||  # Trade details  ||  max_gas_price: Decimal = Field(..., description=""Maximum gas price (wei)"")  ||  # Risk and confidence  ||  risk_score: Decimal = Field(..., description=""Risk assessment score (0-1)"")  ||  class AutotradeMetrics(BaseModel):  ||  """"""Autotrade engine performance metrics.""""""  ||  opportunities_executed: int = Field(default=0, description=""Successfully executed trades"")  ||  opportunities_rejected: int = Field(default=0, description=""Rejected due to risk/filters"")  ||  class AutotradeEngine:  ||  risk_manager: RiskManager,  ||  safety_controls: SafetyControls,  ||  Initialize autotrade engine.  ||  risk_manager: Risk assessment service  ||  safety_controls: Safety controls and circuit breakers  ||  self.risk_manager = risk_manager  ||  self.safety_controls = safety_controls  ||  self.mode = AutotradeMode.DISABLED  ||  self.opportunity_queue: List[TradeOpportunity] = []  ||  self.active_trades: Dict[str, TradeOpportunity] = {}  ||  self.conflict_cache: Set[str] = set()  # Tokens with active trades  ||  self.max_concurrent_trades = 5  ||  self.metrics = AutotradeMetrics()  ||  logger.info(""AutotradeEngine initialized with real dependencies"")  ||  async def start(self, mode: AutotradeMode = AutotradeMode.STANDARD) -> None:  ||  Start the autotrade engine.  ||  raise ValueError(""Autotrade engine is already running"")  ||  self.metrics = AutotradeMetrics()  ||  logger.info(f""Autotrade engine started in {mode.value} mode"")  ||  """"""Stop the autotrade engine.""""""  ||  self.mode = AutotradeMode.DISABLED  ||  logger.info(""Autotrade engine stopped"")  ||  async def set_mode(self, mode: AutotradeMode) -> None:  ||  Change the autotrade engine mode.  ||  logger.info(f""Autotrade mode changed: {old_mode.value} -> {mode.value}"")  ||  async def add_opportunity(self, opportunity: TradeOpportunity) -> bool:  ||  # Check for conflicts (same token already being traded)  ||  # Risk assessment  ||  risk_assessment = await self._assess_opportunity_risk(opportunity)  ||  if not risk_assessment[""approved""]:  ||  logger.info(f""Opportunity rejected - risk assessment failed: {opportunity.id}"")  ||  async def _assess_opportunity_risk(self, opportunity: TradeOpportunity) -> Dict[str, any]:  ||  Assess risk for a trading opportunity.  ||  Risk assessment result  ||  # Use the real risk manager for assessment  ||  risk_params = {  ||  # Get risk assessment from risk manager  ||  if hasattr(self.risk_manager, 'assess_token_risk'):  ||  risk_result = await self.risk_manager.assess_token_risk(  ||  # Simple approval logic based on risk score  ||  approved = risk_result.get(""risk_score"", 1.0) < 0.8  ||  ""risk_score"": risk_result.get(""risk_score"", 1.0),  ||  ""reasons"": risk_result.get(""risk_factors"", [])  ||  # Fallback risk assessment  ||  logger.warning(""Risk manager doesn't support assess_token_risk, using fallback"")  ||  ""approved"": float(opportunity.risk_score) < 0.7,  ||  ""risk_score"": float(opportunity.risk_score),  ||  logger.error(f""Risk assessment failed for {opportunity.id}: {e}"")  ||  ""risk_score"": 1.0,  ||  ""reasons"": [f""Risk assessment error: {str(e)}""]  ||  # Check if we can execute more trades  ||  active_trade_count = len(self.active_trades)  ||  if active_trade_count >= self.max_concurrent_trades:  ||  logger.debug(f""Max concurrent trades reached: {active_trade_count}"")  ||  self.max_concurrent_trades - active_trade_count,  ||  # Execute in background  ||  asyncio.create_task(self._execute_opportunity(opportunity))  ||  async def _execute_opportunity(self, opportunity: TradeOpportunity) -> None:  ||  Execute a trading opportunity.  ||  opportunity: Opportunity to execute  ||  # Add to active trades  ||  self.active_trades[opportunity.id] = opportunity  ||  # Execute the trade (this will be overridden by integration layer)  ||  success = await self._execute_trade(opportunity)  ||  (self.metrics.avg_execution_time_ms * self.metrics.opportunities_executed + execution_time) /  ||  (self.metrics.opportunities_executed + 1)  ||  self.metrics.opportunities_executed += 1  ||  logger.info(f""Opportunity executed successfully: {opportunity.id}"")  ||  total_attempts = self.metrics.opportunities_executed + self.metrics.opportunities_failed  ||  self.metrics.success_rate = self.metrics.opportunities_executed / total_attempts  ||  self.active_trades.pop(opportunity.id, None)  ||  async def _execute_trade(self, opportunity: TradeOpportunity) -> bool:  ||  Execute trade for opportunity (mock implementation - will be overridden).  ||  opportunity: Opportunity to execute  ||  logger.info(f""Mock trade execution for {opportunity.id}: {'success' if success else 'failed'}"")  ||  ""active_trades"": len(self.active_trades),  ||  ""max_concurrent_trades"": self.max_concurrent_trades,"
"D:\dex\backend\app\autotrade\integration.py","26033","from __future__ import annotations | import asyncio | import logging | from typing import Optional, Dict, Any, Protocol | from datetime import datetime, timezone, timedelta | from decimal import Decimal | from fastapi import Depends | from ..core.dependencies import ( | from ..core.settings import get_settings | from ..storage.repositories import get_transaction_repository | from ..trading.executor import TradeExecutor | from ..trading.models import TradeRequest, TradeType | from .engine import AutotradeEngine, TradeOpportunity, OpportunityType, OpportunityPriority | from .ai_pipeline import AIAutotradesPipeline | from ..discovery.event_processor import ProcessingStatus |             from ..ai.market_intelligence import get_market_intelligence_engine |             from ..ai.tuner import get_auto_tuner |             from ..ws.intelligence_hub import get_intelligence_hub","DEX Sniper Pro - Enhanced Autotrade Integration Layer with AI Pipeline.  ||  This module provides dependency injection and integration for the autotrade engine,  ||  connecting discovery → AI analysis → autotrade execution with secure wallet funding.  ||  - Real-time streaming to dashboard via WebSocket  ||  - Secure wallet funding with user confirmation  ||  File: backend/app/autotrade/integration.py  ||  get_trade_executor,  ||  get_risk_manager,  ||  get_safety_controls,  ||  from ..trading.executor import TradeExecutor  ||  from ..trading.models import TradeRequest, TradeType  ||  from .engine import AutotradeEngine, TradeOpportunity, OpportunityType, OpportunityPriority  ||  from .ai_pipeline import AIAutotradesPipeline  ||  class WalletFundingManager:  ||  """"""Manages secure wallet funding for autotrade operations.""""""  ||  self.approved_wallets: Dict[str, Dict[str, Any]] = {}  ||  self.pending_approvals: Dict[str, Dict[str, Any]] = {}  ||  async def request_wallet_approval(self, user_id: str, wallet_address: str, chain: str,  ||  daily_limit_usd: Decimal, per_trade_limit_usd: Decimal,  ||  approval_duration_hours: int = 24) -> str:  ||  Request wallet approval for autotrade operations.  ||  wallet_address: Wallet to approve  ||  per_trade_limit_usd: Maximum per-trade limit  ||  approval_duration_hours: How long approval lasts  ||  Approval request ID for tracking  ||  approval_id = f""approval_{int(datetime.now(timezone.utc).timestamp())}_{user_id[:8]}""  ||  self.pending_approvals[approval_id] = {  ||  'wallet_address': wallet_address.lower(),  ||  'per_trade_limit_usd': per_trade_limit_usd,  ||  'approval_duration_hours': approval_duration_hours,  ||  f""Wallet approval requested: {approval_id}"",  ||  'wallet_address': wallet_address,  ||  'per_trade_limit': str(per_trade_limit_usd)  ||  return approval_id  ||  async def confirm_wallet_approval(self, approval_id: str, user_confirmation: bool) -> bool:  ||  """"""Confirm or reject wallet approval request.""""""  ||  if approval_id not in self.pending_approvals:  ||  logger.warning(f""Approval request not found: {approval_id}"")  ||  approval = self.pending_approvals[approval_id]  ||  user_id = approval['user_id']  ||  chain = approval['chain']  ||  if user_id not in self.approved_wallets:  ||  self.approved_wallets[user_id] = {}  ||  self.approved_wallets[user_id][chain] = {  ||  'address': approval['wallet_address'],  ||  'expires_at': datetime.now(timezone.utc) + timedelta(hours=approval['approval_duration_hours']),  ||  'daily_limit_usd': approval['daily_limit_usd'],  ||  'per_trade_limit_usd': approval['per_trade_limit_usd']  ||  approval['status'] = 'approved'  ||  logger.info(f""Wallet approved for trading: {approval_id}"")  ||  approval['status'] = 'rejected'  ||  logger.info(f""Wallet approval rejected: {approval_id}"")  ||  del self.pending_approvals[approval_id]  ||  async def get_approved_trading_wallet(self, user_id: str, chain: str) -> Optional[str]:  ||  """"""Get user's approved trading wallet for specific chain.""""""  ||  user_wallets = self.approved_wallets.get(user_id, {})  ||  wallet_info = user_wallets.get(chain)  ||  if not wallet_info:  ||  # Check if approval hasn't expired  ||  if wallet_info.get('expires_at') and wallet_info['expires_at'] < datetime.now(timezone.utc):  ||  del self.approved_wallets[user_id][chain]  ||  return wallet_info.get('address')  ||  logger.error(f""Error getting approved wallet: {e}"")  ||  async def check_spending_limits(self, user_id: str, chain: str, trade_amount_usd: Decimal) -> Dict[str, Any]:  ||  """"""Check if trade amount is within approved spending limits.""""""  ||  user_wallets = self.approved_wallets.get(user_id, {})  ||  wallet_info = user_wallets.get(chain)  ||  if not wallet_info:  ||  return {'allowed': False, 'reason': 'no_approved_wallet'}  ||  # Check per-trade limit  ||  per_trade_limit = wallet_info.get('per_trade_limit_usd', Decimal('0'))  ||  if trade_amount_usd > per_trade_limit:  ||  'reason': 'per_trade_limit_exceeded',  ||  'per_trade_limit': str(per_trade_limit),  ||  'requested_amount': str(trade_amount_usd)  ||  daily_limit = wallet_info.get('daily_limit_usd', Decimal('0'))  ||  if current_daily_spending + trade_amount_usd > daily_limit:  ||  async def record_trade_spending(self, user_id: str, chain: str, amount_usd: Decimal) -> None:  ||  logger.info(f""Recorded trade spending: ${amount_usd} for user {user_id} on {chain}"")  ||  logger.error(f""Error recording trade spending: {e}"")  ||  def get_wallet_status(self, user_id: str) -> Dict[str, Any]:  ||  """"""Get complete wallet approval and spending status for user.""""""  ||  'approved_wallets': self.approved_wallets.get(user_id, {}),  ||  'pending_approvals': [  ||  approval for approval in self.pending_approvals.values()  ||  if approval['user_id'] == user_id  ||  class AutotradeIntegration:  ||  Enhanced integration layer with AI pipeline for intelligent autotrade processing.  ||  Flow: Discovery → AI Analysis → Opportunity Creation → Dashboard Streaming → Autotrade Execution  ||  trade_executor: TradeExecutor,  ||  risk_manager,  ||  safety_controls,  ||  """"""Initialize enhanced autotrade integration with AI pipeline.""""""  ||  self.trade_executor = trade_executor  ||  self.risk_manager = risk_manager  ||  self.safety_controls = safety_controls  ||  # Initialize secure wallet funding manager  ||  self.wallet_funding = WalletFundingManager()  ||  # Create the autotrade engine with real dependencies  ||  self.engine = AutotradeEngine(  ||  risk_manager=risk_manager,  ||  safety_controls=safety_controls,  ||  self.ai_pipeline: Optional[AIAutotradesPipeline] = None  ||  logger.info(""Enhanced AutotradeIntegration initialized"")  ||  self.ai_pipeline = AIAutotradesPipeline(  ||  websocket_hub=await get_intelligence_hub(),  ||  autotrade_engine=self.engine  ||  ""module"": ""autotrade_integration"",  ||  f""AI pipeline created autotrade opportunity: {ai_opportunity.id}"",  ||  ""module"": ""autotrade_integration"",  ||  ""module"": ""autotrade_integration"",  ||  ""module"": ""autotrade_integration"",  ||  ""risk_warnings"": processed_pair.risk_warnings  ||  async def _execute_secure_trade(  ||  opportunity: TradeOpportunity,  ||  """"""Execute trade with secure wallet funding and AI optimizations.""""""  ||  f""Executing AI-enhanced secure trade: {opportunity.id}"",  ||  ""module"": ""autotrade_integration"",  ||  # SECURITY: Verify user wallet approval  ||  logger.error(""No user_id provided for secure trade execution"")  ||  wallet_address = await self.wallet_funding.get_approved_trading_wallet(  ||  if not wallet_address:  ||  logger.warning(f""No approved wallet for user {user_id} on {opportunity.chain}"")  ||  trade_amount_usd = opportunity.position_size_gbp * Decimal('1.2')  # GBP to USD rough conversion  ||  limit_check = await self.wallet_funding.check_spending_limits(  ||  user_id, opportunity.chain, trade_amount_usd  ||  logger.warning(f""Trade blocked by spending limits: {limit_check['reason']}"")  ||  # Build trade request with AI optimizations  ||  trade_request = TradeRequest(  ||  trace_id=f""ai_autotrade_{opportunity.id}"",  ||  trade_type=TradeType.BUY,  ||  wallet_address=wallet_address,  ||  max_gas_price=200000000000,  # 200 gwei max  ||  preset_name=""ai_autotrade""  ||  # Execute with AI delay if recommended  ||  # Execute trade  ||  result = await self.trade_executor.execute_trade(trade_request, chain_clients)  ||  await self.wallet_funding.record_trade_spending(  ||  user_id, opportunity.chain, trade_amount_usd  ||  f""AI-enhanced trade executed successfully: {result.tx_hash}"",  ||  ""module"": ""autotrade_integration"",  ||  logger.warning(f""Trade execution failed: {result.error_message}"")  ||  logger.error(f""AI-enhanced trade execution error: {e}"")  ||  """"""Start the integrated AI-enhanced autotrade system.""""""  ||  logger.warning(""Autotrade integration already started"")  ||  # Override engine's trade execution with secure method  ||  self.engine._execute_trade = self._execute_secure_trade  ||  # Start the autotrade engine  ||  ""AI-enhanced autotrade integration started successfully"",  ||  ""module"": ""autotrade_integration"",  ||  ""secure_wallet_funding"": True  ||  logger.error(f""Failed to start AI-enhanced autotrade integration: {e}"")  ||  """"""Stop the integrated AI-enhanced autotrade system.""""""  ||  logger.info(""AI-enhanced autotrade integration stopped"")  ||  logger.error(f""Error stopping AI-enhanced autotrade integration: {e}"")  ||  def get_engine(self) -> AutotradeEngine:  ||  """"""Get the autotrade engine instance.""""""  ||  def get_ai_pipeline(self) -> Optional[AIAutotradesPipeline]:  ||  def get_wallet_funding_manager(self) -> WalletFundingManager:  ||  """"""Get the wallet funding manager instance.""""""  ||  return self.wallet_funding  ||  ""secure_wallet_funding"": True  ||  _autotrade_integration: Optional[AutotradeIntegration] = None  ||  async def get_autotrade_integration() -> AutotradeIntegration:  ||  """"""Get or create the AI-enhanced autotrade integration instance.""""""  ||  global _autotrade_integration  ||  if _autotrade_integration is None:  ||  trade_executor = await get_trade_executor()  ||  risk_manager = await get_risk_manager()  ||  safety_controls = await get_safety_controls()  ||  _autotrade_integration = AutotradeIntegration(  ||  trade_executor=trade_executor,  ||  risk_manager=risk_manager,  ||  safety_controls=safety_controls,  ||  logger.info(""AI-enhanced autotrade integration instance created successfully"")  ||  logger.error(f""Failed to create AI-enhanced autotrade integration: {e}"")  ||  return _autotrade_integration  ||  async def get_autotrade_engine() -> AutotradeEngine:  ||  """"""FastAPI dependency to get the AI-enhanced autotrade engine.""""""  ||  integration = await get_autotrade_integration()  ||  async def get_ai_pipeline() -> Optional[AIAutotradesPipeline]:  ||  integration = await get_autotrade_integration()  ||  async def get_wallet_funding_manager() -> WalletFundingManager:  ||  """"""FastAPI dependency to get the wallet funding manager.""""""  ||  integration = await get_autotrade_integration()  ||  return integration.get_wallet_funding_manager()  ||  def get_autotrade_integration_dependency() -> AutotradeIntegration:  ||  """"""FastAPI dependency for AI-enhanced autotrade integration.""""""  ||  return Depends(get_autotrade_integration)  ||  def get_autotrade_engine_dependency() -> AutotradeEngine:  ||  """"""FastAPI dependency for AI-enhanced autotrade engine.""""""  ||  return Depends(get_autotrade_engine)"
"D:\dex\backend\app\autotrade\position_manager.py","2377","from __future__ import annotations | import asyncio | import logging | from datetime import datetime, timedelta | from decimal import Decimal | from typing import Dict, List, Optional, Set, Tuple | from pydantic import BaseModel, Field | from backend.app.strategy.orders.advanced_orders import DCAOrder, TrailingStopOrder, TWAPOrder | from backend.app.strategy.orders.base import BaseOrder, OrderManager, OrderStatus, OrderType | from backend.app.strategy.orders.stop_orders import BracketOrder, StopLimitOrder, StopLossOrder, TakeProfitOrder","Coordinates advanced orders, risk management, and position lifecycle.  ||  # Risk management"
"D:\dex\backend\app\autotrade\queue.py","34142","from __future__ import annotations | import asyncio | import logging | from datetime import datetime, timezone, timedelta | from decimal import Decimal | from typing import Dict, List, Optional, Set, Tuple, Union, Any, Callable | from dataclasses import dataclass, field | from enum import Enum | import uuid | import heapq | from collections import defaultdict | from pydantic import BaseModel, Field | from .engine import TradeOpportunity, QueuedTrade, TradePriority, TradeStatus, ConflictResolution | from ..strategy.base import StrategyType","Trade Queue Management System for DEX Sniper Pro.  ||  from .engine import TradeOpportunity, QueuedTrade, TradePriority, TradeStatus, ConflictResolution  ||  RISK_ADJUSTED = ""risk_adjusted""  # Risk-adjusted profit optimization  ||  """"""Trade batching strategies.""""""  ||  SAME_TOKEN = ""same_token""  # Batch trades for same token  ||  SAME_DEX = ""same_dex""  # Batch trades on same DEX  ||  SAME_CHAIN = ""same_chain""  # Batch trades on same chain  ||  OPTIMAL_GAS = ""optimal_gas""  # Optimize for gas efficiency  ||  ROUND_ROBIN = ""round_robin""  # Distribute evenly across wallets  ||  LEAST_BUSY = ""least_busy""  # Use least busy wallet  ||  RANDOM = ""random""  # Random wallet selection  ||  PERFORMANCE_BASED = ""performance_based""  # Use best performing wallet  ||  trade: QueuedTrade  ||  class TradeBatch:  ||  """"""Represents a batch of trades for optimized execution.""""""  ||  trades: List[QueuedTrade] = field(default_factory=list)  ||  estimated_gas_savings: Decimal = Decimal(""0"")  ||  """"""Calculate total value of trades in batch.""""""  ||  return sum(trade.opportunity.amount_in for trade in self.trades)  ||  """"""Calculate average priority score of trades in batch.""""""  ||  if not self.trades:  ||  TradePriority.LOW: 1,  ||  TradePriority.NORMAL: 2,  ||  TradePriority.HIGH: 3,  ||  TradePriority.CRITICAL: 4,  ||  TradePriority.EMERGENCY: 5  ||  priority_values.get(trade.opportunity.priority, 2)  ||  for trade in self.trades  ||  return total_priority / len(self.trades)  ||  max_batch_size: int = Field(default=5, description=""Maximum trades per batch"")  ||  risk_weight: float = Field(default=0.3, description=""Weight for risk in priority scoring"")  ||  min_batch_size: int = Field(default=2, description=""Minimum trades to form a batch"")  ||  class TradeQueueManager:  ||  Advanced trade queue management system.  ||  and intelligent scheduling for optimal trade execution.  ||  self._trade_lookup: Dict[str, QueuedTrade] = {}  ||  self._batches: Dict[str, TradeBatch] = {}  ||  self._pending_batches: List[TradeBatch] = []  ||  self._wallet_loads: Dict[str, int] = defaultdict(int)  ||  self._wallet_performance: Dict[str, float] = defaultdict(lambda: 1.0)  ||  self._processed_trades: List[QueuedTrade] = []  ||  ""Trade queue manager initialized"",  ||  async def enqueue(self, trade: QueuedTrade) -> None:  ||  Add a trade to the queue with intelligent prioritization.  ||  trade: Trade to add to the queue  ||  QueueManagerError: If queue is full or trade is invalid  ||  # Remove lowest priority trade if queue is full  ||  priority_score = await self._calculate_priority_score(trade)  ||  trade=trade  ||  self._trade_lookup[trade.trade_id] = trade  ||  priority_str = trade.opportunity.priority.value  ||  await self._check_batching_opportunity(trade)  ||  f""Trade enqueued with priority score {priority_score:.3f}"",  ||  ""trade_id"": trade.trade_id,  ||  ""priority"": trade.opportunity.priority.value,  ||  async def dequeue(self) -> Optional[Union[QueuedTrade, TradeBatch]]:  ||  Remove and return the highest priority trade or batch.  ||  QueuedTrade or TradeBatch: Next item to execute, or None if queue is empty  ||  # Get individual trade  ||  trade = queue_item.trade  ||  del self._trade_lookup[trade.trade_id]  ||  f""Trade dequeued after {wait_time:.1f}ms wait"",  ||  ""trade_id"": trade.trade_id,  ||  return trade  ||  async def remove(self, trade_id: str) -> Optional[QueuedTrade]:  ||  Remove a specific trade from the queue.  ||  trade_id: ID of trade to remove  ||  QueuedTrade: Removed trade, or None if not found  ||  if trade_id not in self._trade_lookup:  ||  trade = self._trade_lookup[trade_id]  ||  if item.trade.trade_id == trade_id:  ||  item.trade.status = TradeStatus.CANCELLED  ||  del self._trade_lookup[trade_id]  ||  await self._remove_from_batches(trade_id)  ||  f""Trade removed from queue"",  ||  extra={""trade_id"": trade_id, ""module"": ""queue_manager""}  ||  return trade  ||  async def peek(self) -> Optional[Union[QueuedTrade, TradeBatch]]:  ||  QueuedTrade or TradeBatch: Next item to execute, or None if queue is empty  ||  return self._priority_queue[0].trade  ||  trade = item.trade  ||  if trade.status == TradeStatus.CANCELLED:  ||  ""trade_id"": trade.trade_id,  ||  ""opportunity_id"": trade.opportunity.opportunity_id,  ||  ""priority"": trade.opportunity.priority.value,  ||  ""strategy"": trade.opportunity.strategy_type.value,  ||  ""token_address"": trade.opportunity.token_address,  ||  ""amount_usd"": float(trade.opportunity.amount_in),  ||  ""expires_at"": trade.opportunity.expires_at.isoformat() if trade.opportunity.expires_at else None,  ||  ""batch_id"": await self._get_trade_batch_id(trade.trade_id)  ||  async def _calculate_priority_score(self, trade: QueuedTrade) -> float:  ||  Calculate comprehensive priority score for a trade.  ||  trade: Trade to score  ||  TradePriority.LOW: 1.0,  ||  TradePriority.NORMAL: 2.0,  ||  TradePriority.HIGH: 3.0,  ||  TradePriority.CRITICAL: 4.0,  ||  TradePriority.EMERGENCY: 5.0  ||  }.get(trade.opportunity.priority, 2.0)  ||  profit_score = await self._calculate_profit_score(trade)  ||  time_score = await self._calculate_time_urgency_score(trade)  ||  risk_score = await self._calculate_risk_score(trade)  ||  self.config.risk_weight * (1.0 - risk_score)  # Invert risk (lower risk = higher score)  ||  strategy_type = trade.opportunity.strategy_type.value  ||  async def _calculate_profit_score(self, trade: QueuedTrade) -> float:  ||  expected_profit = trade.opportunity.expected_output - trade.opportunity.amount_in  ||  profit_percentage = float(expected_profit / trade.opportunity.amount_in) if trade.opportunity.amount_in > 0 else 0  ||  async def _calculate_time_urgency_score(self, trade: QueuedTrade) -> float:  ||  if not trade.opportunity.expires_at:  ||  time_to_expiry = trade.opportunity.expires_at - datetime.now(timezone.utc)  ||  async def _calculate_risk_score(self, trade: QueuedTrade) -> float:  ||  """"""Calculate risk score (0-1, where 1 = highest risk).""""""  ||  return trade.opportunity.risk_score  ||  async def _check_batching_opportunity(self, new_trade: QueuedTrade) -> None:  ||  """"""Check if new trade can be batched with existing trades.""""""  ||  # Find compatible trades for batching  ||  compatible_trades = await self._find_compatible_trades(new_trade)  ||  if len(compatible_trades) >= self.config.min_batch_size - 1:  # -1 because we include new_trade  ||  batch = TradeBatch(  ||  trades=[new_trade] + compatible_trades[:self.config.max_batch_size - 1],  ||  f""Created batch with {len(batch.trades)} trades"",  ||  async def _find_compatible_trades(self, trade: QueuedTrade) -> List[QueuedTrade]:  ||  """"""Find trades compatible for batching.""""""  ||  if item.trade.trade_id == trade.trade_id:  ||  if item.trade.status != TradeStatus.QUEUED:  ||  if await self._are_trades_compatible(trade, item.trade):  ||  compatible.append(item.trade)  ||  async def _are_trades_compatible(self, trade1: QueuedTrade, trade2: QueuedTrade) -> bool:  ||  """"""Check if two trades are compatible for batching.""""""  ||  return (trade1.opportunity.token_address == trade2.opportunity.token_address and  ||  trade1.opportunity.chain == trade2.opportunity.chain)  ||  return (trade1.opportunity.dex == trade2.opportunity.dex and  ||  trade1.opportunity.chain == trade2.opportunity.chain)  ||  return trade1.opportunity.chain == trade2.opportunity.chain  ||  elif self.config.batching_strategy == BatchingStrategy.OPTIMAL_GAS:  ||  # Check if trades can be optimized together for gas savings  ||  return (trade1.opportunity.chain == trade2.opportunity.chain and  ||  abs(float(trade1.opportunity.amount_in - trade2.opportunity.amount_in)) < 100)  ||  async def _set_batch_attributes(self, batch: TradeBatch) -> None:  ||  """"""Set common attributes for a batch based on its trades.""""""  ||  if not batch.trades:  ||  first_trade = batch.trades[0]  ||  batch.common_chain = first_trade.opportunity.chain  ||  batch.common_token = first_trade.opportunity.token_address  ||  batch.common_dex = first_trade.opportunity.dex  ||  # Estimate gas savings (simplified calculation)  ||  individual_gas_cost = len(batch.trades) * Decimal(""5.0"")  # $5 per trade  ||  batch_gas_cost = Decimal(""8.0"")  # Estimated batch cost  ||  batch.estimated_gas_savings = max(Decimal(""0""), individual_gas_cost - batch_gas_cost)  ||  async def _get_ready_batch(self) -> Optional[TradeBatch]:  ||  if (len(batch.trades) >= self.config.max_batch_size or  ||  # Remove trades from individual queue  ||  for trade in batch.trades:  ||  if trade.trade_id in self._trade_lookup:  ||  await self.remove(trade.trade_id)  ||  ""trade_count"": len(batch.trades),  ||  async def _get_trade_batch_id(self, trade_id: str) -> Optional[str]:  ||  """"""Get batch ID for a trade if it's batched.""""""  ||  if any(trade.trade_id == trade_id for trade in batch.trades):  ||  async def _remove_from_batches(self, trade_id: str) -> None:  ||  """"""Remove a trade from all batches.""""""  ||  batch.trades = [trade for trade in batch.trades if trade.trade_id != trade_id]  ||  # Remove batch if too few trades remain  ||  if len(batch.trades) < self.config.min_batch_size:  ||  """"""Remove the lowest priority trade when queue is full.""""""  ||  await self.remove(lowest_item.trade.trade_id)  ||  f""Evicted lowest priority trade due to queue full"",  ||  ""trade_id"": lowest_item.trade.trade_id,  ||  if item.trade.status == TradeStatus.QUEUED  ||  """"""Optimize the order of trades in the queue.""""""  ||  # Recalculate priority scores for all trades  ||  if item.trade.status == TradeStatus.QUEUED:  ||  new_score = await self._calculate_priority_score(item.trade)  ||  trade=item.trade  ||  # Analyze recent completed trades  ||  for trade in self._processed_trades:  ||  if trade.completed_at and trade.completed_at > recent_cutoff:  ||  strategy = trade.opportunity.strategy_type.value  ||  if trade.status == TradeStatus.COMPLETED:  ||  # If batch has minimum trades, keep it ready  ||  if len(batch.trades) >= self.config.min_batch_size:  ||  # Dissolve batch and return trades to individual queue  ||  for trade in batch.trades:  ||  await self.enqueue(trade)  ||  # Try to add more compatible trades  ||  additional_trades = []  ||  if len(batch.trades) >= self.config.max_batch_size:  ||  if item.trade.status == TradeStatus.QUEUED:  ||  if batch.trades and await self._are_trades_compatible(batch.trades[0], item.trade):  ||  additional_trades.append(item.trade)  ||  # Add compatible trades to batch  ||  for trade in additional_trades:  ||  if len(batch.trades) < self.config.max_batch_size:  ||  batch.trades.append(trade)  ||  await self.remove(trade.trade_id)  ||  trade for trade in self._processed_trades  ||  if trade.completed_at and trade.completed_at > recent_cutoff  ||  total_batched = sum(len(batch.trades) for batch in self._batches.values())  ||  total_trades = self.metrics.total_processed + self.metrics.current_queue_depth  ||  if total_trades > 0:  ||  self.metrics.batch_efficiency = total_batched / total_trades"
"D:\dex\backend\app\chains\circuit_breaker.py","2356","from __future__ import annotations | import time | from dataclasses import dataclass | from enum import Enum",""
"D:\dex\backend\app\chains\evm_client.py","19206","from __future__ import annotations | import asyncio | import logging | from decimal import Decimal | from typing import Any, Dict, List, Optional, Tuple | from eth_account import Account | from eth_typing import ChecksumAddress, HexStr | from web3 import Web3 | from web3.exceptions import TransactionNotFound | from web3.types import TxParams, TxReceipt | from ..core.settings import settings | from .rpc_pool import RpcProvider, rpc_pool","class NonceManager:  ||  Nonce management for EVM transactions with concurrent support.  ||  Handles nonce tracking to prevent conflicts when sending multiple  ||  """"""Initialize nonce manager.""""""  ||  self._nonces: Dict[str, int] = {}  ||  async def get_next_nonce(self, address: str, chain: str) -> int:  ||  Get next nonce for address on chain.  ||  address: Wallet address  ||  Next nonce to use  ||  # Get current nonce from chain  ||  current_nonce = await self._get_chain_nonce(address, chain)  ||  logger.warning(f""Failed to get nonce from chain: {e}"")  ||  current_nonce = 0  ||  # Use max of chain nonce and our tracked nonce  ||  tracked_nonce = self._nonces.get(key, current_nonce)  ||  next_nonce = max(current_nonce, tracked_nonce)  ||  self._nonces[key] = next_nonce + 1  ||  logger.debug(f""Assigned nonce {next_nonce} for {address} on {chain}"")  ||  return next_nonce  ||  async def _get_chain_nonce(self, address: str, chain: str) -> int:  ||  """"""Get current nonce from blockchain.""""""  ||  def reset_nonce(self, address: str, chain: str) -> None:  ||  """"""Reset tracked nonce for address (use after failed transaction).""""""  ||  if key in self._nonces:  ||  del self._nonces[key]  ||  logger.debug(f""Reset nonce tracking for {address} on {chain}"")  ||  class GasEstimator:  ||  Gas estimation and pricing for EVM transactions.  ||  Handles EIP-1559 gas pricing and legacy gas price estimation  ||  with safety margins and chain-specific optimizations.  ||  """"""Initialize gas estimator.""""""  ||  self.gas_multipliers = {  ||  async def estimate_gas(  ||  Estimate gas limit for transaction.  ||  Estimated gas limit  ||  method=""eth_estimateGas"",  ||  base_gas = int(result, 16)  ||  # Apply chain-specific multiplier for safety  ||  multiplier = self.gas_multipliers.get(chain, 1.1)  ||  estimated_gas = int(base_gas * multiplier)  ||  min_gas = 21000  # Minimum for simple transfer  ||  max_gas = 2000000  # Reasonable maximum  ||  final_gas = max(min_gas, min(estimated_gas, max_gas))  ||  logger.debug(f""Gas estimate for {chain}: {base_gas} -> {final_gas}"")  ||  return final_gas  ||  logger.warning(f""Gas estimation failed for {chain}: {e}"")  ||  """"""Get EIP-1559 gas fees.""""""  ||  base_fee = int(result[""baseFeePerGas""][-1], 16)  ||  max_fee_per_gas = int(base_fee * 2 + avg_priority_fee)  ||  max_priority_fee_per_gas = min(avg_priority_fee * 2, max_fee_per_gas // 10)  ||  logger.debug(f""EIP-1559 fees for {chain}: max={max_fee_per_gas}, priority={max_priority_fee_per_gas}"")  ||  return None, max_fee_per_gas, max_priority_fee_per_gas  ||  gas_price = await self._get_legacy_gas_price(chain)  ||  return gas_price, None, None  ||  async def _get_legacy_gas_price(self, chain: str) -> int:  ||  """"""Get legacy gas price.""""""  ||  method=""eth_gasPrice"",  ||  multiplier = self.gas_multipliers.get(chain, 1.1)  ||  logger.debug(f""Legacy gas price for {chain}: {base_price} -> {final_price}"")  ||  self.nonce_manager = NonceManager()  ||  self.gas_estimator = GasEstimator()  ||  address: Wallet address  ||  gas_limit: Optional[int] = None,  ||  gas_limit: Gas limit (estimated if None)  ||  # Get nonce  ||  nonce = await self.nonce_manager.get_next_nonce(from_address, chain)  ||  # Estimate gas if not provided  ||  if gas_limit is None:  ||  gas_limit = await self.gas_estimator.estimate_gas(chain, temp_tx)  ||  # Get gas pricing  ||  gas_price, max_fee, max_priority_fee = await self.gas_estimator.get_gas_price(chain)  ||  ""gas"": gas_limit,  ||  ""nonce"": nonce,  ||  # Add gas pricing (EIP-1559 or legacy)  ||  tx_params[""maxFeePerGas""] = max_fee  ||  tx_params[""maxPriorityFeePerGas""] = max_priority_fee  ||  tx_params[""gasPrice""] = gas_price  ||  logger.debug(f""Built transaction for {chain}: nonce={nonce}, gas={gas_limit}"")  ||  ""nonce_manager"": {  ||  ""tracked_addresses"": len(self.nonce_manager._nonces)"
"D:\dex\backend\app\chains\rpc_pool.py","17548","from __future__ import annotations | import asyncio | import logging | import time | from dataclasses import dataclass | from enum import Enum | from typing import Dict, List, Optional | import httpx | from httpx import AsyncClient | from ..core.settings import settings | from .circuit_breaker import CircuitBreaker, CircuitState","result = await self._execute_request(provider, method, params)  ||  async def _execute_request(self, provider: RpcProvider, method: str, params: List) -> any:  ||  """"""Execute single RPC request to provider."""""""
"D:\dex\backend\app\chains\solana_client.py","20724","from __future__ import annotations | import asyncio | import base64 | import json | import logging | from decimal import Decimal | from typing import Any, Dict, List, Optional, Tuple | import httpx | from solana.rpc.async_api import AsyncClient | from solana.rpc.commitment import Commitment | from solana.rpc.types import TxOpts | from solders.pubkey import Pubkey | from solders.transaction import VersionedTransaction | from ..core.settings import settings | from .rpc_pool import rpc_pool |         import time |         import time","self.base_url = ""https://quote-api.jup.ag/v6""  ||  async def get_quote(  ||  Get quote for token swap from Jupiter.  ||  Jupiter quote response  ||  response = await self.client.get(f""{self.base_url}/quote"", params=params)  ||  quote_data = response.json()  ||  logger.debug(f""Jupiter quote: {amount} {input_mint[:8]}... -> {quote_data.get('outAmount', 0)} {output_mint[:8]}..."")  ||  return quote_data  ||  logger.error(f""Jupiter quote failed: {e}"")  ||  quote: Dict[str, Any],  ||  Get swap transaction from Jupiter quote.  ||  quote: Quote from get_quote()  ||  user_public_key: User's wallet public key  ||  ""quoteResponse"": quote,  ||  address: Wallet address  ||  async def get_jupiter_quote(  ||  Get quote from Jupiter aggregator.  ||  Jupiter quote with route information  ||  return await self.jupiter.get_quote(  ||  quote: Dict[str, Any],  ||  quote: Quote from get_jupiter_quote()  ||  user_public_key: User's wallet public key  ||  quote=quote,  ||  Get token price in SOL using Jupiter quote.  ||  amount: Amount to quote (in token's smallest units)  ||  quote = await self.get_jupiter_quote(  ||  out_amount = Decimal(quote[""outAmount""])"
"D:\dex\backend\app\core\ai_dependencies.py","23792","from __future__ import annotations | import logging | from typing import Optional | from fastapi import Depends | from ..ai.tuner import StrategyAutoTuner, get_auto_tuner, TuningMode | from ..ai.risk_explainer import RiskExplainer, get_risk_explainer, ExplanationStyle | from ..ai.anomaly_detector import AnomalyDetectionSystem, get_anomaly_detector | from ..ai.decision_journal import DecisionJournal, get_decision_journal |     from datetime import datetime |         from datetime import datetime |     from datetime import datetime","from ..ai.risk_explainer import RiskExplainer, get_risk_explainer, ExplanationStyle  ||  async def get_risk_explainer_dependency(  ||  ) -> RiskExplainer:  ||  """"""FastAPI dependency for risk explainer system.  ||  style: Explanation style for risk analysis  ||  RiskExplainer: Initialized risk explainer instance  ||  return await get_risk_explainer(style)  ||  self.risk_explainer_ready = False  ||  self.risk_explainer_ready and  ||  ""risk_explainer"": ""ready"" if self.risk_explainer_ready else ""not_ready"",  ||  # Check Risk Explainer  ||  explainer = await get_risk_explainer()  ||  health_status[""systems""][""risk_explainer""] = {  ||  ""templates_loaded"": len(explainer.risk_templates),  ||  _ai_status.risk_explainer_ready = True  ||  health_status[""systems""][""risk_explainer""] = {  ||  _ai_status.risk_explainer_ready = False  ||  self.risk_explanation_style = ExplanationStyle.INTERMEDIATE  ||  # Safety settings  ||  self.max_risk_budget = 0.05  # 5% max risk per trade  ||  if ""risk_explanation_style"" in config_updates:  ||  self.risk_explanation_style = ExplanationStyle(config_updates[""risk_explanation_style""])  ||  updated_fields.append(""risk_explanation_style"")  ||  # Update risk budget  ||  if ""max_risk_budget"" in config_updates:  ||  risk_budget = float(config_updates[""max_risk_budget""])  ||  if 0.001 <= risk_budget <= 0.10:  # 0.1% to 10% range  ||  self.max_risk_budget = risk_budget  ||  updated_fields.append(""max_risk_budget"")  ||  logger.warning(f""Risk budget {risk_budget} outside allowed range [0.001, 0.10]"")  ||  ""risk_explanation_style"": self.risk_explanation_style.value,  ||  ""max_risk_budget"": self.max_risk_budget,  ||  ""risk_explanations"": 0,  ||  ""avg_risk_explanation_time"": 0.0,  ||  ""risk_explainer_errors"": 0,  ||  risk_explainer: RiskExplainer,  ||  risk_explainer: Risk explainer system  ||  self.risk_explainer = risk_explainer  ||  ""risk_explainer"": {  ||  ""status"": ""ready"" if self.status.risk_explainer_ready else ""not_ready"",  ||  ""style"": self.config.risk_explanation_style.value,  ||  ""templates"": len(self.risk_explainer.risk_templates)  ||  risk_explainer: RiskExplainer = Depends(get_risk_explainer_dependency),  ||  risk_explainer: Risk explainer dependency  ||  risk_explainer=risk_explainer,  ||  ""risk_explainer"": status.risk_explainer_ready,  ||  ""get_risk_explainer_dependency"","
"D:\dex\backend\app\core\auth.py","17245","from __future__ import annotations | import logging | import secrets | from datetime import datetime, timedelta, timezone | from typing import Optional, Dict, Any, Union | from fastapi import HTTPException, status | from jose import JWTError, jwt | from jose.exceptions import ExpiredSignatureError, JWTClaimsError | from passlib.context import CryptContext | from pydantic import BaseModel, validator | from .config import get_settings",""
"D:\dex\backend\app\core\bootstrap.py","33884","from __future__ import annotations | import asyncio | import logging | import os | from contextlib import asynccontextmanager | from datetime import datetime, timezone | from typing import AsyncGenerator, List, Optional | from fastapi import APIRouter, FastAPI, HTTPException | from fastapi.middleware.cors import CORSMiddleware | from .exceptions import exception_handler | from .logging import cleanup_logging, setup_logging | from .middleware import RequestTracingMiddleware, SecurityHeadersMiddleware | from .settings import settings | from ..storage.database import init_database, close_database |         from ..ai.tuner import initialize_auto_tuner, TuningMode |         from ..ai.risk_explainer import get_risk_explainer |         from ..ai.anomaly_detector import get_anomaly_detector |         from ..ai.decision_journal import get_decision_journal |         from ..monitoring.alerts import get_alert_manager |         from ..core.self_test import get_diagnostic_runner |         from ..core.self_test import run_quick_health_check |                 from ..monitoring.alerts import create_critical_alert |             from ..monitoring.alerts import create_system_alert |         from ..monitoring.alerts import create_system_alert |             from ..monitoring.alerts import create_system_alert |             from ..monitoring.alerts import get_alert_manager |     from fastapi import status |             from ..monitoring.alerts import get_alert_manager |         from ..api.ai import router as ai_router |         from ..api.monitoring import router as monitoring_router |         from ..api.diagnostics import router as diagnostics_router |                 from ..monitoring.alerts import record_response_time |                 from ..monitoring.alerts import record_error_rate |             from ..monitoring.alerts import get_alert_manager","# Initialize Risk Explainer (already lazy-loaded)  ||  from ..ai.risk_explainer import get_risk_explainer  ||  await get_risk_explainer()  ||  log.info(""AI Risk Explainer initialized"")  ||  ""risk_score"": 20.0,  ||  ""risk_score"": 25.0,  ||  ""risk_score"": 50.0,  ||  ""risk_score"": 45.0,  ||  ""risk_score"": 80.0,  ||  ""risk_score"": 85.0,  ||  ""risk_score"": preset.get(""risk_score"", 30.0),  ||  ""description"": ""Low-risk new pair snipe""  ||  ""description"": ""High-risk new pair snipe""  ||  ""description"": ""High-risk trending plays""  ||  ""risk_score"": preset.get(""risk_score"", 30.0),  ||  ""reason"": ""Low risk approach for new pair detection"",  ||  {""condition"": ""immediate"", ""name"": ""Immediate"", ""description"": ""Execute immediately""},  ||  ""total_trades"": 0,  ||  ""successful_trades"": 0,  ||  ""total_trades"": 0,  ||  ""winning_trades"": 0,  ||  ""losing_trades"": 0,  ||  ""total_gas_cost_usd"": ""0.00"",  ||  ""daily_trades"": 0,  ||  ""rolling_24h_trades"": 0,  ||  ""daily_risk_score"": 0.0,  ||  ""failed_trades_today"": 0,  ||  ""gas_spent_today_usd"": ""0.00"",  ||  ""average_trade_size_usd"": ""0.00"",  ||  ""largest_trade_usd"": ""0.00"",  ||  ""trades_per_day"": 0.0,  ||  ""total_trades"": 0,  ||  ""total_gas_cost_usd"": ""0.00"","
"D:\dex\backend\app\core\bootstrap_autotrade.py","5525","from __future__ import annotations | import asyncio | import logging | from typing import Dict, Any, Optional | from ..autotrade.integration import get_autotrade_integration | from ..discovery.event_processor import event_processor","DEX Sniper Pro - Enhanced Autotrade Bootstrap.  ||  This module handles the initialization of the complete AI-enhanced autotrade system  ||  including discovery integration, AI pipeline, and secure wallet funding.  ||  File: backend/app/core/bootstrap_autotrade.py  ||  from ..autotrade.integration import get_autotrade_integration  ||  class AutotradeBootstrap:  ||  """"""Bootstrap manager for the AI-enhanced autotrade system.""""""  ||  async def initialize_autotrade_system(self) -> Dict[str, Any]:  ||  Initialize the complete AI-enhanced autotrade system.  ||  return {""status"": ""already_initialized"", ""message"": ""Autotrade system already running""}  ||  logger.info(""Initializing AI-enhanced autotrade system..."")  ||  # Step 2: Get and initialize autotrade integration  ||  self.integration = await get_autotrade_integration()  ||  success_message = ""AI-enhanced autotrade system initialized successfully""  ||  ""autotrade_integration"": integration_status,  ||  ""secure_wallet_funding"": True  ||  logger.error(f""Failed to initialize autotrade system: {e}"")  ||  ""message"": f""Autotrade initialization failed: {str(e)}"",  ||  async def shutdown_autotrade_system(self) -> Dict[str, Any]:  ||  """"""Shutdown the autotrade system gracefully.""""""  ||  logger.info(""Autotrade system shutdown completed"")  ||  ""message"": ""Autotrade system shutdown completed""  ||  logger.error(f""Error during autotrade shutdown: {e}"")  ||  autotrade_bootstrap = AutotradeBootstrap()  ||  async def initialize_autotrade_system() -> Dict[str, Any]:  ||  """"""Initialize the AI-enhanced autotrade system.""""""  ||  return await autotrade_bootstrap.initialize_autotrade_system()  ||  async def shutdown_autotrade_system() -> Dict[str, Any]:  ||  """"""Shutdown the autotrade system.""""""  ||  return await autotrade_bootstrap.shutdown_autotrade_system()  ||  def get_autotrade_system_status() -> Dict[str, Any]:  ||  """"""Get autotrade system status.""""""  ||  return autotrade_bootstrap.get_system_status()"
"D:\dex\backend\app\core\bootstrap_updated.py","20510","from __future__ import annotations | import asyncio | import logging | from typing import Any, Dict, Optional | from fastapi import FastAPI | from fastapi.middleware.cors import CORSMiddleware | from .settings import get_settings | from .middleware import setup_middleware | from .logging import setup_logging | from ..storage.database import initialize_database | from ..chains.evm_client import EVMClient | from ..chains.solana_client import SolanaClient |         from ..api.health import router as health_router |         from ..api.database import router as database_router |         from ..api.presets import router as presets_router |         from ..api.simulation import router as simulation_router |         from ..api.wallet import router as wallet_router |         from ..api.quotes import router as quotes_router |         from ..api.trades import router as trades_router |         from ..api.pairs import router as pairs_router |         from ..api.risk import router as risk_router |         from ..api.analytics import router as analytics_router |         from ..api.orders import router as orders_router |         from ..api.discovery import router as discovery_router |         from ..api.safety import router as safety_router |         from ..api.autotrade import router as autotrade_router |         from ..api.copytrade import router as copytrade_router |         from fastapi import APIRouter |         from ..discovery.mempool_listeners import get_mempool_manager, get_mev_events |         from fastapi import APIRouter |         from ..trading.orderflow.private_submit import get_private_orderflow_manager, get_orderflow_statistics |         from fastapi import APIRouter |         from ..services.telegram_bot import get_telegram_bot |         from fastapi import APIRouter |         from ..services.alpha_feeds import get_alpha_feed_manager, get_alpha_signals |                 from ..dex.arbitrum_adapters import register_arbitrum_dexs |                 from ..strategy.copytrade import start_copy_trading |                 from ..discovery.mempool_listeners import start_mempool_monitoring |                 from ..services.telegram_bot import start_telegram_bot |                 from ..services.alpha_feeds import start_alpha_monitoring |                 from ..ai.tuner import get_tuner |                 from ..ai.anomaly_detector import get_anomaly_detector |             from ..strategy.copytrade import stop_copy_trading |             from ..discovery.mempool_listeners import stop_mempool_monitoring |             from ..services.telegram_bot import stop_telegram_bot |             from ..services.alpha_feeds import stop_alpha_monitoring |         from ..strategy.copytrade import get_copy_trade_manager |         from ..discovery.mempool_listeners import get_mempool_manager |         from ..services.telegram_bot import get_telegram_bot |         from ..services.alpha_feeds import get_alpha_feed_manager","from ..api.wallet import router as wallet_router  ||  from ..api.quotes import router as quotes_router  ||  from ..api.trades import router as trades_router  ||  from ..api.risk import router as risk_router  ||  from ..api.safety import router as safety_router  ||  from ..api.autotrade import router as autotrade_router  ||  from ..api.copytrade import router as copytrade_router  ||  app.include_router(wallet_router, prefix=""/api/v1"")  ||  app.include_router(quotes_router, prefix=""/api/v1"")  ||  app.include_router(trades_router, prefix=""/api/v1"")  ||  app.include_router(risk_router, prefix=""/api/v1"")  ||  app.include_router(safety_router, prefix=""/api/v1"")  ||  app.include_router(autotrade_router, prefix=""/api/v1"")  ||  app.include_router(copytrade_router, prefix=""/api/v1"")  ||  from ..strategy.copytrade import start_copy_trading  ||  from ..strategy.copytrade import stop_copy_trading  ||  from ..strategy.copytrade import get_copy_trade_manager  ||  manager = await get_copy_trade_manager()"
"D:\dex\backend\app\core\config.py","39035","from __future__ import annotations | import logging | import secrets | import sys | from pathlib import Path | from typing import Optional, Dict, List | from decimal import Decimal | from pydantic import validator, Field, SecretStr, ValidationError | from pydantic_settings import BaseSettings |                 import re","# WebSocket Security  ||  websocket_max_connections: int = 100  ||  websocket_max_message_size: int = 65536  # 64KB  ||  websocket_heartbeat_interval: int = 30  ||  websocket_connection_timeout: int = 300  # 5 minutes  ||  websocket_rate_limit_messages: int = 60  ||  websocket_rate_limit_period: int = 60  ||  trading parameters, risk limits, API configurations, and security  ||  default_gas_multiplier: Decimal = Decimal(""1.2"")  ||  max_gas_multiplier: Decimal = Decimal(""3.0"")  ||  # Risk Limits (GBP-based)  ||  max_daily_trades: int = 100  ||  cooldown_between_trades_seconds: int = 1  ||  # Autotrade Settings  ||  autotrade_enabled: bool = False  ||  autotrade_hot_wallet_cap_gbp: Decimal = Decimal(""1000"")  ||  autotrade_max_concurrent_trades: int = 5  ||  autotrade_emergency_stop_enabled: bool = True  ||  # Ledger Configuration  ||  ledger_retention_days: int = 730  ||  ledger_format: str = ""csv""  ||  ledger_backup_enabled: bool = True  ||  ledger_encryption_enabled: bool = False  ||  ""max_position_size_gbp"", ""daily_loss_limit_gbp"", ""autotrade_hot_wallet_cap_gbp""  ||  ""autotrade_enabled"": self.autotrade_enabled,"
"D:\dex\backend\app\core\cors.py","5158","import os | from typing import List, Optional | from fastapi import FastAPI | from fastapi.middleware.cors import CORSMiddleware | from pydantic import BaseSettings |     import logging","""X-Wallet-Type"","
"D:\dex\backend\app\core\dependencies.py","51005","from __future__ import annotations | import hashlib | import logging | import secrets | import time | import uuid  # Add this missing import | from datetime import datetime, timedelta, timezone | from typing import Optional, AsyncGenerator, Dict, Any, List | from fastapi import Depends, HTTPException, status, Header, Request | from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials | from sqlalchemy.ext.asyncio import AsyncSession | from sqlalchemy.orm import Session | from pydantic import BaseModel | from ..storage.database import get_db_session | from ..storage.models import User | from .auth import get_jwt_manager, TokenType, TokenData as JWTTokenData | from .config import get_settings |                 from ..api.wallet import REGISTERED_WALLETS |                     from ..storage.repositories import get_user_repository |                             import uuid as uuid_mod |         from ..strategy.risk_manager import risk_manager |         from ..strategy.safety_controls import safety_controls |         from ..analytics.performance import PerformanceAnalytics |         from ..discovery.event_processor import EventProcessor |         from ..storage.repositories import get_transaction_repository","wallet_address: Optional[str] = None  ||  Get current authenticated user with JWT, API key, and wallet support.  ||  3. Wallet-based session authentication (NEW)  ||  wallet_address=None,  ||  # Method 2: NEW - Wallet-based session authentication  ||  wallet_address = request.headers.get('X-Wallet-Address')  ||  wallet_session_id = request.headers.get('X-Session-ID')  ||  if wallet_address:  ||  ""Attempting wallet authentication"",  ||  'wallet_address': wallet_address[:10] + '...' if len(wallet_address) > 10 else wallet_address,  ||  'has_session_id': bool(wallet_session_id),  ||  'auth_method': 'wallet'  ||  from ..api.wallet import REGISTERED_WALLETS  ||  # Check if wallet is registered  ||  wallet_data = REGISTERED_WALLETS.get(wallet_address.lower())  ||  if wallet_data:  ||  # Try to find or create user for wallet  ||  # Try to find user by session_id from wallet data  ||  if wallet_data.get('session_id'):  ||  user = await user_repo.get_by_session_id(wallet_data['session_id'])  ||  logger.debug(f""Could not find user by wallet session_id: {e}"")  ||  new_session_id = wallet_data.get('session_id') or f""wallet_{uuid_mod.uuid4().hex[:12]}""  ||  default_trade_amount_gbp=100.0,  ||  risk_tolerance=""medium"",  ||  # Update wallet registration with user info  ||  wallet_data['user_id'] = user.id  ||  wallet_data['session_id'] = user.session_id  ||  REGISTERED_WALLETS[wallet_address.lower()] = wallet_data  ||  ""Created user for wallet authentication"",  ||  'wallet_address': wallet_address[:10] + '...',  ||  'auth_method': 'wallet_auto_create'  ||  logger.error(f""Failed to create user for wallet: {e}"")  ||  username=f""wallet_user_{user.id}"",  ||  wallet_address=wallet_address,  ||  auth_method=""wallet"",  ||  ""Wallet authentication successful"",  ||  'wallet_address': wallet_address[:10] + '...',  ||  'auth_method': 'wallet',  ||  f""Wallet authentication error: {e}"",  ||  extra={'extra_data': {**auth_context, 'wallet_address': wallet_address[:10] + '...'}}  ||  wallet_address=None,  ||  username=""dex_trader"",  ||  email=""trader@dexsniper.local"",  ||  wallet_address=wallet_address,  # Include wallet if provided  ||  'wallet_address': wallet_address[:10] + '...' if wallet_address else None  ||  ""supported_methods"": [""JWT"", ""API Key"", ""Wallet""],  ||  ""Wallet"": ""X-Wallet-Address: <address>, X-Session-ID: <session>""  ||  def require_autotrade_mode(  ||  Dependency to require autotrade mode is enabled.  ||  Current user if autotrade is enabled  ||  HTTPException: If autotrade is not enabled  ||  if not settings.autotrade_enabled:  ||  f""Autotrade access denied - mode disabled: {current_user.username}"",  ||  'autotrade_enabled': settings.autotrade_enabled  ||  detail=""Autotrade mode is disabled""  ||  f""Autotrade access granted: {current_user.username}"",  ||  logger.error(f""Autotrade mode check error: {e}"", exc_info=True)  ||  detail=""Autotrade mode validation error""  ||  def get_trade_executor():  ||  Get trade executor instance for executing DEX trades.  ||  This dependency provides access to the trade execution engine  ||  Trade executor instance or mock for development  ||  HTTPException: If trade executor initialization fails  ||  # In production, this would return the actual TradeExecutor instance  ||  class MockTradeExecutor:  ||  """"""Mock trade executor for development with enhanced logging.""""""  ||  self.name = ""MockTradeExecutor""  ||  self.trades_executed = 0  ||  logger.info(""Mock trade executor initialized"")  ||  async def execute_trade(self, trade_params: Dict[str, Any]) -> Dict[str, Any]:  ||  Mock trade execution with detailed logging.  ||  trade_params: Trade parameters  ||  self.trades_executed += 1  ||  ""gas_used"": 150000,  ||  ""amount_out"": trade_params.get(""amount_in"", ""0""),  ||  ""executed_at"": datetime.now(timezone.utc).isoformat(),  ||  ""execution_id"": self.trades_executed  ||  f""Mock trade executed: {mock_tx_hash}"",  ||  'trade_params': trade_params,  ||  logger.error(f""Mock trade execution error: {e}"", exc_info=True)  ||  async def estimate_gas(self, trade_params: Dict[str, Any]) -> int:  ||  """"""Mock gas estimation.""""""  ||  gas_estimate = 150000  ||  f""Mock gas estimation: {gas_estimate}"",  ||  extra={'extra_data': {'trade_params': trade_params}}  ||  return gas_estimate  ||  logger.error(f""Mock gas estimation error: {e}"", exc_info=True)  ||  async def get_quote(self, trade_params: Dict[str, Any]) -> Dict[str, Any]:  ||  """"""Get mock price quote.""""""  ||  quote = {  ||  ""amount_out"": trade_params.get(""amount_in"", ""0""),  ||  ""quoted_at"": datetime.now(timezone.utc).isoformat()  ||  ""Mock quote generated"",  ||  'trade_params': trade_params,  ||  'quote': quote  ||  return quote  ||  logger.error(f""Mock quote generation error: {e}"", exc_info=True)  ||  executor = MockTradeExecutor()  ||  logger.error(f""Trade executor initialization error: {e}"", exc_info=True)  ||  detail=""Trade executor initialization failed""  ||  # Autotrade Service Dependencies (NEW ADDITIONS)  ||  async def get_risk_manager():  ||  FastAPI dependency to get RiskManager instance.  ||  RiskManager: Risk assessment service  ||  from ..strategy.risk_manager import risk_manager  ||  logger.debug(""Retrieved RiskManager instance"")  ||  return risk_manager  ||  logger.error(f""Failed to get RiskManager: {e}"")  ||  detail=""Risk manager not available""  ||  async def get_safety_controls():  ||  FastAPI dependency to get SafetyControls instance.  ||  SafetyControls: Safety controls and circuit breakers  ||  from ..strategy.safety_controls import safety_controls  ||  logger.debug(""Retrieved SafetyControls instance"")  ||  return safety_controls  ||  logger.error(f""Failed to get SafetyControls: {e}"")  ||  detail=""Safety controls not available""  ||  self.trades_tracked = 0  ||  async def track_trade(self, trade_data: Dict[str, Any]) -> None:  ||  """"""Track trade performance.""""""  ||  self.trades_tracked += 1  ||  logger.debug(f""Trade tracked: {self.trades_tracked}"")  ||  ""trades_tracked"": self.trades_tracked,  ||  # WebSocket connection manager (for real-time updates)  ||  Enhanced WebSocket connection manager with logging.  ||  Production should use the unified WebSocket hub from ws/hub.py  ||  async def connect(self, websocket):  ||  Accept and store WebSocket connection.  ||  websocket: WebSocket connection  ||  await websocket.accept()  ||  self.active_connections.append(websocket)  ||  f""WebSocket connection added, total: {len(self.active_connections)}"",  ||  logger.error(f""WebSocket connection error: {e}"", exc_info=True)  ||  def disconnect(self, websocket):  ||  Remove WebSocket connection.  ||  websocket: WebSocket connection to remove  ||  if websocket in self.active_connections:  ||  self.active_connections.remove(websocket)  ||  f""WebSocket connection removed, total: {len(self.active_connections)}"",  ||  logger.error(f""WebSocket disconnect error: {e}"", exc_info=True)  ||  logger.debug(""No WebSocket connections for broadcast"")  ||  logger.warning(f""Failed to send message to WebSocket connection: {e}"")"
"D:\dex\backend\app\core\environment_validator.py","21465","from __future__ import annotations | import logging | import os | import re | from pathlib import Path | from typing import Dict, List, Optional, Tuple, Any | from urllib.parse import urlparse |     import argparse","self.warnings.append(""Rate limiting disabled in production - security risk"")  ||  autotrade_enabled = os.getenv(""AUTOTRADE_ENABLED"", ""false"").lower() == ""true""  ||  if autotrade_enabled and not mainnet_enabled:  ||  self.warnings.append(""Autotrade enabled but mainnet disabled - verify configuration"")  ||  self.warnings.append(""MAX_POSITION_SIZE_GBP should be set for risk management"")  ||  self.warnings.append(""MAX_DAILY_TRADING_GBP should be set for risk management"")  ||  self.warnings.append(""Backups disabled in production - data loss risk"")  ||  self.warnings.append(""High position limits in staging - consider reducing for safety"")  ||  ""WORKERS"", ""LOG_LEVEL"", ""LOG_DIR"", ""MAINNET_ENABLED"", ""AUTOTRADE_ENABLED"","
"D:\dex\backend\app\core\exceptions.py","6109","from __future__ import annotations | import traceback | import uuid | from typing import Any, Dict, Optional | from fastapi import HTTPException, Request, status | from fastapi.responses import JSONResponse | from .logging import get_logger","class RiskError(DEXSniperException):  ||  """"""Raised when risk checks fail.""""""  ||  class WalletError(DEXSniperException):  ||  """"""Raised when wallet operations fail."""""""
"D:\dex\backend\app\core\exception_handlers.py","11867","from __future__ import annotations | import logging | import traceback | from typing import Any, Dict | from fastapi import HTTPException, Request, status | from fastapi.exceptions import RequestValidationError | from fastapi.responses import JSONResponse | from starlette.exceptions import HTTPException as StarletteHTTPException | import logging | import time | from typing import Any, Dict, Optional | from fastapi import HTTPException, Request | from fastapi.responses import JSONResponse | from starlette.exceptions import HTTPException as StarletteHTTPException |         from .logging_config import get_trace_id",""
"D:\dex\backend\app\core\lifespan.py","27538","from __future__ import annotations | import asyncio | import logging | from contextlib import asynccontextmanager | from datetime import datetime, timezone | from typing import AsyncGenerator | from fastapi import FastAPI | from .scheduler import scheduler_manager | from ..chains.evm_client import EvmClient | from ..chains.solana_client import SolanaClient |         from ..middleware.rate_limiting import (  # type: ignore |             from .config import settings  # type: ignore |         from ..middleware.rate_limiting import init_rate_limiter, redis_rate_limiter |             from ..ws.intelligence_hub import intelligence_hub  # type: ignore |             from ..storage.database import init_database  # type: ignore |             from ..core.wallet_registry import wallet_registry  # type: ignore |             from ..chains.rpc_pool import rpc_pool  # type: ignore |             from ..strategy.risk_manager import RiskManager  # type: ignore |             from ..discovery.dexscreener import dexscreener_client  # type: ignore |                         from ..middleware.rate_limiting import (  # type: ignore |             from ..ws.hub import ws_hub  # type: ignore |             from .config import settings  # type: ignore |             from .config import settings  # type: ignore |             from ..middleware.rate_limiting import shutdown_rate_limiter  # type: ignore","async def setup_intelligence_autotrade_bridge(app: FastAPI) -> bool:  ||  Set up the bridge between Intelligence WebSocket Hub and Autotrade WebSocket Hub.  ||  autotrade subscribers in real-time.  ||  logger.info(""Setting up Intelligence-Autotrade WebSocket bridge..."")  ||  logger.error(""Main WebSocket hub not available for bridge"")  ||  logger.error(""Intelligence WebSocket hub not available for bridge"")  ||  await intelligence_hub.register_autotrade_callback(  # type: ignore  ||  ""✅ Intelligence-Autotrade WebSocket bridge established successfully""  ||  logger.info(""   • Intelligence events will route to autotrade subscribers"")  ||  logger.info(""   • Market regime changes will trigger autotrade updates"")  ||  logger.error(""Failed to setup Intelligence-Autotrade bridge: %s"", e)  ||  logger.info(""Intelligence WebSocket hub imported successfully"")  ||  logger.warning(""Intelligence WebSocket hub not available: %s"", e)  ||  # 3. Initialize wallet registry  ||  from ..core.wallet_registry import wallet_registry  # type: ignore  ||  logger.info(""Loading wallet registry..."")  ||  app.state.wallet_registry = wallet_registry  ||  wallets = await wallet_registry.list_wallets()  ||  logger.info(""Wallet registry loaded: %d wallets"", len(wallets))  ||  app.state.wallet_registry_status = ""operational""  ||  startup_warnings.append(f""Wallet registry not available: {e}"")  ||  logger.warning(""Wallet registry not available: %s"", e)  ||  app.state.wallet_registry_status = ""not_available""  ||  startup_warnings.append(f""Wallet registry initialization failed: {e}"")  ||  logger.error(""Wallet registry initialization failed: %s"", e)  ||  app.state.wallet_registry_status = ""failed""  ||  # 5. Initialize risk manager  ||  from ..strategy.risk_manager import RiskManager  # type: ignore  ||  logger.info(""Initializing risk manager..."")  ||  risk_manager = RiskManager()  ||  if hasattr(risk_manager, ""initialize""):  ||  await risk_manager.initialize()  ||  app.state.risk_manager = risk_manager  ||  logger.info(""Risk Manager initialized successfully"")  ||  app.state.risk_manager_status = ""operational""  ||  startup_warnings.append(f""Risk manager not available: {e}"")  ||  logger.warning(""Risk manager not available: %s"", e)  ||  app.state.risk_manager_status = ""not_available""  ||  startup_warnings.append(f""Risk manager initialization failed: {e}"")  ||  logger.error(""Risk manager initialization failed: %s"", e)  ||  app.state.risk_manager_status = ""failed""  ||  logger.info(""Starting Market Intelligence WebSocket hub..."")  ||  if hasattr(app.state, ""wallet_registry"") and app.state.wallet_registry:  ||  async def refresh_wallet_balances() -> None:  ||  """"""Refresh balances for all wallets.""""""  ||  wallets = await app.state.wallet_registry.list_wallets()  ||  ""Refreshing %d wallet balances"", len(wallets)  ||  ""Failed to refresh wallet balances: %s"", e  ||  func=refresh_wallet_balances,  ||  name=""Refresh wallet balances"",  ||  # 9. Start WebSocket hub  ||  logger.info(""Starting WebSocket hub..."")  ||  logger.info(""WebSocket Hub started successfully"")  ||  app.state.websocket_status = ""operational""  ||  startup_warnings.append(f""WebSocket hub not available: {e}"")  ||  logger.warning(""WebSocket hub not available: %s"", e)  ||  app.state.websocket_status = ""not_available""  ||  startup_warnings.append(f""WebSocket hub initialization failed: {e}"")  ||  logger.error(""WebSocket hub initialization failed: %s"", e)  ||  app.state.websocket_status = ""failed""  ||  # 9.5 Setup Intelligence-Autotrade Bridge (NEW)  ||  bridge_success = await setup_intelligence_autotrade_bridge(app)  ||  logger.info(""Intelligence-Autotrade bridge operational"")  ||  ""Intelligence-Autotrade bridge setup failed""  ||  ""Cannot setup bridge - missing WebSocket hub or Intelligence hub""  ||  logger.info(""  WebSocket: ws://127.0.0.1:8001/ws"")  ||  logger.info(""  Intelligence WebSocket: ws://127.0.0.1:8001/ws/intelligence"")  ||  ""wallet_registry"": getattr(  ||  app.state, ""wallet_registry_status"", ""unknown""  ||  ""risk_manager"": getattr(app.state, ""risk_manager_status"", ""unknown""),  ||  ""websocket"": getattr(app.state, ""websocket_status"", ""unknown""),  ||  # 6. Stop WebSocket hub  ||  logger.info(""WebSocket hub stopped successfully"")  ||  shutdown_errors.append(f""WebSocket shutdown: {e}"")"
"D:\dex\backend\app\core\logging.py","8180","from __future__ import annotations | import json | import logging | import logging.handlers | import queue | import threading | import uuid | from datetime import datetime | from pathlib import Path | from typing import Any, Dict, Optional","# Add trace and request IDs if available (using getattr for type safety)  ||  'strategy_id', 'risk_reason', 'preset', 'phase'  ||  # Queue handler for thread safety"
"D:\dex\backend\app\core\logging_config.py","7351","from __future__ import annotations | import json | import logging | import logging.handlers | import sys | import uuid | from datetime import datetime | from pathlib import Path | from typing import Any, Dict, Optional |             import traceback","""strategy_id"", ""risk_reason"", ""request_id"",  ||  logging.getLogger(""websockets"").setLevel(logging.WARNING)"
"D:\dex\backend\app\core\middleware.py","5654","from __future__ import annotations | import time | import uuid | from typing import Callable | from fastapi import Request, Response | from starlette.middleware.base import BaseHTTPMiddleware | from .logging import get_logger | from .settings import settings",""
"D:\dex\backend\app\core\middleware_setup.py","20060","from __future__ import annotations | import logging | import time | from collections import defaultdict, deque | from datetime import datetime, timezone | from typing import Dict, List, Deque | from fastapi import APIRouter, FastAPI, Request, Response | from fastapi.middleware.cors import CORSMiddleware | from starlette.middleware.base import BaseHTTPMiddleware |         from ..middleware.request_validation import RequestValidationMiddleware |         from ..api.intelligence import router as intelligence_router |         from ..api import api_router |         from ..api.websocket import router as websocket_router |         from .config import settings |                 from ..middleware.rate_limiting import FallbackRateLimiter |             from ..middleware.rate_limiting import rate_limit_middleware |                 from ..middleware.rate_limiting import FallbackRateLimiter","FIXED: Added endpoint-specific rate limiting to prevent autotrade polling spam.  ||  class AutotradeRateLimiter(BaseHTTPMiddleware):  ||  Specialized rate limiter for autotrade endpoints.  ||  Initialize autotrade-specific rate limiter.  ||  ""/api/v1/autotrade/status"": 10,      # 10 seconds minimum  ||  ""/api/v1/autotrade/settings"": 30,    # 30 seconds minimum  ||  ""/api/v1/autotrade/metrics"": 15,     # 15 seconds minimum  ||  ""/api/v1/autotrade/queue"": 5,        # 5 seconds minimum  ||  ""/api/v1/autotrade/activities"": 10,  # 10 seconds minimum  ||  ""/api/v1/autotrade/config"": 30,      # 30 seconds minimum  ||  ""Autotrade rate limiter initialized with intervals: %s"",  ||  Process request with autotrade-specific rate limiting.  ||  # Only check autotrade endpoints  ||  if not path.startswith(""/api/v1/autotrade/""):  ||  if path in [""/api/v1/autotrade/start"",  ||  ""/api/v1/autotrade/stop"",  ||  ""/api/v1/autotrade/emergency-stop"",  ||  ""/api/v1/autotrade/mode""]:  ||  ""risk_level"": ""medium"",  ||  IMPORTANT: Middleware is executed in REVERSE order of addition.  ||  Last added = First executed.  ||  # 1. CORS middleware (added last, executed first for preflight)  ||  # 3. Autotrade-specific rate limiting (more specific, higher priority)  ||  app.add_middleware(AutotradeRateLimiter)  ||  logger.info(""Autotrade rate limiter added to prevent polling spam"")  ||  # 4. Request validation middleware (added first, executed last)  ||  (""ledger"", ""Ledger""),  ||  (""wallet"", ""Wallet Management""),  ||  (""quotes"", ""Quote Aggregation""),  ||  (""trades"", ""Trade Execution""),  ||  (""safety"", ""Safety Controls""),  ||  (""risk"", ""Risk Assessment""),  ||  (""autotrade"", ""Automated Trading""),  ||  # Include WebSocket router  ||  from ..api.websocket import router as websocket_router  ||  app.include_router(websocket_router)  ||  logger.info(""WebSocket router registered at /ws"")  ||  logger.warning(f""WebSocket router not available: {e}"")  ||  logger.error(f""Failed to register WebSocket router: {e}"")  ||  'AutotradeRateLimiter'"
"D:\dex\backend\app\core\retry.py","13689","from __future__ import annotations | import asyncio | import functools | import logging | import random | from datetime import datetime, timedelta | from enum import Enum | from typing import Any, Callable, Optional, Type, Union, Tuple |                         import time",""
"D:\dex\backend\app\core\scheduler.py","7610","from __future__ import annotations | import asyncio | import logging | from datetime import datetime | from typing import Any, Callable, Dict, Optional | from apscheduler.schedulers.asyncio import AsyncIOScheduler | from apscheduler.triggers.cron import CronTrigger | from apscheduler.triggers.interval import IntervalTrigger","- Wallet balance refreshes  ||  - Risk cooldown cleanups  ||  - Approval monitoring  ||  func: Function to execute  ||  async def check_approvals():  ||  """"""Check and manage token approvals.""""""  ||  logger.info(""Checking token approvals"")  ||  # This will be implemented by approval manager"
"D:\dex\backend\app\core\self_test.py","45971","from __future__ import annotations | import asyncio | import json | import logging | import os | import time | from collections import defaultdict | from dataclasses import dataclass, field | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from pathlib import Path | from typing import Any, Callable, Dict, List, Optional, Tuple, Union | import httpx | import psutil | from pydantic import BaseModel | from ..chains.evm_client import EVMClient | from ..chains.solana_client import SolanaClient | from ..core.settings import get_settings | from ..storage.database import get_database | from ..monitoring.alerts import get_alert_manager, create_system_alert |             from ..api.quotes import get_quote |             from ..ai.tuner import get_auto_tuner |             from ..ai.risk_explainer import get_risk_explainer |             from ..ai.anomaly_detector import get_anomaly_detector |             from ..ai.decision_journal import get_decision_journal","- Trading engine functional testing with canary trades  ||  result = await conn.execute(""SELECT 1"")  ||  result = await conn.execute(""PRAGMA journal_mode"")  ||  integrity_result = await conn.execute(""PRAGMA integrity_check"")  ||  fk_result = await conn.execute(""PRAGMA foreign_key_check"")  ||  tables_result = await conn.execute(  ||  count_result = await conn.execute(f""SELECT COUNT(*) FROM {table}"")  ||  async def test_quote_generation() -> TestResult:  ||  """"""Test quote generation functionality.""""""  ||  test_id=""quote_generation"",  ||  name=""Quote Generation"",  ||  description=""Test DEX quote generation and aggregation"",  ||  # Test quote for WETH/USDC on Ethereum (well-known pair)  ||  from ..api.quotes import get_quote  ||  quote_params = {  ||  quote_result = await get_quote(quote_params)  ||  quote_time = (time.time() - start_time) * 1000  ||  ""quote_time_ms"": round(quote_time, 2),  ||  ""quote_generated"": quote_result is not None,  ||  ""test_parameters"": quote_params  ||  if quote_result:  ||  ""estimated_output"": quote_result.get(""amount_out"", ""N/A""),  ||  ""dex_used"": quote_result.get(""dex"", ""N/A""),  ||  ""gas_estimate"": quote_result.get(""gas_estimate"", ""N/A"")  ||  if quote_time > 2000:  ||  warnings.append(f""Slow quote generation: {quote_time:.0f}ms"")  ||  if not quote_result:  ||  warnings.append(""Quote generation failed"")  ||  if quote_time > 5000:  ||  recommendations.append(""Optimize quote generation or check RPC performance"")  ||  if not quote_result:  ||  success = quote_result is not None and quote_time < 5000  ||  test.complete(False, f""Quote generation test failed: {e}"")  ||  from ..ai.risk_explainer import get_risk_explainer  ||  # Test Risk Explainer  ||  explainer = await get_risk_explainer()  ||  ai_results[""risk_explainer""] = {  ||  ""template_count"": len(explainer.risk_templates)  ||  ai_results[""risk_explainer""] = {  ||  await conn.execute(""SELECT 1"")  ||  TradingEngineDiagnostics.test_quote_generation"
"D:\dex\backend\app\core\settings.py","9535","from __future__ import annotations | import os | import secrets | from pathlib import Path | from typing import Any, Dict, List, Optional | from pydantic import Field, field_validator | from pydantic_settings import BaseSettings","autotrade_enabled: bool = False  # Enable autotrade bot  ||  ledger_retention_days: int = 730  ||  default_per_trade_cap_gbp: float = 75.0  ||  default_gas_multiplier_cap: float = 1.25  # +25%  ||  daily_loss_action: str = ""disable_autotrade""  # disable_autotrade, stop_all, notify_only  ||  walletconnect_project_id: Optional[str] = None  ||  hot_wallet_max_balance_gbp: float = 1000.0  ||  require_canary_trades: bool = True  ||  ledgers_dir: Path = Field(default_factory=lambda: Path(""data/ledgers""))  ||  @field_validator(""data_dir"", ""logs_dir"", ""ledgers_dir"", ""sims_dir"", ""keystores_dir"", mode=""before"")"
"D:\dex\backend\app\core\wallet_registry.py","17685","from __future__ import annotations | import asyncio | import json | import logging | import secrets | from datetime import datetime, timezone | from decimal import Decimal | from pathlib import Path | from typing import Dict, List, Optional, Tuple | from cryptography.fernet import Fernet | from cryptography.hazmat.primitives import hashes, serialization | from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC | from eth_account import Account | from eth_account.signers.local import LocalAccount | from solders.keypair import Keypair | from solders.pubkey import Pubkey | from ..core.settings import settings | import logging | from ..storage.repositories import WalletRepository, get_wallet_repository","Wallet registry for managing encrypted keystores and hot wallet operations.  ||  from ..storage.repositories import WalletRepository, get_wallet_repository  ||  class WalletSecurityError(Exception):  ||  """"""Raised when wallet security operations fail.""""""  ||  class WalletRegistry:  ||  Manages encrypted wallet keystores and hot wallet operations.  ||  """"""Initialize wallet registry.""""""  ||  # Runtime wallet cache (encrypted keys only)  ||  self._wallet_locks: Dict[str, asyncio.Lock] = {}  ||  logger.info(""Wallet registry initialized"")  ||  async def create_hot_wallet(  ||  wallet_label: str = ""hot_wallet"",  ||  Create new encrypted hot wallet for specified chain.  ||  wallet_label: Human-readable wallet label  ||  Dict with wallet address and keystore path  ||  WalletSecurityError: If wallet creation fails  ||  raise WalletSecurityError(""Emergency mode active - wallet operations disabled"")  ||  # Generate wallet based on chain  ||  # EVM wallet generation  ||  ""wallet_type"": ""hot_wallet"",  ||  ""label"": wallet_label,  ||  # Solana wallet generation  ||  ""wallet_type"": ""hot_wallet"",  ||  ""label"": wallet_label,  ||  raise WalletSecurityError(f""Unsupported chain: {chain}"")  ||  keystore_filename = f""{chain}_{wallet_label}_{address[:8].lower()}.json""  ||  wallet_key = f""{chain}:{address}""  ||  self._cached_keystores[wallet_key] = keystore_data  ||  self._session_passphrases[wallet_key] = passphrase  ||  self._wallet_locks[wallet_key] = asyncio.Lock()  ||  f""Hot wallet created: {address[:10]}... on {chain}"",  ||  'wallet_label': wallet_label,  ||  ""wallet_label"": wallet_label,  ||  logger.error(f""Failed to create hot wallet: {e}"")  ||  raise WalletSecurityError(f""Wallet creation failed: {e}"")  ||  async def load_wallet(  ||  Load encrypted wallet from keystore file.  ||  Wallet information dict  ||  WalletSecurityError: If loading fails  ||  raise WalletSecurityError(""Emergency mode active - wallet operations disabled"")  ||  raise WalletSecurityError(f""Keystore file not found: {keystore_path}"")  ||  raise WalletSecurityError(f""Invalid keystore: missing {field}"")  ||  raise WalletSecurityError(""Invalid passphrase"")  ||  wallet_key = f""{chain}:{address}""  ||  self._cached_keystores[wallet_key] = keystore_data  ||  self._session_passphrases[wallet_key] = passphrase  ||  self._wallet_locks[wallet_key] = asyncio.Lock()  ||  f""Wallet loaded: {address[:10]}... on {chain}"",  ||  ""wallet_label"": keystore_data.get(""label"", ""unknown""),  ||  logger.error(f""Failed to load wallet: {e}"")  ||  raise WalletSecurityError(f""Wallet loading failed: {e}"")  ||  address: Wallet address  ||  WalletSecurityError: If key retrieval fails  ||  raise WalletSecurityError(""Emergency mode active - signing disabled"")  ||  wallet_key = f""{chain}:{address}""  ||  if wallet_key not in self._cached_keystores:  ||  raise WalletSecurityError(f""Wallet not loaded: {address}"")  ||  if wallet_key not in self._session_passphrases:  ||  raise WalletSecurityError(f""Passphrase not available for: {address}"")  ||  async with self._wallet_locks[wallet_key]:  ||  keystore_data = self._cached_keystores[wallet_key]  ||  passphrase = self._session_passphrases[wallet_key]  ||  raise WalletSecurityError(f""Key retrieval failed: {e}"")  ||  Emergency drain hot wallet to cold wallet.  ||  source_address: Hot wallet address to drain  ||  destination_address: Cold wallet destination  ||  WalletSecurityError: If drain fails  ||  # 2. Calculate gas for transfer  ||  raise WalletSecurityError(f""Emergency drain failed: {e}"")  ||  async def list_wallets(self) -> List[Dict[str, str]]:  ||  List all available wallet keystores.  ||  List of wallet information dicts  ||  wallets = []  ||  wallet_info = {  ||  wallets.append(wallet_info)  ||  logger.error(f""Failed to list wallets: {e}"")  ||  return wallets  ||  raise WalletSecurityError(f""Encryption failed: {e}"")  ||  raise WalletSecurityError(f""Decryption failed: {e}"")  ||  """"""Clear session data for wallet (passphrase, cache).""""""  ||  wallet_key = f""{chain}:{address}""  ||  if wallet_key in self._session_passphrases:  ||  del self._session_passphrases[wallet_key]  ||  if wallet_key in self._cached_keystores:  ||  del self._cached_keystores[wallet_key]  ||  if wallet_key in self._wallet_locks:  ||  del self._wallet_locks[wallet_key]  ||  f""Session cleared for wallet: {address[:10]}..."",  ||  logger.warning(""Emergency mode reset - wallet operations re-enabled"")  ||  # Global wallet registry instance  ||  wallet_registry = WalletRegistry()"
"D:\dex\backend\app\core\__init__.py","3","False",""
"D:\dex\backend\app\dex\arbitrum_adapters.py","17596","from __future__ import annotations | import logging | from decimal import Decimal | from typing import Any, Dict, List, Optional, Tuple | from ..chains.evm_client import EVMClient | from .base import DEXAdapter, QuoteRequest, QuoteResponse, TradeRequest, TradeResponse |         import random","- Arbitrum-specific transaction handling and gas optimization  ||  from .base import DEXAdapter, QuoteRequest, QuoteResponse, TradeRequest, TradeResponse  ||  async def get_quote(self, request: QuoteRequest) -> QuoteResponse:  ||  """"""Get quote from Camelot.""""""  ||  if request.trade_type == ""buy"":  ||  # Estimate gas (Arbitrum has lower gas costs)  ||  gas_estimate = await self._estimate_gas_cost(request)  ||  return QuoteResponse(  ||  gas_estimate=gas_estimate,  ||  valid_until=self._get_quote_expiry(),  ||  logger.error(f""Error getting Camelot quote: {e}"")  ||  return QuoteResponse(  ||  async def execute_trade(self, request: TradeRequest) -> TradeResponse:  ||  """"""Execute trade on Camelot.""""""  ||  if request.trade_type == ""buy"":  ||  # Execute transaction  ||  value=request.amount if request.trade_type == ""buy"" else Decimal(""0"")  ||  return TradeResponse(  ||  logger.error(f""Error executing Camelot trade: {e}"")  ||  return TradeResponse(  ||  async def get_quote(self, request: QuoteRequest) -> QuoteResponse:  ||  """"""Get quote from Uniswap V3 on Arbitrum.""""""  ||  best_quote = None  ||  # Get quote for this fee tier  ||  quote_amount = await self._get_quote_for_fee_tier(request, fee_tier)  ||  if quote_amount > Decimal(""0""):  ||  if best_quote is None or quote_amount > best_quote:  ||  best_quote = quote_amount  ||  if best_quote is None:  ||  raise Exception(""No valid quotes found"")  ||  price_impact = await self._calculate_price_impact(request, best_quote)  ||  # Estimate gas (lower on Arbitrum)  ||  gas_estimate = await self._estimate_gas_cost(request)  ||  return QuoteResponse(  ||  output_amount=best_quote,  ||  gas_estimate=gas_estimate,  ||  valid_until=self._get_quote_expiry(),  ||  logger.error(f""Error getting Uniswap V3 Arbitrum quote: {e}"")  ||  return QuoteResponse(  ||  async def _get_quote_for_fee_tier(self, request: QuoteRequest, fee_tier: Decimal) -> Decimal:  ||  """"""Get quote for specific fee tier.""""""  ||  # Mock implementation - would use actual Uniswap V3 quoter  ||  if random.random() < 0.8:  # 80% chance of successful quote  ||  async def get_quote(self, request: QuoteRequest) -> QuoteResponse:  ||  """"""Get quote from SushiSwap on Arbitrum.""""""  ||  if request.trade_type == ""buy"":  ||  # Estimate gas  ||  gas_estimate = await self._estimate_gas_cost(request)  ||  return QuoteResponse(  ||  gas_estimate=gas_estimate,  ||  valid_until=self._get_quote_expiry(),  ||  logger.error(f""Error getting SushiSwap Arbitrum quote: {e}"")  ||  return QuoteResponse(  ||  async def get_best_quote(self, request: QuoteRequest) -> Optional[QuoteResponse]:  ||  """"""Get best quote across all Arbitrum DEXs.""""""  ||  quotes = []  ||  # Get quotes from all adapters  ||  quote = await adapter.get_quote(request)  ||  if quote.output_amount > Decimal(""0""):  ||  quotes.append(quote)  ||  logger.error(f""Error getting quote from {name}: {e}"")  ||  if not quotes:  ||  # Return best quote (highest output amount)  ||  best_quote = max(quotes, key=lambda q: q.output_amount)  ||  return best_quote  ||  async def execute_best_trade(self, request: TradeRequest) -> Optional[TradeResponse]:  ||  """"""Execute trade on the best DEX.""""""  ||  # Get best quote first  ||  quote_request = QuoteRequest(  ||  trade_type=request.trade_type  ||  best_quote = await self.get_best_quote(quote_request)  ||  if not best_quote:  ||  # Execute on the best DEX  ||  adapter = self.adapters.get(best_quote.dex_name)  ||  return await adapter.execute_trade(request)  ||  ""gas_price_l1"": ""20 gwei"",  ||  ""gas_price_l2"": ""0.1 gwei"",  ||  base_cost = Decimal(""0.01"")  # Base L1 gas cost"
"D:\dex\backend\app\dex\hyperliquid.py","18732","from __future__ import annotations | import asyncio | import logging | import time | from decimal import Decimal | from typing import Any, Dict, List, Optional, Tuple | from datetime import datetime, timezone, timedelta | import httpx | from pydantic import BaseModel | from .base import DEXAdapter, QuoteRequest, QuoteResponse, TradeRequest, TradeResponse | from ..chains.evm_client import EVMClient","from .base import DEXAdapter, QuoteRequest, QuoteResponse, TradeRequest, TradeResponse  ||  quote_asset: str  ||  Provides ultra-low latency quotes and execution for spot and perpetual markets  ||  self.websocket_url = ""wss://api.hyperliquid.xyz/ws""  ||  async def get_quote(self, request: QuoteRequest) -> QuoteResponse:  ||  Get quote from Hyperliquid with ultra-low latency.  ||  request: Quote request parameters  ||  QuoteResponse with best available pricing  ||  Exception: If quote fails or market not supported  ||  # Calculate quote based on trade type and size  ||  if request.trade_type == ""buy"":  ||  output_amount, avg_price = await self._calculate_buy_quote(  ||  output_amount, avg_price = await self._calculate_sell_quote(  ||  # Estimate gas costs (minimal on Hyperliquid L1)  ||  gas_estimate = Decimal(""0.001"")  # ~$0.001 USD  ||  # Log successful quote  ||  f""Hyperliquid quote: {symbol} - {request.trade_type} {request.amount} ""  ||  'trade_type': request.trade_type,  ||  return QuoteResponse(  ||  gas_estimate=gas_estimate,  ||  valid_until=self._get_quote_expiry(),  ||  logger.error(f""Hyperliquid quote failed: {e}"", exc_info=True)  ||  async def execute_trade(self, request: TradeRequest) -> TradeResponse:  ||  Execute trade on Hyperliquid with advanced order routing.  ||  request: Trade execution request  ||  TradeResponse with execution details  ||  # Execute order through Hyperliquid API  ||  side=""buy"" if request.trade_type == ""buy"" else ""sell"",  ||  return TradeResponse(  ||  output_amount=Decimal(str(order_result.get(""executed_amount"", 0))),  ||  gas_used=Decimal(""0.001""),  # Minimal on Hyperliquid  ||  gas_price=Decimal(""0.001""),  ||  logger.error(f""Hyperliquid trade execution failed: {e}"")  ||  return TradeResponse(  ||  quote_asset=""USD"",  ||  async def _calculate_buy_quote(  ||  """"""Calculate buy quote using order book or market price.""""""  ||  trade_size = min(remaining_amount, size)  ||  total_cost += trade_size * price  ||  remaining_amount -= trade_size  ||  async def _calculate_sell_quote(  ||  """"""Calculate sell quote using order book or market price.""""""  ||  trade_size = min(remaining_amount, size)  ||  total_received += trade_size * price  ||  remaining_amount -= trade_size  ||  quote_symbol = symbol_mapping.get(token_out.upper(), token_out.upper())  ||  # Hyperliquid primarily trades against USD  ||  if quote_symbol == ""USD"" or quote_symbol == ""USDC"":  ||  return quote_symbol  ||  ""executed_amount"": float(amount),  ||  def _error_response(self, request: QuoteRequest, error: str) -> QuoteResponse:  ||  """"""Create error quote response.""""""  ||  return QuoteResponse(  ||  def _get_quote_expiry(self) -> datetime:  ||  """"""Get quote expiration time."""""""
"D:\dex\backend\app\dex\jupiter.py","14270","from __future__ import annotations | import asyncio | import logging | import time | from decimal import Decimal | from typing import Any, Dict, List, Optional | import httpx | import logging","JUPITER_API_BASE = ""https://quote-api.jup.ag/v6""  ||  async def get_quote(  ||  Get quote for token swap via Jupiter aggregator.  ||  Quote data with Jupiter routing information  ||  # Get quote from Jupiter API  ||  quote_data = await self._get_jupiter_quote(  ||  if not quote_data:  ||  # Extract quote information  ||  output_amount_lamports = int(quote_data.get(""outAmount"", ""0""))  ||  price_impact_pct = quote_data.get(""priceImpactPct"", 0)  ||  route_plan = quote_data.get(""routePlan"", [])  ||  ""jupiter_quote"": {  ||  ""input_mint"": quote_data.get(""inputMint""),  ||  ""output_mint"": quote_data.get(""outputMint""),  ||  ""in_amount"": quote_data.get(""inAmount""),  ||  ""out_amount"": quote_data.get(""outAmount""),  ||  ""other_amount_threshold"": quote_data.get(""otherAmountThreshold""),  ||  ""swap_mode"": quote_data.get(""swapMode""),  ||  f""Quote failed for {self.dex_name}: {e}"",  ||  async def _get_jupiter_quote(  ||  Get quote from Jupiter API.  ||  Jupiter quote response or None if failed  ||  f""{self.api_base}/quote"",  ||  quote_data = response.json()  ||  if ""outAmount"" not in quote_data:  ||  logger.warning(f""Invalid Jupiter response: {quote_data}"")  ||  return quote_data"
"D:\dex\backend\app\dex\pancake.py","17568","from __future__ import annotations | import asyncio | import logging | import time | from decimal import Decimal | from typing import Any, Dict, List, Optional, Tuple |     from web3 import Web3 |     from web3.exceptions import ContractLogicError |     from web3.providers import HTTPProvider |     import logging | import logging","GAS_ESTIMATE_V2_SWAP = 150000  # PancakeSwap V2 typically uses less gas than V3  ||  async def get_quote(  ||  Get quote for token swap using PancakeSwap V2/V3.  ||  Quote data with routing information  ||  # Get quote using V2 router  ||  quote_result = await self._get_v2_quote(  ||  if not quote_result:  ||  quote_result = await self._get_v2_quote(  ||  if not quote_result:  ||  amount_out = Decimal(quote_result[-1]) / Decimal(10**18)  # Last amount in path  ||  ""gas_estimate"": GAS_ESTIMATE_V2_SWAP,  ||  f""Quote failed for {self.dex_name} on {chain}: {e}"",  ||  async def _get_v2_quote(  ||  Get quote using V2 router getAmountsOut.  ||  logger.debug(f""V2 quote failed for path {path}: {e}"")  ||  Estimate price impact based on trade size.  ||  # Simple heuristic: larger trades = more impact"
"D:\dex\backend\app\dex\quickswap.py","4033","from __future__ import annotations | import logging | from decimal import Decimal | from typing import Any, Dict, List, Optional | from .uniswap_v2 import UniswapV2Adapter","This adapter provides QuickSwap V2 integration for quote fetching and trade building  ||  self.default_gas_limit = 180_000  # Polygon typically uses less gas  ||  async def get_quote(  ||  Get QuickSwap quote for token swap.  ||  Quote information with QuickSwap routing  ||  return await super().get_quote("
"D:\dex\backend\app\dex\uniswap_v2.py","36225","from __future__ import annotations | import asyncio | import logging | import time | import uuid | from decimal import Decimal | from typing import Any, Dict, List, Optional, Tuple | from web3 import Web3 | from web3.exceptions import ContractLogicError, Web3Exception | import logging |                 from ..chains.rpc_pool import rpc_pool |             from web3 import HTTPProvider","Uniswap V2 DEX adapter for quote calculation and trade execution.  ||  GAS_ESTIMATE_SWAP = 150000  # Standard Uniswap V2 swap gas units  ||  # Native token placeholder address used in quotes.py  ||  # Gas price defaults (in gwei) for different chains  ||  DEFAULT_GAS_PRICES = {  ||  Uniswap V2 adapter for quote calculation and transaction building.  ||  Handles pair discovery, quote calculation, price impact estimation,  ||  async def _get_current_gas_price(self, w3: Web3, chain: str, trace_id: str) -> Dict[str, Any]:  ||  Get current gas price and calculate costs.  ||  Dictionary with gas price info and cost calculations  ||  # Try to get current gas price from the network  ||  gas_price_wei = await asyncio.to_thread(w3.eth.gas_price)  ||  gas_price_gwei = Decimal(gas_price_wei) / Decimal(10**9)  ||  f""Current gas price fetched: {gas_price_gwei} gwei"",  ||  'gas_price_gwei': float(gas_price_gwei)  ||  # Fallback to default gas prices  ||  gas_price_gwei = Decimal(DEFAULT_GAS_PRICES.get(chain, 30))  ||  f""Failed to fetch gas price, using default: {gas_price_gwei} gwei - {e}"",  ||  'default_gas_price': float(gas_price_gwei)  ||  # Calculate gas cost in ETH/BNB/MATIC  ||  gas_units = GAS_ESTIMATE_SWAP  ||  gas_cost_wei = Decimal(gas_units) * Decimal(gas_price_gwei) * Decimal(10**9)  ||  gas_cost_eth = gas_cost_wei / Decimal(10**18)  ||  gas_cost_usd = gas_cost_eth * native_price_usd  ||  ""gas_units"": gas_units,  ||  ""gas_price_gwei"": float(gas_price_gwei),  ||  ""gas_cost_eth"": float(gas_cost_eth),  ||  ""gas_cost_usd"": float(gas_cost_usd),  ||  async def get_quote(  ||  Get quote for token swap.  ||  Quote data with price, impact, and execution details  ||  f""Getting quote from {self.dex_name}"",  ||  # Get current gas prices early  ||  gas_info = await self._get_current_gas_price(w3, chain, trace_id)  ||  'gas_price_gwei': gas_info['gas_price_gwei']  ||  ""gas_estimate"": gas_info[""gas_units""],  # Keep for backward compatibility  ||  ""gas_info"": gas_info,  # New detailed gas information  ||  f""Quote successful for {self.dex_name}"",  ||  'gas_cost_usd': gas_info['gas_cost_usd'],  ||  'gas_price_gwei': gas_info['gas_price_gwei'],  ||  f""Quote failed for {self.dex_name} on {chain}: {e}"",  ||  ""error"": f""Quote execution failed: {str(e)}"",  ||  Calculate price impact for the trade.  ||  f""Trade would drain liquidity completely"",  ||  # Return conservative estimate based on trade size  ||  trade_size_ratio = amount_in / Decimal(""1000"")  # Assume 1000 token pool  ||  return min(trade_size_ratio * Decimal(""0.01""), Decimal(""0.1""))  # Max 10%"
"D:\dex\backend\app\dex\uniswap_v3.py","45993","from __future__ import annotations | import asyncio | import logging | import time | from decimal import Decimal | from typing import Any, Dict, List, Optional, Tuple | from web3 import Web3 | from web3.exceptions import ContractLogicError | import logging |         from web3 import HTTPProvider","GAS_ESTIMATE_V3_SWAP = 200000  # Uniswap V3 typically uses more gas  ||  Handles fee tier discovery, quote calculation with concentrated liquidity,  ||  - Primary quoter contract integration with V2 interface  ||  - Fallback direct pool calculation when quoters fail  ||  self.quoter_addresses = self._get_quoter_addresses()  ||  # Quoter V2 ABI (more efficient than V1)  ||  self.quoter_abi = [  ||  ""name"": ""quoteExactInputSingle"",  ||  {""internalType"": ""uint256"", ""name"": ""gasEstimate"", ""type"": ""uint256""}  ||  def _get_quoter_addresses(self) -> Dict[str, str]:  ||  """"""Get Quoter V2 addresses for each chain.""""""  ||  ""ethereum"": ""0x61fFE014bA17989E743c5F6cB21bF9697530B21e"",  # QuoterV2  ||  async def get_quote(  ||  Get quote for token swap with fee tier enumeration.  ||  Uses primary quoter contract with fallback to direct pool calculation  ||  when quoter contracts fail or revert.  ||  Quote data with best fee tier and price impact  ||  if chain not in self.quoter_addresses:  ||  # Phase 1: Try quoter contracts first  ||  best_quote = None  ||  best_gas_estimate = GAS_ESTIMATE_V3_SWAP  ||  quotes_by_tier = {}  ||  quoter_success = False  ||  quoter_address = self.quoter_addresses[chain]  ||  quoter_contract = w3.eth.contract(  ||  address=w3.to_checksum_address(quoter_address),  ||  abi=self.quoter_abi  ||  quote_result = await self._get_single_quote(  ||  quoter_contract, token_in_addr, token_out_addr,  ||  if quote_result:  ||  amount_out, sqrt_price_after, ticks_crossed, gas_est = quote_result  ||  quotes_by_tier[fee_tier] = {  ||  ""gas_estimate"": gas_est,  ||  # Track best quote (highest output)  ||  if best_quote is None or amount_out > best_quote:  ||  best_quote = amount_out  ||  best_gas_estimate = gas_est  ||  quoter_success = True  ||  f""Fee tier {fee_tier} quoter failed for {self.dex_name}: {fee_error}"",  ||  # Phase 2: Fallback to direct pool calculation if quoter failed  ||  if best_quote is None:  ||  f""Quoter contracts failed, trying direct pool calculation for {self.dex_name}"",  ||  'fallback_reason': 'quoter_failure'  ||  direct_result = await self._get_quote_from_pool_direct(  ||  amount_out, price_impact_calc, gas_estimate = direct_result  ||  if best_quote is None or amount_out_wei > best_quote:  ||  best_quote = amount_out_wei  ||  best_gas_estimate = gas_estimate  ||  # Store for quotes_by_tier  ||  quotes_by_tier[fee_tier] = {  ||  ""gas_estimate"": gas_estimate,  ||  if best_quote is None:  ||  ""error"": ""No valid quotes found via quoter or direct calculation"",  ||  amount_out = Decimal(best_quote) / Decimal(10**token_out_decimals)  ||  # Log successful quote  ||  f""Quote successful for {self.dex_name}"",  ||  'method': 'quoter' if quoter_success else 'direct_pool',  ||  ""gas_estimate"": int(best_gas_estimate),  ||  ""quotes_by_tier"": {  ||  ""gas_estimate"": int(data[""gas_estimate""]),  ||  for tier, data in quotes_by_tier.items()  ||  ""quote_method"": ""quoter"" if quoter_success else ""direct_pool""  ||  f""Quote failed for {self.dex_name} on {chain}: {e}"",  ||  async def _get_quote_from_pool_direct(  ||  Get quote directly from pool state (fallback when quoter fails).  ||  without relying on quoter contracts.  ||  Tuple of (amount_out, price_impact, gas_estimate) or None if failed  ||  # Estimate price impact based on trade size vs liquidity  ||  trade_to_liquidity_ratio = amount_in / liquidity_decimal  ||  price_impact = min(trade_to_liquidity_ratio * Decimal(""0.01""), Decimal(""0.05""))  ||  # Standard V3 gas estimate  ||  gas_estimate = 180000  ||  f""Direct pool quote successful for {self.dex_name}"",  ||  return amount_out, price_impact, gas_estimate  ||  async def _get_single_quote(  ||  quoter_contract: Any,  ||  Get quote for a single fee tier using quoter contract.  ||  quoter_contract: Quoter contract instance  ||  Tuple of (amount_out, sqrt_price_after, ticks_crossed, gas_estimate) or None  ||  quoter_contract.functions.quoteExactInputSingle(  ||  # QuoterV2 returns tuple: (amountOut, sqrtPriceX96After, initializedTicksCrossed, gasEstimate)  ||  # Fallback for QuoterV1 or other variants  ||  return result[0], 0, 0, GAS_ESTIMATE_V3_SWAP  ||  f""Quoter call failed for fee tier {fee_tier}: {e}"",  ||  trade_to_liquidity_ratio = amount_in / liquidity_decimal  ||  base_impact = trade_to_liquidity_ratio * Decimal(""0.1"")  # 10% per unit ratio  ||  Estimate price impact based on trade size and fee tier.  ||  # Simple heuristic: larger trades and higher fees = more impact  ||  return chain in self.quoter_addresses"
"D:\dex\backend\app\dex\__init__.py","36051","from __future__ import annotations | import logging | import traceback | import time | from typing import Dict, List, Optional, Any, Union | from decimal import Decimal |     from .uniswap_v3 import uniswap_v3_adapter, pancake_v3_adapter |     from .pancake import pancake_v2_adapter |     from .uniswap_v2 import uniswap_v2_adapter, pancake_adapter, quickswap_adapter |     from .jupiter import jupiter_adapter |                 import inspect |         import asyncio","enabling quote aggregation and trade execution across multiple protocols.  ||  Registry for managing DEX adapters and routing quotes.  ||  and performing quote aggregation across multiple protocols with  ||  if hasattr(uniswap_v3_adapter, 'get_quote'):  ||  logger.warning(""Uniswap V3 adapter missing get_quote method"")  ||  if hasattr(pancake_v3_adapter, 'get_quote'):  ||  logger.warning(""PancakeSwap V3 adapter missing get_quote method"")  ||  if hasattr(pancake_v2_adapter, 'get_quote'):  ||  logger.warning(""PancakeSwap V2 adapter missing get_quote method"")  ||  if hasattr(uniswap_v2_adapter, 'get_quote'):  ||  logger.warning(""Uniswap V2 adapter missing get_quote method"")  ||  if hasattr(pancake_adapter, 'get_quote'):  ||  logger.warning(""Pancake adapter missing get_quote method"")  ||  if hasattr(quickswap_adapter, 'get_quote'):  ||  logger.warning(""QuickSwap adapter missing get_quote method"")  ||  if hasattr(jupiter_adapter, 'get_quote'):  ||  logger.warning(""Jupiter adapter missing get_quote method"")  ||  async def get_quote(  ||  Get quote from specific DEX adapter with comprehensive error handling.  ||  Quote result dictionary  ||  trace_id = f""quote_{int(time.time() * 1000)}""  ||  error_msg = ""Missing required parameters for quote request""  ||  # Check get_quote method exists  ||  if not hasattr(adapter, 'get_quote'):  ||  error_msg = f""Adapter {dex_name} missing get_quote method""  ||  # Execute quote with method signature inspection  ||  sig = inspect.signature(adapter.get_quote)  ||  f""Executing quote for {dex_name} on {chain}"",  ||  result = await adapter.get_quote(  ||  result = await adapter.get_quote(  ||  f""Quote successful: {dex_name} on {chain}"",  ||  f""Quote failed: {dex_name} on {chain} - {result.get('error', 'Unknown error')}"",  ||  error_msg = f""Quote execution failed: {str(adapter_error)}""  ||  f""Quote execution error for {dex_name} on {chain}: {adapter_error}"",  ||  f""Critical error in get_quote: {e}"",  ||  async def get_quotes_from_multiple_dexs(  ||  Get quotes from multiple DEXs concurrently with comprehensive error handling.  ||  logger.warning(""Empty DEX list provided to get_quotes_from_multiple_dexs"")  ||  f""Getting quotes from {len(dex_names)} DEXs on {chain}"",  ||  task = self.get_quote(  ||  # Execute with timeout protection  ||  timeout=30.0  # 30 second timeout for all quotes  ||  logger.error(f""Quote requests timed out after 30 seconds for chain {chain}"")  ||  ""error"": ""Quote requests timed out"",  ||  quotes = []  ||  ""error"": f""Exception during quote: {str(result)}"",  ||  quotes.append(error_dict)  ||  quotes.append(result)  ||  ""error"": f""Invalid quote result format: {type(result)}"",  ||  quotes.append(error_dict)  ||  f""Quote aggregation completed for {chain}: {successful_count} successful, {failed_count} failed"",  ||  'successful_quotes': successful_count,  ||  'failed_quotes': failed_count,  ||  return quotes  ||  f""Critical error in get_quotes_from_multiple_dexs: {e}"",  ||  async def get_best_quote(  ||  Get the best quote across all available adapters for a chain.  ||  quotes = await self.get_quotes_from_multiple_dexs(  ||  # Filter successful quotes and find the best one  ||  successful_quotes = [q for q in quotes if q.get(""success"", False)]  ||  if not successful_quotes:  ||  failed_errors = [q.get(""error"", ""Unknown error"") for q in quotes]  ||  # Find quote with highest output amount  ||  best_quote = max(  ||  successful_quotes,  ||  logger.error(f""Error finding best quote: {e}"")  ||  # Return first successful quote as fallback  ||  best_quote = successful_quotes[0]  ||  best_quote[""quote_comparison""] = {  ||  ""total_quotes"": len(quotes),  ||  ""successful_quotes"": len(successful_quotes),  ||  ""best_dex"": best_quote.get(""dex""),  ||  for q in successful_quotes if q != best_quote  ||  return best_quote  ||  logger.error(f""Critical error in get_best_quote: {e}"", exc_info=True)  ||  ""error"": f""Critical error finding best quote: {str(e)}"","
"D:\dex\backend\app\discovery\chain_watchers.py","21767","from __future__ import annotations | import asyncio | import time | from decimal import Decimal | from typing import Dict, List, Optional, Any, Callable | from dataclasses import dataclass | from enum import Enum | from web3 import Web3 | from web3.types import FilterParams, LogReceipt | from websockets.exceptions import ConnectionClosed | import logging | from ..core.settings import settings","from websockets.exceptions import ConnectionClosed"
"D:\dex\backend\app\discovery\dexscreener.py","25638","from __future__ import annotations | import asyncio | import time | from decimal import Decimal | from typing import Dict, List, Optional, Any | from dataclasses import dataclass | from enum import Enum | import httpx | import logging | from ..core.settings import settings","quote_token: TokenInfo  ||  liquidity_quote: Optional[Decimal] = None  ||  ""risk_indicators"": [],  ||  pair_info.quote_token.address.lower()  ||  ""quote_token"": {  ||  ""address"": pair_info.quote_token.address,  ||  ""name"": pair_info.quote_token.name,  ||  ""symbol"": pair_info.quote_token.symbol,  ||  ""decimals"": pair_info.quote_token.decimals,  ||  # Generate risk indicators  ||  risk_indicators = []  ||  risk_indicators.append(""no_liquidity"")  ||  risk_indicators.append(""low_liquidity"")  ||  risk_indicators.append(""no_price_data"")  ||  risk_indicators.append(""low_volume"")  ||  risk_indicators.append(""low_activity"")  ||  risk_indicators.append(""very_new_pair"")  ||  validation_result[""risk_indicators""] = risk_indicators  ||  'risk_indicators': len(validation_result[""risk_indicators""]),  ||  # Extract base and quote token information  ||  quote_token_data = pair_data.get(""quoteToken"", {})  ||  quote_token = TokenInfo(  ||  address=quote_token_data.get(""address"", """"),  ||  name=quote_token_data.get(""name"", """"),  ||  symbol=quote_token_data.get(""symbol"", """"),  ||  decimals=quote_token_data.get(""decimals""),  ||  total_supply=quote_token_data.get(""totalSupply""),  ||  logo_uri=quote_token_data.get(""logoURI""),  ||  quote_token=quote_token,  ||  liquidity_quote=safe_decimal(pair_data.get(""liquidity"", {}).get(""quote"")),"
"D:\dex\backend\app\discovery\dexscreener_watcher.py","13206","from __future__ import annotations | import asyncio | import logging | from datetime import datetime, timezone | from typing import Dict, List, Any, Optional | from decimal import Decimal | import time | import httpx | from pydantic import BaseModel | from ..core.settings import get_settings | from ..services.token_metadata import TokenMetadataService | from ..strategy.risk_scoring import RiskManager","from ..strategy.risk_scoring import RiskManager  ||  quote_token: Dict[str, Any]  ||  self.risk_manager = RiskManager()  ||  quote_token = pair_data.get('quoteToken', {})  ||  if not base_token.get('address') or not quote_token.get('address'):  ||  # Calculate basic risk score  ||  risk_score = await self._calculate_basic_risk_score(pair_data)  ||  # Determine risk flags  ||  risk_flags = self._determine_risk_flags(pair_data)  ||  ""address"": quote_token.get('address'),  ||  ""symbol"": quote_token.get('symbol', 'UNKNOWN'),  ||  ""name"": quote_token.get('name', 'Unknown Token'),  ||  ""risk_score"": risk_score,  ||  ""risk_flags"": risk_flags,  ||  async def _calculate_basic_risk_score(self, pair_data: Dict[str, Any]) -> int:  ||  """"""Calculate a basic risk score from available data.""""""  ||  return 50  # Default medium risk  ||  def _determine_risk_flags(self, pair_data: Dict[str, Any]) -> List[str]:  ||  """"""Determine risk flags based on pair data."""""""
"D:\dex\backend\app\discovery\event_processor.py","52615","from __future__ import annotations | import asyncio | import time | import uuid | from decimal import Decimal | from typing import Dict, List, Optional, Any, Callable | from dataclasses import dataclass | from enum import Enum | from .chain_watchers import PairCreatedEvent, LiquidityEvent | from .dexscreener import dexscreener_client, DexscreenerResponse | from ..strategy.risk_manager import risk_manager, RiskAssessment | from ..services.security_providers import security_provider | from ..ai.market_intelligence import MarketIntelligenceEngine | from ..services.pricing import PricingService | import logging |     from ..autotrade.pipeline import AIAutotradesPipeline  # type: ignore |         from ..ai.autotrade_pipeline import AIAutotradesPipeline  # type: ignore |     from ..ai.market_intelligence import get_market_intelligence_engine |     from ..ai.tuner import get_auto_tuner |     from ..ws.intelligence_hub import get_intelligence_hub |     from ..autotrade.engine import get_autotrade_engine","Event processing pipeline for discovered pairs with validation and risk assessment.  ||  from ..strategy.risk_manager import risk_manager, RiskAssessment  ||  # AI Autotrade pipeline factory (added)  ||  from ..autotrade.pipeline import AIAutotradesPipeline  # type: ignore  ||  from ..ai.autotrade_pipeline import AIAutotradesPipeline  # type: ignore  ||  AIAutotradesPipeline = None  # type: ignore  ||  async def get_ai_autotrade_pipeline() -> AIAutotradesPipeline:  ||  """"""Get AI autotrade pipeline instance.  ||  if AIAutotradesPipeline is None:  ||  ""AIAutotradesPipeline class could not be imported from expected modules.""  ||  from ..autotrade.engine import get_autotrade_engine  ||  return AIAutotradesPipeline(  ||  websocket_hub=await get_intelligence_hub(),  ||  autotrade_engine=await get_autotrade_engine(),  ||  RISK_ASSESSING = ""risk_assessing""  ||  EXCELLENT = ""excellent""  # High liquidity, low risk, good metadata  ||  GOOD = ""good""           # Moderate liquidity, acceptable risk  ||  FAIR = ""fair""           # Low liquidity or higher risk  ||  POOR = ""poor""           # Very risky or problematic  ||  BLOCKED = ""blocked""     # Critical risks - do not trade  ||  """"""Fully processed pair with all validation and risk data.""""""  ||  quote_token_name: Optional[str] = None  ||  quote_token_symbol: Optional[str] = None  ||  # Risk assessment  ||  risk_assessment: Optional[RiskAssessment] = None  ||  risk_assessment_time_ms: Optional[float] = None  ||  tradeable: bool = False  ||  risk_warnings: List[str] = None  ||  if self.risk_warnings is None:  ||  self.risk_warnings = []  ||  Event processing pipeline that combines discovery, validation, and risk assessment.  ||  with comprehensive risk assessment and AI-enhanced opportunity scoring.  ||  ProcessingStatus.RISK_ASSESSING: [],  ||  ""critical_coordination"": 80.0,  # Block trade  ||  ""negative_sentiment"": -0.4,     # Risk warning  ||  # Step 3: Risk assessment  ||  await self._assess_risk(processed_pair)  ||  if processed_pair.tradeable:  ||  'tradeable': processed_pair.tradeable,  ||  'risk_level': processed_pair.risk_assessment.overall_risk.value if processed_pair.risk_assessment else None,  ||  quote_token = token_metadata.get(""quote_token"", {})  ||  processed_pair.quote_token_name = quote_token.get(""name"")  ||  processed_pair.quote_token_symbol = quote_token.get(""symbol"")  ||  # Add risk indicators from validation  ||  risk_indicators = validation_result.get(""risk_indicators"", [])  ||  for indicator in risk_indicators:  ||  processed_pair.risk_warnings.append(""No liquidity detected"")  ||  processed_pair.risk_warnings.append(""Low liquidity detected"")  ||  processed_pair.risk_warnings.append(""Low trading volume"")  ||  processed_pair.risk_warnings.append(""Very new pair (< 1 hour)"")  ||  # Apply AI-based trade filtering  ||  self._apply_ai_trade_filtering(processed_pair, intelligence_analysis)  ||  'coordination_risk': intelligence_analysis.get('coordination_risk', 0),  ||  coordination_risk = intelligence_analysis.get('coordination_risk', 0.0)      # 0-100  ||  processed_pair.risk_warnings.append(  ||  # Coordination Risk Impact (safety factor)  ||  if coordination_risk >= self.ai_thresholds[""critical_coordination""]:  ||  processed_pair.risk_warnings.append(  ||  f""AI: CRITICAL coordination risk ({coordination_risk:.1f}%)""  ||  elif coordination_risk >= self.ai_thresholds[""high_coordination""]:  ||  processed_pair.risk_warnings.append(  ||  f""AI: HIGH coordination risk ({coordination_risk:.1f}%)""  ||  processed_pair.risk_warnings.append(  ||  processed_pair.risk_warnings.append(""AI: Bear market regime detected"")  ||  processed_pair.risk_warnings.append(""AI: High volatility market regime"")  ||  processed_pair.risk_warnings.append(  ||  'coordination_risk': coordination_risk,  ||  def _apply_ai_trade_filtering(  ||  """"""Apply AI-based trade filtering to remove high-risk opportunities.""""""  ||  coordination_risk = intelligence_analysis.get('coordination_risk', 0.0)  ||  whale_dump_risk = intelligence_analysis.get('whale_dump_risk', False)  ||  if coordination_risk >= self.ai_thresholds[""critical_coordination""]:  ||  processed_pair.tradeable = False  ||  processed_pair.risk_warnings.append(""BLOCKED by AI: Critical coordination risk"")  ||  processed_pair.tradeable = False  ||  processed_pair.risk_warnings.append(""BLOCKED by AI: Market manipulation detected"")  ||  elif whale_dump_risk:  ||  processed_pair.tradeable = False  ||  processed_pair.risk_warnings.append(""BLOCKED by AI: Whale dump risk detected"")  ||  f""Failed to apply AI trade filtering: {e}"",  ||  async def _assess_risk(self, processed_pair: ProcessedPair):  ||  """"""Perform comprehensive risk assessment.""""""  ||  processed_pair.processing_status = ProcessingStatus.RISK_ASSESSING  ||  await self._notify_callbacks(ProcessingStatus.RISK_ASSESSING, processed_pair)  ||  risk_start = time.time()  ||  # For now, we'll simulate the risk assessment  ||  # Perform risk assessment on the non-native token  ||  # For now, assess risk on token0  ||  risk_assessment = await risk_manager.assess_token_risk(  ||  trade_amount=processed_pair.liquidity_usd / 10 if processed_pair.liquidity_usd else None,  ||  processed_pair.risk_assessment = risk_assessment  ||  processed_pair.risk_assessment_time_ms = (time.time() - risk_start) * 1000  ||  ""risk_factors"": security_data.risk_factors,  ||  if risk_assessment.warnings:  ||  processed_pair.risk_warnings.extend(risk_assessment.warnings)  ||  if risk_assessment.recommendations:  ||  processed_pair.trading_recommendations.extend(risk_assessment.recommendations)  ||  f""Risk assessment completed for {processed_pair.pair_address}"",  ||  'risk_level': risk_assessment.overall_risk.value,  ||  'risk_score': risk_assessment.overall_score,  ||  'tradeable': risk_assessment.tradeable,  ||  'assessment_time_ms': processed_pair.risk_assessment_time_ms,  ||  processed_pair.errors.append(f""Risk assessment failed: {str(e)}"")  ||  logger.error(f""Risk assessment error for {processed_pair.pair_address}: {e}"")  ||  This combines traditional liquidity/risk analysis with AI intelligence insights  ||  tradeable = False  ||  processed_pair.risk_warnings.append(""Pair not found in Dexscreener"")  ||  processed_pair.risk_warnings.append(""No liquidity detected"")  ||  elif processed_pair.risk_assessment and not processed_pair.risk_assessment.tradeable:  ||  processed_pair.risk_warnings.append(""Risk assessment blocked trading"")  ||  coordination_risk = processed_pair.intelligence_data.get('coordination_risk', 0.0)  ||  # AI Risk Downgrade Logic  ||  if coordination_risk >= self.ai_thresholds[""critical_coordination""]:  ||  processed_pair.risk_warnings.append(""BLOCKED: Critical AI coordination risk"")  ||  elif coordination_risk >= self.ai_thresholds[""high_coordination""]:  ||  # Downgrade for high coordination risk  ||  processed_pair.risk_warnings.append(""DOWNGRADED: High AI coordination risk"")  ||  processed_pair.risk_warnings.append(""DOWNGRADED: Low AI intelligence score"")  ||  # Traditional risk assessment downgrade  ||  if processed_pair.risk_assessment:  ||  risk_level = processed_pair.risk_assessment.overall_risk.value  ||  if risk_level == ""critical"":  ||  elif risk_level == ""high"" and opportunity_level == OpportunityLevel.EXCELLENT:  ||  elif risk_level == ""high"":  ||  tradeable = opportunity_level != OpportunityLevel.BLOCKED  ||  processed_pair.trading_recommendations.append(""POOR: High risk - consider avoiding"")  ||  processed_pair.tradeable = tradeable  ||  'tradeable': tradeable,  ||  if pair.opportunity_level.value >= min_level.value and pair.tradeable"
"D:\dex\backend\app\ledger\archival.py","26820","from __future__ import annotations | import gzip | import logging | import shutil | from datetime import datetime, timedelta | from pathlib import Path | from typing import Any, Dict, List, Optional, Tuple | import pandas as pd | from sqlalchemy import and_, or_, select, text | from sqlalchemy.ext.asyncio import AsyncSession | from ..core.settings import settings | from ..storage.database import get_session_context | from ..storage.models import LedgerEntry | from ..storage.repositories import LedgerRepository | from .exporters import LedgerExporter |                             from sqlalchemy import select","This module handles the archival of ledger data according to the 730-day retention  ||  from ..storage.models import LedgerEntry  ||  from ..storage.repositories import LedgerRepository  ||  from .exporters import LedgerExporter  ||  class LedgerArchivalManager:  ||  Manages archival of historical ledger data with compression and retention.  ||  self.ledger_dir = settings.ledgers_dir  ||  self.archive_dir = self.ledger_dir / ""archives""  ||  self.temp_dir = self.ledger_dir / ""temp""  ||  self.exporter = LedgerExporter()  ||  Archive ledger data for a specific month.  ||  # Get all users with ledger entries in this month  ||  # Parse date from filename (format: ledger_user_X_YYYYMM_*.*)  ||  Restore ledger data from archive file.  ||  ledger_repo = LedgerRepository(session)  ||  stmt = select(LedgerEntry).where(LedgerEntry.trace_id == row['trace_id'])  ||  result = await check_session.execute(stmt)  ||  # Create new ledger entry  ||  'wallet_address': row['wallet_address'],  ||  for col in ['gas_fee_gbp', 'gas_fee_native', 'token_symbol', 'token_address',  ||  await ledger_repo.create_entry(**entry_data)  ||  """"""Get list of user IDs with ledger data in the specified period.""""""  ||  FROM ledger_entries  ||  result = await session.execute(  ||  csv_file = await self.exporter.export_user_ledger_csv(  ||  archive_filename = f""ledger_user_{user_id}_{month_str}.csv""  ||  # Expected format: ledger_user_X_YYYYMM.csv or ledger_user_X_YYYYMMDD_HHMMSS.csv"
"D:\dex\backend\app\ledger\exporters.py","22076","from __future__ import annotations | import csv | import logging | from datetime import datetime, timedelta | from decimal import Decimal | from pathlib import Path | from typing import Any, Dict, List, Optional, Union | import pandas as pd | from sqlalchemy import and_, or_ | from sqlalchemy.ext.asyncio import AsyncSession | from ..core.settings import settings | from ..storage.database import get_session_context | from ..storage.models import LedgerEntry | from ..storage.repositories import LedgerRepository","Enhanced ledger export functionality with multiple formats and advanced filtering.  ||  ledger system, supporting CSV, XLSX, and specialized tax export formats.  ||  from ..storage.models import LedgerEntry  ||  from ..storage.repositories import LedgerRepository  ||  class LedgerExporter:  ||  Enhanced ledger exporter with multiple format support and advanced filtering.  ||  """"""Initialize ledger exporter.""""""  ||  self.export_dir = settings.ledgers_dir / ""exports""  ||  async def export_user_ledger_csv(  ||  include_gas_fees: bool = True,  ||  Export user's ledger to CSV with advanced filtering.  ||  include_gas_fees: Whether to include gas fee entries  ||  filename = f""ledger_user_{user_id}_{timestamp}.csv""  ||  include_gas_fees=include_gas_fees,  ||  'chain', 'wallet_address', 'amount_gbp', 'amount_native',  ||  'transaction_id', 'gas_fee_gbp', 'gas_fee_native',  ||  'wallet_address': entry.wallet_address,  ||  'gas_fee_gbp': str(entry.metadata.get('gas_fee_gbp', '')) if entry.metadata else '',  ||  'gas_fee_native': str(entry.metadata.get('gas_fee_native', '')) if entry.metadata else '',  ||  async def export_user_ledger_xlsx(  ||  include_gas_fees: bool = True,  ||  Export user's ledger to XLSX with formatting and optional summary sheet.  ||  include_gas_fees: Whether to include gas fee entries  ||  filename = f""ledger_user_{user_id}_{timestamp}.xlsx""  ||  include_gas_fees=include_gas_fees,  ||  'Wallet': entry.wallet_address,  ||  'Gas Fee (GBP)': float(entry.metadata.get('gas_fee_gbp', 0)) if entry.metadata and entry.metadata.get('gas_fee_gbp') else None,  ||  'Gas Fee (Native)': float(entry.metadata.get('gas_fee_native', 0)) if entry.metadata and entry.metadata.get('gas_fee_native') else None,  ||  'Wallet', 'Amount (GBP)', 'Amount (Native)', 'Currency',  ||  'Gas Fee (GBP)', 'Gas Fee (Native)', 'Token Symbol',  ||  # Main ledger sheet  ||  df.to_excel(writer, sheet_name='Ledger', index=False)  ||  worksheet = writer.sheets['Ledger']  ||  include_gas_fees: bool = True,  ||  include_gas_fees: Whether to include gas fees in cost basis  ||  include_gas_fees=include_gas_fees,  ||  include_gas_fees: bool = True,  ||  ) -> List[LedgerEntry]:  ||  """"""Get filtered ledger entries based on criteria.""""""  ||  ledger_repo = LedgerRepository(session)  ||  filters.append(LedgerEntry.created_at >= start_date)  ||  filters.append(LedgerEntry.created_at <= end_date)  ||  filters.append(LedgerEntry.entry_type.in_(entry_types))  ||  filters.append(LedgerEntry.chain.in_(chains))  ||  filters.append(LedgerEntry.amount_gbp >= min_amount_gbp)  ||  if not include_gas_fees:  ||  filters.append(LedgerEntry.entry_type != 'gas_fee')  ||  entries = await ledger_repo.get_user_ledger(  ||  async def _create_summary_data(self, entries: List[LedgerEntry]) -> List[Dict[str, Any]]:  ||  entries: List[LedgerEntry],"
"D:\dex\backend\app\ledger\integrity.py","32776","from __future__ import annotations | import logging | from datetime import datetime, timedelta | from decimal import Decimal | from typing import Any, Dict, List, Optional, Set, Tuple | from sqlalchemy import and_, func, or_, select, text, update | from sqlalchemy.ext.asyncio import AsyncSession | from ..core.settings import settings | from ..storage.database import get_session_context | from ..storage.models import LedgerEntry, Transaction | from ..storage.repositories import LedgerRepository, TransactionRepository","Ledger integrity verification and repair system.  ||  ledger system, including data validation, consistency checks, and repair capabilities.  ||  from ..storage.models import LedgerEntry, Transaction  ||  from ..storage.repositories import LedgerRepository, TransactionRepository  ||  affected_entries: List of ledger entry IDs affected  ||  class LedgerIntegrityChecker:  ||  Comprehensive ledger integrity verification and repair system.  ||  duplicate entries, and calculation errors in the ledger system.  ||  Run comprehensive integrity check on ledger data.  ||  Verify integrity of a specific ledger entry.  ||  entry_id: Ledger entry ID to verify  ||  stmt = select(LedgerEntry).where(LedgerEntry.id == entry_id)  ||  result = await session.execute(stmt)  ||  stmt = select(func.count(LedgerEntry.id)).where(LedgerEntry.trace_id == entry.trace_id)  ||  result = await session.execute(stmt)  ||  result = await session.execute(stmt)  ||  """"""Check for duplicate trace IDs in the ledger.""""""  ||  FROM ledger_entries  ||  result = await session.execute(text(base_query))  ||  """"""Check for ledger entries with invalid transaction references.""""""  ||  # Find ledger entries with transaction IDs that don't exist  ||  FROM ledger_entries le  ||  result = await session.execute(text(query))  ||  FROM ledger_entries  ||  result = await session.execute(text(query))  ||  FROM ledger_entries  ||  result = await session.execute(text(query))  ||  # you'd track running balances per token per wallet  ||  SELECT wallet_address, chain, currency,  ||  FROM ledger_entries  ||  GROUP BY wallet_address, chain, currency  ||  result = await session.execute(text(query))  ||  wallet_address, chain, currency, net_balance = row  ||  description=f""Negative balance for {currency} in wallet {wallet_address[:10]}... on {chain}"",  ||  'wallet_address': wallet_address,  ||  FROM ledger_entries le  ||  result = await session.execute(text(query))  ||  FROM ledger_entries  ||  result = await session.execute(text(query))  ||  FROM ledger_entries  ||  result = await session.execute(text(query))  ||  FROM ledger_entries  ||  result = await session.execute(text(query))  ||  stmt = select(LedgerEntry).where(LedgerEntry.id == entry_id)  ||  result = await session.execute(stmt)  ||  update(LedgerEntry)  ||  .where(LedgerEntry.id == entry_id)  ||  await session.execute(stmt)  ||  update(LedgerEntry)  ||  .where(LedgerEntry.id == entry_id)  ||  await session.execute(stmt)  ||  update(LedgerEntry)  ||  .where(LedgerEntry.id == entry_id)  ||  await session.execute(stmt)"
"D:\dex\backend\app\ledger\ledger_writer.py","15281","from __future__ import annotations | import csv | import logging | from datetime import datetime | from decimal import Decimal | from pathlib import Path | from typing import Any, Dict, List, Optional | import pandas as pd | from sqlalchemy.ext.asyncio import AsyncSession | from ..core.settings import settings | from ..storage.database import get_session_context | from ..storage.models import LedgerEntry | from ..storage.repositories import LedgerRepository","Ledger writer for atomic transaction logging and export functionality.  ||  from ..storage.models import LedgerEntry  ||  from ..storage.repositories import LedgerRepository  ||  class LedgerWriter:  ||  Atomic ledger writer with CSV/XLSX export capabilities.  ||  """"""Initialize ledger writer.""""""  ||  self.ledger_dir = settings.ledgers_dir  ||  self._ensure_ledger_directory()  ||  def _ensure_ledger_directory(self) -> None:  ||  """"""Ensure ledger directory exists.""""""  ||  self.ledger_dir.mkdir(parents=True, exist_ok=True)  ||  logger.debug(f""Ledger directory: {self.ledger_dir}"")  ||  async def write_trade_entry(  ||  trade_type: str,  # buy, sell  ||  wallet_address: str,  ||  gas_fee_native: Optional[Decimal] = None,  ||  gas_fee_gbp: Optional[Decimal] = None,  ||  ) -> LedgerEntry:  ||  Write a trade entry to the ledger.  ||  trade_type: Type of trade (buy/sell)  ||  wallet_address: Wallet address  ||  gas_fee_native: Gas fee in native currency  ||  gas_fee_gbp: Gas fee in GBP  ||  dex: DEX used for trade  ||  slippage: Executed slippage  ||  Created LedgerEntry  ||  description_parts = [f""{trade_type.upper()} {token_symbol}""]  ||  signed_amount_native = amount_native if trade_type == ""buy"" else -amount_native  ||  signed_amount_gbp = amount_gbp if trade_type == ""buy"" else -amount_gbp  ||  ledger_repo = LedgerRepository(session)  ||  # Create main trade entry  ||  trade_entry = await ledger_repo.create_entry(  ||  entry_type=""trade"",  ||  wallet_address=wallet_address,  ||  # Create gas fee entry if provided  ||  if gas_fee_native and gas_fee_gbp:  ||  await ledger_repo.create_entry(  ||  amount_gbp=-gas_fee_gbp,  # Always negative (cost)  ||  amount_native=-gas_fee_native,  ||  description=f""Gas fee for {trade_type} {token_symbol}"",  ||  wallet_address=wallet_address,  ||  f""Ledger entry created: {trade_type} {token_symbol}"",  ||  return trade_entry  ||  async def write_approval_entry(  ||  wallet_address: str,  ||  gas_fee_native: Decimal,  ||  gas_fee_gbp: Decimal,  ||  ) -> LedgerEntry:  ||  Write an approval entry to the ledger.  ||  wallet_address: Wallet address  ||  gas_fee_native: Gas fee in native currency  ||  gas_fee_gbp: Gas fee in GBP  ||  Created LedgerEntry  ||  ledger_repo = LedgerRepository(session)  ||  approval_entry = await ledger_repo.create_entry(  ||  amount_gbp=-gas_fee_gbp,  # Always negative (cost)  ||  amount_native=-gas_fee_native,  ||  wallet_address=wallet_address,  ||  f""Approval ledger entry created: {token_symbol}"",  ||  'gas_fee_gbp': float(gas_fee_gbp),  ||  return approval_entry  ||  async def export_user_ledger_csv(  ||  Export user's ledger to CSV file.  ||  filename = f""ledger_user_{user_id}_{timestamp}.csv""  ||  filepath = self.ledger_dir / filename  ||  ledger_repo = LedgerRepository(session)  ||  # Get all ledger entries for user  ||  entries = await ledger_repo.get_user_ledger(  ||  'chain', 'wallet_address', 'amount_gbp', 'amount_native',  ||  'wallet_address': entry.wallet_address,  ||  async def export_user_ledger_xlsx(  ||  Export user's ledger to XLSX file with formatting.  ||  filename = f""ledger_user_{user_id}_{timestamp}.xlsx""  ||  filepath = self.ledger_dir / filename  ||  ledger_repo = LedgerRepository(session)  ||  # Get all ledger entries for user  ||  entries = await ledger_repo.get_user_ledger(  ||  'Wallet': entry.wallet_address,  ||  'Wallet', 'Amount (GBP)', 'Amount (Native)', 'Currency',  ||  df.to_excel(writer, sheet_name='Ledger', index=False)  ||  worksheet = writer.sheets['Ledger']  ||  # Global ledger writer instance  ||  ledger_writer = LedgerWriter()"
"D:\dex\backend\app\middleware\rate_limiting.py","30103","from __future__ import annotations | import asyncio | import logging | import time | from collections import defaultdict, deque | from datetime import datetime, timedelta | from enum import Enum | from typing import Any, Dict, List, Optional, Tuple | from fastapi.responses import JSONResponse | import redis.asyncio as redis | from fastapi import HTTPException, Request, Response, status | from pydantic import BaseModel | from slowapi import Limiter | from starlette.middleware.base import BaseHTTPMiddleware | import logging | import time | from collections import defaultdict, deque | from typing import DefaultDict, Deque | from fastapi import HTTPException, Request, status | from starlette.middleware.base import BaseHTTPMiddleware |             from ..core.config import settings |         from ..core.config import settings","if any(endpoint in path for endpoint in ['/trades', '/orders', '/wallet']):  ||  # Execute pipeline  ||  results = await pipe.execute()"
"D:\dex\backend\app\middleware\request_validation.py","19760","from __future__ import annotations | import asyncio | import json | import logging | import re | import time | from typing import Any, Dict, List, Optional, Set | from fastapi import HTTPException, Request, Response, status | from starlette.middleware.base import BaseHTTPMiddleware | from starlette.responses import JSONResponse","'/api/v1/trades',  ||  '/api/v1/quotes',  ||  '/api/v1/wallet',  ||  re.compile(r""(\bexec\b|\bexecute\b)"", re.IGNORECASE),"
"D:\dex\backend\app\middleware\__init__.py","1054","from __future__ import annotations |     from .rate_limiting import (",""
"D:\dex\backend\app\monitoring\alerts.py","34951","from __future__ import annotations | import asyncio | import json | import logging | import smtplib | import time | from collections import defaultdict, deque | from dataclasses import dataclass, field | from datetime import datetime, timedelta | from decimal import Decimal | from email.mime.multipart import MIMEMultipart | from email.mime.text import MIMEText | from enum import Enum | from typing import Any, Callable, Deque, Dict, List, Optional, Set, Union | from urllib.parse import urljoin | import httpx | from pydantic import BaseModel, Field | from ..core.settings import get_settings",""
"D:\dex\backend\app\reporting\pnl.py","31462","from __future__ import annotations | import logging | from collections import defaultdict, deque | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Tuple | from sqlalchemy import and_, func, select, text | from sqlalchemy.ext.asyncio import AsyncSession | from ..core.settings import settings | from ..storage.database import get_session_context | from ..storage.models import LedgerEntry | from ..storage.repositories import LedgerRepository |                 import json |         import json |         import json","from ..storage.models import LedgerEntry  ||  from ..storage.repositories import LedgerRepository  ||  TRADE_BY_TRADE = ""trade_by_trade""  # Calculate PnL for each trade  ||  class TradeLot:  ||  trade_id: Optional[int] = None,  ||  """"""Initialize trade lot.""""""  ||  self.trade_id = trade_id  ||  def take_quantity(self, amount: Decimal) -> Optional[TradeLot]:  ||  New TradeLot with the taken quantity, or None if insufficient  ||  taken_lot = TradeLot(  ||  trade_id=self.trade_id,  ||  'trade_id': self.trade_id,  ||  """"""Represents a complete PnL calculation for a trade.""""""  ||  trade_date: datetime,  ||  trade_type: str,  ||  lots_used: List[TradeLot],  ||  self.trade_date = trade_date  ||  self.trade_type = trade_type  ||  days = (self.trade_date - lot.purchase_date).days  ||  'trade_date': self.trade_date.isoformat(),  ||  'trade_type': self.trade_type,  ||  self.position_lots: Dict[str, deque[TradeLot]] = defaultdict(deque)  # token_key -> lots  ||  # Get all trades for the user  ||  trades = await self._get_user_trades(user_id, start_date, end_date)  ||  # Process trades chronologically  ||  for trade in trades:  ||  pnl_calc = await self._process_trade(trade)  ||  if pnl_calc and pnl_calc.trade_type == 'sell':  ||  token_key = self._get_token_key(trade)  ||  'trades_processed': len(self.pnl_calculations),  ||  # Get trades for this specific token  ||  trades = await self._get_token_trades(user_id, token_address, chain, start_date, end_date)  ||  # Process trades  ||  for trade in trades:  ||  await self._process_trade(trade)  ||  if calc.trade_type == 'sell'  ||  'trade_calculations': [calc.to_dict() for calc in self.pnl_calculations],  ||  'trades_count': len(period_result['trade_calculations']),  ||  async def _get_user_trades(  ||  """"""Get all trades for a user in chronological order.""""""  ||  FROM ledger_entries  ||  result = await session.execute(text(query), params)  ||  trades = []  ||  trades.append({  ||  return trades  ||  async def _get_token_trades(  ||  """"""Get trades for a specific token.""""""  ||  all_trades = await self._get_user_trades(user_id, start_date, end_date)  ||  token_trades = []  ||  for trade in all_trades:  ||  if trade['chain'] == chain:  ||  metadata = json.loads(trade['metadata']) if isinstance(trade['metadata'], str) else trade['metadata']  ||  token_trades.append(trade)  ||  return token_trades  ||  async def _process_trade(self, trade: Dict[str, Any]) -> Optional[PnLCalculation]:  ||  """"""Process a single trade and update position lots.""""""  ||  metadata = json.loads(trade['metadata']) if isinstance(trade['metadata'], str) else trade['metadata']  ||  logger.warning(f""Invalid metadata for trade {trade['id']}"")  ||  token_key = self._get_token_key(trade)  ||  if trade['entry_type'] == 'buy':  ||  return await self._process_buy_trade(trade, token_key, amount_tokens)  ||  elif trade['entry_type'] == 'sell':  ||  return await self._process_sell_trade(trade, token_key, amount_tokens)  ||  async def _process_buy_trade(  ||  trade: Dict[str, Any],  ||  """"""Process a buy trade by adding to position lots.""""""  ||  cost_per_unit_gbp = trade['amount_gbp'] / amount_tokens  ||  cost_per_unit_native = trade['amount_native'] / amount_tokens  ||  lot = TradeLot(  ||  purchase_date=trade['created_at'],  ||  trade_id=trade['id'],  ||  trace_id=trade['trace_id'],  ||  # For buy trades, we don't calculate realized PnL  ||  async def _process_sell_trade(  ||  trade: Dict[str, Any],  ||  """"""Process a sell trade by calculating PnL against position lots.""""""  ||  gross_proceeds_gbp = trade['amount_gbp']  ||  gross_proceeds_native = trade['amount_native']  ||  trade_date=trade['created_at'],  ||  trade_type='sell',  ||  trace_id=trade['trace_id'],  ||  def _get_token_key(self, trade: Dict[str, Any]) -> str:  ||  metadata = json.loads(trade['metadata']) if isinstance(trade['metadata'], str) else trade['metadata']  ||  return f""{token_address}_{trade['chain']}""  ||  return f""unknown_{trade['chain']}""  ||  'trades_analyzed': len(self.pnl_calculations),  ||  'trade_calculations': [calc.to_dict() for calc in self.pnl_calculations],"
"D:\dex\backend\app\reporting\portfolio.py","34824","from __future__ import annotations | import logging | from collections import defaultdict | from datetime import datetime, timedelta | from decimal import Decimal | from typing import Any, Dict, List, Optional, Tuple | from sqlalchemy import and_, func, or_, select, text | from sqlalchemy.ext.asyncio import AsyncSession | from ..core.settings import settings | from ..storage.database import get_session_context | from ..storage.models import LedgerEntry, Transaction | from ..storage.repositories import LedgerRepository","risk metrics, asset allocation analysis, and comparative reporting across  ||  from ..storage.models import LedgerEntry, Transaction  ||  from ..storage.repositories import LedgerRepository  ||  Provides detailed portfolio performance metrics, risk analysis,  ||  # Calculate risk metrics  ||  risk_metrics = await self._calculate_risk_metrics(user_id, as_of_date)  ||  'risk_metrics': risk_metrics,  ||  'concentration_risk': await self._calculate_concentration_risk(positions),  ||  FROM ledger_entries  ||  result = await session.execute(  ||  async def _calculate_risk_metrics(  ||  """"""Calculate portfolio risk metrics.""""""  ||  DATE(created_at) as trade_date,  ||  FROM ledger_entries  ||  ORDER BY trade_date  ||  result = await session.execute(  ||  # Calculate basic risk metrics  ||  # Calculate Sharpe ratio (simplified, assuming risk-free rate = 0)  ||  MIN(created_at) as first_trade,  ||  MAX(created_at) as last_trade  ||  FROM ledger_entries  ||  result = await session.execute(  ||  total_trades = 0  ||  entry_type, count, volume, avg_size, first_trade, last_trade = row  ||  'first_trade': first_trade.isoformat() if first_trade else None,  ||  'last_trade': last_trade.isoformat() if last_trade else None,  ||  total_trades += count  ||  FROM ledger_entries  ||  result = await session.execute(  ||  'total_trades': total_trades,  ||  'average_trade_size_gbp': float(total_volume / total_trades) if total_trades > 0 else 0,  ||  MIN(created_at) as first_trade_date,  ||  MAX(created_at) as last_trade_date,  ||  FROM ledger_entries  ||  result = await session.execute(text(query), {'user_id': user_id})  ||  first_trade, last_trade, trading_days, unique_tokens, chains_used = row  ||  account_age_days = (last_trade - first_trade).days  ||  'first_trade_date': first_trade.isoformat(),  ||  'last_trade_date': last_trade.isoformat(),  ||  'unique_tokens_traded': unique_tokens or 0,  ||  'first_trade_date': None,  ||  'last_trade_date': None,  ||  'unique_tokens_traded': 0,  ||  async def _calculate_concentration_risk(  ||  """"""Calculate concentration risk metrics."""""""
"D:\dex\backend\app\reporting\tax_export.py","32392","from __future__ import annotations | import csv | import logging | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from pathlib import Path | from typing import Any, Dict, List, Optional, Tuple | import pandas as pd | from sqlalchemy import and_, func, select, text | from sqlalchemy.ext.asyncio import AsyncSession | from ..core.settings import settings | from ..storage.database import get_session_context | from ..storage.models import LedgerEntry | from .pnl import AccountingMethod, PnLEngine |         import json","from ..storage.models import LedgerEntry  ||  TRADE = ""trade""  # Trading one crypto for another  ||  TransactionCategory.TRADE,  ||  TransactionCategory.TRADE,  ||  self.export_dir = settings.ledgers_dir / ""tax_exports""  ||  """"""Extract and categorize tax events from ledger entries.""""""  ||  FROM ledger_entries  ||  result = await session.execute(  ||  event = await self._convert_ledger_to_tax_event(row)  ||  async def _convert_ledger_to_tax_event(self, ledger_row: Tuple) -> Optional[TaxEvent]:  ||  """"""Convert ledger entry to tax event.""""""  ||  pnl_gbp, pnl_native, description, metadata) = ledger_row  ||  if metadata_dict.get('gas_fee_gbp'):  ||  fee_gbp = Decimal(str(metadata_dict['gas_fee_gbp']))  ||  'gas_fee': TransactionCategory.FEE,  ||  return type_mapping.get(entry_type, TransactionCategory.TRADE)"
"D:\dex\backend\app\security\keystore.py","22267","from __future__ import annotations | import asyncio | import json | import logging | import secrets | import shutil | from datetime import datetime, timezone | from pathlib import Path | from typing import Dict, List, Optional, Tuple | from cryptography.fernet import Fernet | from cryptography.hazmat.primitives import hashes | from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC | from ..core.settings import settings | import logging",""
"D:\dex\backend\app\services\alpha_feeds.py","31486","from __future__ import annotations | import asyncio | import hashlib | import json | import logging | import re | import time | from collections import defaultdict, deque | from dataclasses import dataclass, field | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Set | from urllib.parse import urljoin, urlparse | import httpx | from pydantic import BaseModel | from ..core.settings import get_settings | from ..monitoring.alerts import create_system_alert |             import random",""
"D:\dex\backend\app\services\pricing.py","16874","from __future__ import annotations | import asyncio | import logging | from decimal import Decimal | from typing import Any, Dict, List, Optional, Tuple | from datetime import datetime, timedelta | from dataclasses import dataclass | from enum import Enum | import httpx | from pydantic import BaseModel | from ..core.settings import settings | from ..dex.uniswap_v2 import pancake_adapter, quickswap_adapter, uniswap_v2_adapter","Quote aggregation engine for multi-DEX price comparison and routing.  ||  include_gas: bool = False  ||  Calculate price impact of a trade.  ||  class QuoteEngine:  ||  Multi-DEX quote aggregation engine with router-first logic.  ||  """"""Initialize quote engine.""""""  ||  async def get_best_quote(  ||  Get best quote across available DEXs with router-first logic.  ||  Best quote with routing information  ||  # Router-first: get quotes from DEX adapters only  ||  quotes = await self._get_dex_quotes(  ||  quotes = await self._get_aggregated_quotes(  ||  if not quotes:  ||  raise Exception(""No quotes available from any source"")  ||  # Select best quote by output amount  ||  best_quote = max(quotes, key=lambda q: q[""amount_out""])  ||  best_quote[""routing_strategy""] = ""router_first"" if use_router_first else ""aggregator_first""  ||  best_quote[""quotes_compared""] = len(quotes)  ||  best_quote[""alternative_quotes""] = [  ||  for q in quotes if q != best_quote  ||  f""Best quote selected: {best_quote['dex']} on {chain}"",  ||  'amount_out': float(best_quote['amount_out']),  ||  'price_impact': float(best_quote['price_impact']),  ||  'quotes_compared': len(quotes)  ||  return best_quote  ||  logger.error(f""Quote aggregation failed: {e}"")  ||  async def _get_dex_quotes(  ||  """"""Get quotes from DEX adapters only.""""""  ||  # Get quotes from all adapters concurrently  ||  task = self._safe_get_quote(  ||  # Filter successful quotes  ||  quotes = []  ||  quotes.append(result)  ||  logger.warning(f""DEX quote failed: {result}"")  ||  return quotes  ||  async def _get_aggregated_quotes(  ||  Get quotes from aggregators with DEX fallback.  ||  For now, this returns DEX quotes as fallback.  ||  # For now, fallback to DEX quotes  ||  return await self._get_dex_quotes(  ||  async def _safe_get_quote(  ||  """"""Safely get quote from adapter with error handling.""""""  ||  return await adapter.get_quote(  ||  logger.warning(f""Quote failed for {adapter.dex_name}: {e}"")  ||  async def estimate_gas_cost(  ||  quote: Dict[str, Any],  ||  Estimate gas cost for executing the quote.  ||  quote: Quote information  ||  Gas cost estimates  ||  # Base gas estimates by DEX type  ||  base_gas_estimates = {  ||  dex = quote.get(""dex"", ""uniswap_v2"")  ||  base_gas = base_gas_estimates.get(dex, 150000)  ||  # TODO: Get actual gas price from chain  ||  gas_price_gwei = {  ||  gas_cost_gwei = Decimal(str(base_gas * gas_price_gwei))  ||  gas_cost_eth = gas_cost_gwei / Decimal(""1000000000"")  # Convert to ETH  ||  ""gas_limit"": Decimal(str(base_gas)),  ||  ""gas_price_gwei"": Decimal(str(gas_price_gwei)),  ||  ""gas_cost_native"": gas_cost_eth,  ||  ""gas_cost_usd"": gas_cost_eth * Decimal(""2000""),  # Rough ETH price estimate  ||  quote_engine = QuoteEngine()"
"D:\dex\backend\app\services\security_providers.py","34854","from __future__ import annotations | import asyncio | import time | from decimal import Decimal | from enum import Enum | from typing import Dict, List, Optional, Any | from dataclasses import dataclass | import httpx | import logging | from ..core.settings import settings |         import random","risk_score: float  # 0.0 - 1.0  ||  risk_factors: List[str]  ||  overall_risk_score: float  ||  risk_factors: List[str]  ||  Provides honeypot detection, risk scoring, and token validation  ||  'overall_risk_score': aggregated.overall_risk_score,  ||  risk_score=0.5,  # Medium risk on failure  ||  risk_factors=[""provider_check_failed""],  ||  # Extract risk factors  ||  risk_factors = []  ||  risk_factors.append(""honeypot_detected"")  ||  risk_factors.append(""high_buy_tax"")  ||  risk_factors.append(""high_sell_tax"")  ||  risk_factors.append(""excessive_sell_tax"")  ||  # Calculate risk score based on taxes and honeypot status  ||  risk_score = 0.95  ||  risk_score = 0.8  ||  risk_score = 0.6  ||  risk_score = 0.3  ||  risk_score = 0.1  ||  risk_score=risk_score,  ||  risk_factors=risk_factors,  ||  ""buy_gas_used"": data.get(""BuyGasUsed"", 0),  ||  ""sell_gas_used"": data.get(""SellGasUsed"", 0),  ||  # Extract risk factors  ||  risk_factors = []  ||  risk_factors.append(""honeypot_detected"")  ||  risk_factors.append(""cannot_sell_all"")  ||  risk_factors.append(""blacklist_function"")  ||  risk_factors.append(""proxy_contract"")  ||  risk_factors.append(""mintable"")  ||  risk_factors.append(""ownership_can_be_reclaimed"")  ||  risk_factors.append(""hidden_owner"")  ||  risk_factors.append(""selfdestruct_function"")  ||  risk_factors.append(""pausable_transfers"")  ||  # Calculate risk score  ||  risk_score = 0.0  ||  # Critical risk factors  ||  risk_score = max(risk_score, 0.9)  ||  risk_score = max(risk_score, 0.85)  ||  risk_score = max(risk_score, 0.8)  ||  # High risk factors  ||  risk_score = max(risk_score, 0.7)  ||  risk_score = max(risk_score, 0.65)  ||  risk_score = max(risk_score, 0.6)  ||  # Medium risk factors  ||  risk_score = max(risk_score, 0.4)  ||  risk_score = max(risk_score, 0.35)  ||  risk_score = max(risk_score, 0.5)  ||  # Tax-based risk  ||  risk_score = max(risk_score, 0.8)  ||  risk_score = max(risk_score, 0.6)  ||  risk_score = max(risk_score, 0.4)  ||  # If no major risks found, set low risk score  ||  if risk_score == 0.0:  ||  risk_score = 0.1  ||  risk_score=risk_score,  ||  risk_factors=risk_factors,  ||  risk_score=0.5,  ||  risk_factors=[""token_not_found""],  ||  # Convert score to risk assessment  ||  risk_score = max(0, (100 - score) / 100)  ||  # Extract risk factors from flags and score  ||  risk_factors = []  ||  risk_factors.append(""honeypot_indicator"")  ||  risk_factors.append(""tax_concern"")  ||  risk_factors.append(""liquidity_concern"")  ||  risk_factors.append(""ownership_concern"")  ||  risk_factors.append(""proxy_contract"")  ||  # Score-based risk factors  ||  risk_factors.append(""very_low_score"")  ||  risk_factors.append(""low_score"")  ||  risk_score=risk_score,  ||  risk_factors=risk_factors,  ||  # Determine risk factors based on audit status  ||  risk_factors = []  ||  risk_factors.extend([""audit_danger_status"", ""high_risk_audit""])  ||  risk_factors.append(""audit_warning_status"")  ||  risk_factors.append(""liquidity_not_locked"")  ||  risk_factors.append(""team_tokens_not_locked"")  ||  risk_factors.append(""low_trust_score"")  ||  risk_factors.append(""medium_trust_score"")  ||  # Calculate risk score  ||  risk_score = 0.9  ||  risk_score = 0.6  ||  risk_score = 0.7  ||  risk_score = 0.4  ||  risk_score = max(0.1, (100 - trust_score) / 100)  ||  risk_score=risk_score,  ||  risk_factors=risk_factors,  ||  overall_risk_score=0.5,  # Medium risk when unknown  ||  risk_factors=[""no_provider_data""],  ||  weighted_risk_score = 0  ||  all_risk_factors = set()  ||  weighted_risk_score += result.risk_score * weight  ||  all_risk_factors.update(result.risk_factors)  ||  avg_risk_score = weighted_risk_score / total_weight  ||  avg_risk_score = 0.5  ||  overall_risk_score=avg_risk_score,  ||  risk_factors=list(all_risk_factors),  ||  risk_level = self._determine_quick_risk_level(result.risk_score)  ||  risk_level = ""medium""  ||  ""risk_level"": risk_level,  ||  ""risk_level"": ""critical"",  ||  # Convert risk score to reputation score (inverted)  ||  base_score = int((1.0 - result.risk_score) * 100)  ||  # Apply penalties for specific risk factors  ||  for factor in result.risk_factors:  ||  def _determine_quick_risk_level(self, risk_score: float) -> str:  ||  """"""Determine risk level from risk score.""""""  ||  if risk_score >= 0.8:  ||  elif risk_score >= 0.6:  ||  elif risk_score >= 0.3:  ||  return ""⚠️ Token has moderate risk - trade with caution""  ||  return ""⚠️ Token has elevated risk - high caution recommended""  ||  return ""🚨 Token has high risk - consider avoiding"""
"D:\dex\backend\app\services\telegram_bot.py","25724","from __future__ import annotations | import asyncio | import logging | import re | from datetime import datetime, timedelta | from decimal import Decimal | from typing import Any, Dict, List, Optional, Set, Tuple | from urllib.parse import urljoin | import httpx | from pydantic import BaseModel | from ..core.settings import get_settings | from ..monitoring.alerts import create_system_alert","- Risk management and emergency controls  ||  async def execute(self, bot: 'TelegramBot', message: TelegramMessage, args: List[str]) -> str:  ||  """"""Execute command and return response.""""""  ||  async def execute(self, bot: 'TelegramBot', message: TelegramMessage, args: List[str]) -> str:  ||  async def execute(self, bot: 'TelegramBot', message: TelegramMessage, args: List[str]) -> str:  ||  async def execute(self, bot: 'TelegramBot', message: TelegramMessage, args: List[str]) -> str:  ||  ""last_trade"": ""2 minutes ago"",  ||  f""Last Trade: {status_data['last_trade']}\n""  ||  async def execute(self, bot: 'TelegramBot', message: TelegramMessage, args: List[str]) -> str:  ||  class TradeCommand(BotCommand):  ||  """"""Execute trading commands.""""""  ||  name=""trade"",  ||  description=""Execute trades"",  ||  usage=""/trade buy|sell TOKEN AMOUNT [CHAIN]"",  ||  async def execute(self, bot: 'TelegramBot', message: TelegramMessage, args: List[str]) -> str:  ||  # Mock trade execution  ||  trade_id = f""TG_{int(datetime.utcnow().timestamp())}""  ||  # Simulate trade execution delay  ||  response = f""✅ *Trade Executed*\n\n""  ||  response += f""Trade ID: `{trade_id}`\n""  ||  logger.error(f""Error executing trade: {e}"")  ||  return f""❌ Trade failed: {str(e)}""  ||  async def execute(self, bot: 'TelegramBot', message: TelegramMessage, args: List[str]) -> str:  ||  async def execute(self, bot: 'TelegramBot', message: TelegramMessage, args: List[str]) -> str:  ||  ""commands_executed"": 0,  ||  TradeCommand(),  ||  # Execute command  ||  response = await command.execute(self, message, args)  ||  self.stats[""commands_executed""] += 1"
"D:\dex\backend\app\services\token_metadata.py","19116","from __future__ import annotations | import asyncio | import logging | import time | from decimal import Decimal | from typing import Any, Dict, List, Optional, Tuple | from ..chains.evm_client import evm_client | from ..chains.solana_client import solana_client | import logging | from ..core.settings import settings | from ..storage.repositories import TokenMetadataRepository, get_token_repository","wallet_address: str,  ||  Get token balance for wallet address.  ||  wallet_address: Wallet address to check  ||  cache_key = f""{chain}:{wallet_address}:{token_address or 'native'}""  ||  balance = await solana_client.get_balance(wallet_address, token_address)  ||  balance = await evm_client.get_balance(wallet_address, chain, token_address)  ||  f""Balance retrieved: {balance} for {wallet_address[:10]}... on {chain}"",  ||  'wallet_address': wallet_address,  ||  wallet_address: str,  ||  wallet_address: Wallet address to check  ||  self.get_balance(chain, wallet_address, token_addr)  ||  f""Retrieved {len(balances)} balances for {wallet_address[:10]}... on {chain}"",  ||  'wallet_address': wallet_address,  ||  if db_token.risk_score and db_token.risk_score > Decimal(""0.8""):  ||  validation_result[""warnings""].append(f""High risk score: {db_token.risk_score}"")"
"D:\dex\backend\app\sim\backtester.py","28165","from __future__ import annotations | import asyncio | import logging | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Dict, List, Optional, Tuple | from pydantic import BaseModel, Field | from .simulator import (","# Risk metrics  ||  # Trade metrics  ||  total_trades: int = Field(description=""Total number of trades"")  ||  winning_trades: int = Field(description=""Number of winning trades"")  ||  losing_trades: int = Field(description=""Number of losing trades"")  ||  avg_trade_duration: float = Field(description=""Average trade duration in hours"")  ||  trade_analysis: Dict = Field(description=""Trade analysis statistics"")  ||  Execute a complete backtesting run.  ||  # Execute based on mode  ||  trade_analysis=self._analyze_trades([sim_result])  ||  trade_analysis=self._analyze_trades([sim_result])  ||  trade_analysis=self._analyze_trades([sim_result])  ||  trade_analysis=self._analyze_trades([sim_result])  ||  total_trades = sum(result.total_trades for result in sim_results)  ||  successful_trades = sum(result.successful_trades for result in sim_results)  ||  if total_trades > 0:  ||  win_rate = (Decimal(successful_trades) / Decimal(total_trades)) * 100  ||  sharpe_ratio=None,  # Would need risk-free rate  ||  total_trades=total_trades,  ||  winning_trades=successful_trades,  ||  losing_trades=total_trades - successful_trades,  ||  avg_trade_duration=24.0,  # Placeholder  ||  # Add trade points  ||  for trade in result.trades_executed:  ||  if trade.success:  ||  trade_pnl = trade.amount_out - trade.amount_in - trade.gas_cost  ||  running_balance += trade_pnl  ||  running_balance -= trade.gas_cost  ||  equity_curve.append((trade.timestamp, running_balance))  ||  def _analyze_trades(self, sim_results: List[SimulationResult]) -> Dict:  ||  """"""Analyze trade statistics.""""""  ||  all_trades = []  ||  all_trades.extend(result.trades_executed)  ||  if not all_trades:  ||  successful_trades = [t for t in all_trades if t.success]  ||  if successful_trades:  ||  profits = [t.amount_out - t.amount_in - t.gas_cost for t in successful_trades]  ||  ""total_trades"": len(all_trades),  ||  ""avg_profit_per_trade"": str(avg_profit),  ||  # Use risk-adjusted return as primary metric  ||  suggestions.append(""Implement stronger risk management to reduce drawdown"")  ||  suggestions.append(""Consider diversifying across multiple chains for better risk distribution"")"
"D:\dex\backend\app\sim\historical_data.py","26413","from __future__ import annotations | import asyncio | import gzip | import json | import logging | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from pathlib import Path | from typing import Dict, List, Optional, Tuple, Union | from pydantic import BaseModel, Field","trade_count: int = Field(description=""Number of trades in period"")  ||  avg_trade_size: Decimal = Field(description=""Average trade size"")  ||  # Gas and network data  ||  gas_price: Optional[Decimal] = Field(None, description=""Gas price at time"")  ||  # Risk factors  ||  trade_count=0,  # Default  ||  avg_trade_size=Decimal(""1000""),  # Default  ||  gas_price=None,  # Optional field"
"D:\dex\backend\app\sim\latency_model.py","20961","from __future__ import annotations | import logging | import random | from dataclasses import dataclass | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Dict, List, Optional, Tuple | from pydantic import BaseModel, Field","operation_type: Type of operation (quote, swap, approve, etc.)  ||  ""quote"": 1.0,  ||  ""nonce"": 0.7,  ||  ""gas_estimate"": 1.1,"
"D:\dex\backend\app\sim\market_impact.py","22527","from __future__ import annotations | import logging | import math | import random | from dataclasses import dataclass | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Dict, List, Optional, Tuple | from pydantic import BaseModel, Field","class TradeImpact(BaseModel):  ||  """"""Market impact result for a trade.""""""  ||  trade_size_usd: Decimal = Field(description=""Trade size in USD"")  ||  volume_ratio: Decimal = Field(description=""Trade size vs 24h volume"")  ||  reserve_ratio: Decimal = Field(description=""Trade size vs reserves"")  ||  self.historical_impacts: List[TradeImpact] = []  ||  Advanced market impact modeling for realistic trade simulation.  ||  trade size, market depth, volatility, and liquidity conditions.  ||  async def calculate_trade_impact(  ||  trade_size_usd: Decimal,  ||  ) -> TradeImpact:  ||  Calculate comprehensive market impact for a trade.  ||  trade_size_usd: Trade size in USD  ||  side: Trade side (""buy"" or ""sell"")  ||  Complete trade impact analysis  ||  trade_size_usd, market_condition, slippage_tolerance  ||  trade_size_usd, snapshot, market_condition  ||  trade_size_usd, snapshot  ||  # Adjust for trade direction (sells typically have higher impact)  ||  amount_out = trade_size_usd / execution_price  ||  volume_ratio = trade_size_usd / max(snapshot.volume_24h, Decimal(""1""))  ||  reserve_ratio = trade_size_usd / max(reserve_usd, Decimal(""1""))  ||  return TradeImpact(  ||  trade_size_usd=trade_size_usd,  ||  trade_size_usd: Decimal,  ||  size_ratio = float(trade_size_usd / max(snapshot.tvl_usd, Decimal(""1"")))  ||  trade_size_usd: Decimal,  ||  # Volume impact (trade size vs 24h volume)  ||  volume_ratio = float(trade_size_usd / max(snapshot.volume_24h, Decimal(""1000"")))  ||  # Reserve impact (trade size vs available reserves)  ||  reserve_ratio = float(trade_size_usd / max(reserve_usd, Decimal(""1000"")))  ||  trade_size_usd: Decimal,  ||  ) -> TradeImpact:  ||  size_usd = float(trade_size_usd)  ||  amount_out = trade_size_usd / execution_price  ||  return TradeImpact(  ||  trade_size_usd=trade_size_usd,  ||  def estimate_optimal_trade_size(  ||  Estimate optimal trade size for given slippage tolerance.  ||  Estimated optimal trade size in USD  ||  """"""Get impact analysis summary for recent trades.""""""  ||  ""high_impact_trades"": len([i for i in all_impacts if i > 0.05]),  # >5%"
"D:\dex\backend\app\sim\metrics.py","63003","from __future__ import annotations | import asyncio | import gzip | import json | import logging | import statistics | from decimal import Decimal | from datetime import datetime, timedelta | from typing import List, Dict, Tuple, Optional, Any, Union | from dataclasses import dataclass | from enum import Enum | from pathlib import Path |     from pydantic import BaseModel, Field |             import json","RISK = ""risk""  ||  self.trade_count = kwargs.get('trade_count', 0)  ||  self.avg_trade_size = kwargs.get('avg_trade_size', Decimal('0'))  ||  self.gas_price = kwargs.get('gas_price')  ||  class TradeResult:  ||  """"""Individual trade result for analysis.""""""  ||  gas_cost: Decimal  ||  """"""Trade duration in hours.""""""  ||  total_trades: int  ||  winning_trades: int  ||  losing_trades: int  ||  total_gas_costs: Decimal  ||  # Risk metrics  ||  value_at_risk_95: Decimal  ||  trade_count=0,  # Default  ||  avg_trade_size=Decimal(""1000""),  # Default  ||  gas_price=None,  # Optional field  ||  data management, backtesting, and advanced risk metrics.  ||  self.risk_free_rate = Decimal(""0.02"")  # 2% annual risk-free rate  ||  trades: List[TradeResult],  ||  trades: List of individual trade results  ||  if not trades or not portfolio_values:  ||  # Calculate trade-based metrics  ||  winning_trades = [t for t in trades if t.pnl > 0]  ||  losing_trades = [t for t in trades if t.pnl < 0]  ||  win_rate = Decimal(len(winning_trades)) / Decimal(len(trades)) * Decimal(""100"") if trades else Decimal(""0"")  ||  total_wins = sum(t.pnl for t in winning_trades)  ||  total_losses = abs(sum(t.pnl for t in losing_trades))  ||  avg_win = total_wins / Decimal(len(winning_trades)) if winning_trades else Decimal(""0"")  ||  avg_loss = total_losses / Decimal(len(losing_trades)) if losing_trades else Decimal(""0"")  ||  largest_win = max((t.pnl for t in winning_trades), default=Decimal(""0""))  ||  largest_loss = min((t.pnl for t in losing_trades), default=Decimal(""0""))  ||  total_fees = sum(t.fees for t in trades)  ||  total_gas_costs = sum(t.gas_cost for t in trades)  ||  # Calculate volatility and risk metrics  ||  # Calculate advanced risk metrics  ||  var_95 = self._calculate_value_at_risk(returns, Decimal(""0.95""))  ||  total_trades=len(trades),  ||  winning_trades=len(winning_trades),  ||  losing_trades=len(losing_trades),  ||  total_gas_costs=total_gas_costs,  ||  value_at_risk_95=var_95,  ||  trades = []  ||  # Create simulated trade  ||  trade = TradeResult(  ||  gas_cost=Decimal(""10""),  ||  trades.append(trade)  ||  portfolio_value += trade.pnl - trade.fees - trade.gas_cost  ||  trades, portfolio_values, Decimal(""10000"")  ||  ""trades"": trades,  ||  trades: List[TradeResult],  ||  trades: List of trades  ||  winning_streak = self._calculate_winning_streak(trades)  ||  losing_streak = self._calculate_losing_streak(trades)  ||  ""risk_metrics"": {  ||  ""value_at_risk_95"": float(metrics.value_at_risk_95),  ||  ""trade_analysis"": {  ||  ""total_trades"": metrics.total_trades,  ||  ""winning_trades"": metrics.winning_trades,  ||  ""losing_trades"": metrics.losing_trades,  ||  ""total_gas_costs"": float(metrics.total_gas_costs),  ||  excess_return = avg_return - (self.risk_free_rate / Decimal(""252""))  # Daily risk-free rate  ||  return (avg_return - self.risk_free_rate / Decimal(""252"")) / downside_deviation  ||  def _calculate_value_at_risk(self, returns: List[Decimal], confidence: Decimal) -> Decimal:  ||  """"""Calculate Value at Risk.""""""  ||  """"""Calculate Conditional Value at Risk (Expected Shortfall).""""""  ||  var = self._calculate_value_at_risk(returns, confidence)  ||  def _calculate_winning_streak(self, trades: List[TradeResult]) -> int:  ||  for trade in trades:  ||  if trade.pnl > 0:  ||  def _calculate_losing_streak(self, trades: List[TradeResult]) -> int:  ||  for trade in trades:  ||  if trade.pnl <= 0:  ||  total_trades=0,  ||  winning_trades=0,  ||  losing_trades=0,  ||  total_gas_costs=Decimal(""0""),  ||  value_at_risk_95=Decimal(""0""),  ||  'TradeResult',  ||  # Example trades  ||  trades = [  ||  TradeResult(  ||  gas_cost=Decimal(""5""),  ||  trades=trades,  ||  trades=trades,  ||  print(f""Backtest completed with {len(backtest_results.get('trades', []))} trades"")"
"D:\dex\backend\app\sim\quality_gates.py","29247","from __future__ import annotations | import asyncio | import gzip | import json | import logging | import os | import time | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from pathlib import Path | from typing import Dict, List, Optional, Tuple, Union | from pydantic import BaseModel, Field |             import httpx |             import aiosqlite |             import httpx |     import asyncio ","self.ledger_dir = self.data_dir / ""ledgers""  ||  cursor = await db.execute(""SELECT 1"")  ||  cursor = await db.execute(  ||  required_tables = [""users"", ""wallets"", ""transactions"", ""ledger"", ""token_metadata""]  ||  ""data/ledgers"",  ||  # Check ledger directory  ||  if self.ledger_dir.exists():  ||  ledger_files = list(self.ledger_dir.glob(""*.csv""))  ||  ledger_system_ready = True  # Directory exists and is writable  ||  self.results[""ledger_system_ready""] = ledger_system_ready  ||  self.results[""ledger_system_ready""] = False  ||  self.results[""ledger_system_ready""] = False  ||  print(""Quality gates script executed"")"
"D:\dex\backend\app\sim\simulator.py","25671","from __future__ import annotations | import asyncio | import logging | import random | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Dict, List, Optional, Tuple | from pydantic import BaseModel, Field | from .historical_data import HistoricalDataManager, SimulationSnapshot | from .latency_model import LatencyModel, NetworkCondition | from .market_impact import MarketImpactModel, MarketCondition, TradeImpact | from ..strategy.risk_manager import RiskManager","from .market_impact import MarketImpactModel, MarketCondition, TradeImpact  ||  from ..strategy.risk_manager import RiskManager  ||  class SimulatedTrade(BaseModel):  ||  """"""Individual simulated trade result.""""""  ||  trade_id: str = Field(description=""Unique trade identifier"")  ||  timestamp: datetime = Field(description=""Trade execution timestamp"")  ||  side: str = Field(description=""Trade side (buy/sell)"")  ||  # Trade amounts  ||  gas_fee: Decimal = Field(description=""Gas fee paid"")  ||  success: bool = Field(description=""Trade success status"")  ||  gas_price_multiplier: Decimal = Field(default=Decimal(""1.0""), description=""Gas price multiplier"")  ||  max_trades_per_hour: int = Field(default=100, description=""Maximum trades per hour"")  ||  trades_executed: List[SimulatedTrade] = Field(description=""All executed trades"")  ||  total_trades: int = Field(description=""Total number of trades"")  ||  successful_trades: int = Field(description=""Number of successful trades"")  ||  failed_trades: int = Field(description=""Number of failed trades"")  ||  success_rate: Decimal = Field(description=""Trade success rate percentage"")  ||  sharpe_ratio: Optional[Decimal] = Field(None, description=""Risk-adjusted return"")  ||  self.risk_manager = RiskManager()  ||  self.active_trades: Dict[str, SimulatedTrade] = {}  ||  Execute a complete enhanced simulation run.  ||  trades_executed=[],  ||  total_trades=0,  ||  successful_trades=0,  ||  failed_trades=0,  ||  trades_executed = []  ||  # Execute simulation loop  ||  if len(trades_executed) >= parameters.max_trades_per_hour:  ||  # Simulate trade opportunity  ||  trade = await self._simulate_trade_opportunity(  ||  if trade:  ||  trades_executed.append(trade)  ||  total_latency += trade.execution_time_ms  ||  if trade.success:  ||  current_balance += trade.pnl  ||  current_balance -= trade.gas_fee  ||  successful_trades = [t for t in trades_executed if t.success]  ||  failed_trades = [t for t in trades_executed if not t.success]  ||  total_pnl = sum(t.pnl for t in trades_executed)  ||  total_fees = sum(t.gas_fee for t in trades_executed)  ||  total_slippage = sum(t.slippage for t in trades_executed) if trades_executed else Decimal(""0"")  ||  avg_price_impact = sum(t.price_impact for t in trades_executed) / len(trades_executed) if trades_executed else Decimal(""0"")  ||  success_rate = len(successful_trades) / len(trades_executed) * 100 if trades_executed else Decimal(""0"")  ||  avg_execution_time = total_latency / len(trades_executed) if trades_executed else 0.0  ||  gross_profit = sum(t.pnl for t in successful_trades)  ||  gross_loss = abs(sum(t.pnl for t in failed_trades))  ||  network_failures = len([t for t in failed_trades if ""network"" in (t.failure_reason or """").lower()])  ||  network_reliability = (1 - network_failures / len(trades_executed)) * 100 if trades_executed else Decimal(""100"")  ||  result.trades_executed = trades_executed  ||  result.total_trades = len(trades_executed)  ||  result.successful_trades = len(successful_trades)  ||  result.failed_trades = len(failed_trades)  ||  logger.info(f""Enhanced simulation {simulation_id} completed: {len(trades_executed)} trades, ""  ||  self.active_trades.clear()  ||  async def _simulate_trade_opportunity(  ||  ) -> Optional[SimulatedTrade]:  ||  Simulate a single trade opportunity.  ||  Simulated trade result or None if no trade  ||  if random.random() > 0.05:  # 5% chance of trade opportunity  ||  # Generate trade parameters  ||  trade_id = f""trade_{int(datetime.now().timestamp() * 1000)}""  ||  trade_size_usd = min(  ||  1000.0  # Max $1000 per trade  ||  if trade_size_usd < 10:  # Minimum trade size  ||  impact_result = await self.market_impact_model.calculate_trade_impact(  ||  trade_size_usd=Decimal(str(trade_size_usd)),  ||  # Calculate trade result  ||  amount_in = Decimal(str(trade_size_usd))  ||  # Calculate gas fee  ||  base_gas_fee = Decimal(""5.0"")  # Base $5 gas fee  ||  gas_fee = base_gas_fee * parameters.gas_price_multiplier  ||  return SimulatedTrade(  ||  trade_id=trade_id,  ||  gas_fee=gas_fee,  ||  logger.error(f""Failed to simulate trade opportunity: {e}"")  ||  ""active_trades"": len(self.active_trades)"
"D:\dex\backend\app\sim\validator.py","5203","from decimal import Decimal | from datetime import datetime, timedelta | from typing import Optional | from pydantic import BaseModel, Field, validator | import logging",""
"D:\dex\backend\app\sim\__init__.py","0","",""
"D:\dex\backend\app\storage\migrations\postgresql_migration.py","22797","from __future__ import annotations | import asyncio | import json | import logging | import os | from decimal import Decimal | from pathlib import Path | from typing import Any, Dict, List, Optional, Tuple, Union | import asyncpg | from sqlalchemy import create_engine, text, MetaData, Table, select | from sqlalchemy.ext.asyncio import create_async_engine, AsyncEngine | from sqlalchemy.orm import sessionmaker | from ..database import DatabaseManager | from ..models import Base, User, Wallet, LedgerEntry, TokenMetadata, Transaction | from ...core.config import get_settings |                 from ..models import ( |             import sqlite3 |     import argparse","from ..models import Base, User, Wallet, LedgerEntry, TokenMetadata, Transaction  ||  User, Wallet, AdvancedOrder, OrderExecution, Position,  ||  TradeExecution, WalletBalance, SystemSettings, LedgerEntry,  ||  SafetyEvent, Trade, TokenMetadata, BlacklistedToken,  ||  await conn.execute(text(""CREATE EXTENSION IF NOT EXISTS \""uuid-ossp\""""))  ||  await conn.execute(text(""CREATE EXTENSION IF NOT EXISTS \""pg_trgm\""""))  ||  ""CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_wallets_active ON wallets (id) WHERE is_active = true"",  ||  ""CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_ledger_timestamp_hash ON ledger_entries USING HASH (date_trunc('day', timestamp))"",  ||  ""CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_safety_events_daily ON safety_events (date_trunc('day', timestamp), event_type)"",  ||  ""CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_trades_wallet_chain_time ON trade_executions (wallet_address, chain, executed_at DESC)"",  ||  await conn.execute(text(optimization))  ||  'wallets',  ||  'trade_executions',  ||  'wallet_balances',  ||  'ledger_entries',  ||  'safety_events',  ||  'trades',  ||  sqlite_result = await sqlite_conn.execute(  ||  await pg_conn.execute(text(insert_sql), converted_rows)  ||  'token_metadata': ['risk_factors', 'security_audit'],  ||  'safety_events': ['details'],  ||  'ledger_entries': ['risk_factors', 'tags'],  ||  'ledger_entries': ['input_amount', 'output_amount', 'price', 'transaction_fee'],  ||  'trade_executions': ['quantity', 'price', 'total_value', 'slippage'],  ||  'wallet_balances': ['balance', 'usd_value']  ||  sqlite_tables_result = await sqlite_conn.execute(  ||  sqlite_count_result = await sqlite_conn.execute(  ||  pg_count_result = await pg_conn.execute(  ||  await conn.execute(text(""DROP SCHEMA public CASCADE""))  ||  await conn.execute(text(""CREATE SCHEMA public""))  ||  await conn.execute(text(""GRANT ALL ON SCHEMA public TO public""))"
"D:\dex\backend\app\storage\repositories\system_state_repository.py","29326","from __future__ import annotations | import json | import uuid | from datetime import datetime, timezone, timedelta | from typing import Dict, List, Optional, Any, Tuple | from decimal import Decimal | from sqlalchemy import select, update, delete, and_, or_, desc, text | from sqlalchemy.ext.asyncio import AsyncSession | from sqlalchemy.exc import SQLAlchemyError, IntegrityError | from ..database import db_manager | from ..models import ( | import logging","SystemStateType.AUTOTRADE_ENGINE: 300,     # 5 minutes  ||  SystemStateType.RISK_MANAGER: 120,         # 2 minutes  ||  SystemStateType.SAFETY_CONTROLS: 60,       # 1 minute  ||  SystemStateType.WEBSOCKET_HUB: 60,         # 1 minute  ||  result = await sess.execute(  ||  result = await sess.execute(  ||  result = await sess.execute(  ||  result = await sess.execute(query)  ||  result = await sess.execute(query)  ||  result = await sess.execute(query)  ||  result = await sess.execute(query)  ||  result = await sess.execute(  ||  result = await sess.execute(select(SystemState))"
"D:\dex\backend\app\storage\repositories\__init__.py","349","from .system_state_repository import system_state_repository, get_system_state_repository",""
"D:\dex\backend\app\storage\backup.py","24902","from __future__ import annotations | import asyncio | import gzip | import json | import logging | import os | import shutil | import subprocess | from datetime import datetime, timedelta | from pathlib import Path | from typing import Any, Dict, List, Optional, Union | import asyncpg | from sqlalchemy import text | from sqlalchemy.ext.asyncio import AsyncEngine | from .database import db_manager, get_database | from ..core.config import get_settings |             import sqlite3 |             import sqlite3 |                 import tempfile |                 import tempfile","cursor.execute(""SELECT COUNT(*) FROM sqlite_master"")  ||  cursor.execute(""SELECT COUNT(*) FROM sqlite_master"")"
"D:\dex\backend\app\storage\database.py","20456","from __future__ import annotations | import asyncio | import logging | from contextlib import asynccontextmanager | from pathlib import Path | from typing import AsyncGenerator, Optional, Union | from urllib.parse import urlparse | from sqlalchemy import event, text | from sqlalchemy.engine import Engine | from sqlalchemy.ext.asyncio import ( | from sqlalchemy.orm import DeclarativeBase | from sqlalchemy.pool import StaticPool, QueuePool | from ..core.settings import get_settings |             from .models import (","result = await conn.execute(text(""SELECT 1""))  ||  """"""Set SQLite pragmas for performance and safety.""""""  ||  cursor.execute(""PRAGMA journal_mode=WAL"")  ||  cursor.execute(""PRAGMA synchronous=NORMAL"")  ||  cursor.execute(""PRAGMA foreign_keys=ON"")  ||  cursor.execute(""PRAGMA busy_timeout=30000"")  ||  cursor.execute(""PRAGMA cache_size=-64000"")  ||  cursor.execute(""PRAGMA temp_store=MEMORY"")  ||  result = await session.execute(text(""SELECT 1""))  ||  wal_result = await session.execute(text(""PRAGMA journal_mode""))  ||  version_result = await session.execute(text(""SELECT version()""))  ||  User, Wallet, LedgerEntry, AdvancedOrder, OrderExecution,  ||  Position, TradeExecution, WalletBalance, SystemSettings,  ||  SafetyEvent, Trade, TokenMetadata, BlacklistedToken, Transaction  ||  await session.execute(text(""SELECT 1""))  ||  result = await session.execute(text(f""SELECT COUNT(*) FROM {table_name}""))"
"D:\dex\backend\app\storage\models.py","30506","from __future__ import annotations | import json | from datetime import datetime, timezone | from decimal import Decimal | from enum import Enum | from typing import Dict, List, Optional, Any | from sqlalchemy import ( | from sqlalchemy.ext.declarative import declarative_base | from sqlalchemy.orm import relationship | from sqlalchemy.types import TypeDecorator, VARCHAR | from sqlalchemy.sql import func |     from sqlalchemy.dialects.postgresql import JSONB | import logging","AUTOTRADE_ENGINE = ""autotrade_engine""  ||  RISK_MANAGER = ""risk_manager""  ||  SAFETY_CONTROLS = ""safety_controls""  ||  WEBSOCKET_HUB = ""websocket_hub""  ||  class WalletType(str, Enum):  ||  """"""Wallet type enumeration.""""""  ||  AUTOTRADE = ""autotrade""  ||  setting_id = Column(String(100), primary_key=True)  # Hierarchical key like ""autotrade.risk.max_position_usd""  ||  category = Column(String(50), nullable=False)  # autotrade, ai, risk, safety, etc.  ||  Records emergency stops, kill switches, and other critical safety actions  ||  approval_required = Column(Boolean, default=False, nullable=False)  ||  wallets = relationship(""Wallet"", back_populates=""user"", cascade=""all, delete-orphan"")  ||  ledger_entries = relationship(""LedgerEntry"", back_populates=""user"")  ||  class Wallet(Base):  ||  """"""Wallet model.""""""  ||  __tablename__ = ""wallets""  ||  wallet_id = Column(String(36), primary_key=True)  # UUID  ||  wallet_type = Column(String(20), nullable=False)  # hot/cold/watch  ||  user = relationship(""User"", back_populates=""wallets"")  ||  balances = relationship(""WalletBalance"", back_populates=""wallet"")  ||  ledger_entries = relationship(""LedgerEntry"", back_populates=""wallet"")  ||  class WalletBalance(Base):  ||  """"""Wallet balance tracking.""""""  ||  __tablename__ = ""wallet_balances""  ||  wallet_id = Column(String(36), ForeignKey(""wallets.wallet_id""), nullable=False)  ||  wallet = relationship(""Wallet"", back_populates=""balances"")  ||  class LedgerEntry(Base):  ||  """"""Comprehensive ledger for all transactions.""""""  ||  __tablename__ = ""ledger_entries""  ||  wallet_id = Column(String(36), ForeignKey(""wallets.wallet_id""), nullable=False)  ||  # Trade information  ||  trade_type = Column(String(20), nullable=False)  # buy/sell/swap  ||  gas_fee = Column(Numeric(36, 18), nullable=True)  ||  ledger_data = Column(JSONType, nullable=True)  # RENAMED from 'metadata'  ||  user = relationship(""User"", back_populates=""ledger_entries"")  ||  wallet = relationship(""Wallet"", back_populates=""ledger_entries"")  ||  max_gas_price = Column(Numeric(36, 18), nullable=True)  ||  quantity_executed = Column(Numeric(36, 18), nullable=False)  ||  gas_used = Column(Integer, nullable=True)  ||  gas_price = Column(Numeric(36, 18), nullable=True)  ||  executed_at = Column(DateTime, default=datetime.utcnow)  ||  class TradeExecution(Base):  ||  """"""Trade execution details.""""""  ||  __tablename__ = ""trade_executions""  ||  # Trade details  ||  gas_used = Column(Integer, nullable=True)  ||  gas_price = Column(Numeric(36, 18), nullable=True)  ||  executed_at = Column(DateTime, default=datetime.utcnow)  ||  class SafetyEvent(Base):  ||  """"""Safety events and circuit breaker activations.""""""  ||  __tablename__ = ""safety_events""  ||  class Trade(Base):  ||  """"""Trade model for basic tracking.""""""  ||  __tablename__ = ""trades""  ||  trade_id = Column(String(36), primary_key=True)  ||  trade_type = Column(String(10), nullable=False)  # buy/sell  ||  gas_used = Column(Integer, nullable=True)  ||  gas_price = Column(Numeric(36, 18), nullable=True)"
"D:\dex\backend\app\storage\repos.py","25601","from __future__ import annotations | from typing import List, Optional, Dict, Any | from decimal import Decimal | from datetime import datetime | import uuid | import logging | from sqlalchemy.orm import Session, sessionmaker | from sqlalchemy.exc import SQLAlchemyError | from sqlalchemy import and_, or_, desc, asc | from .models import ( | from ..core.database import get_database_session | import logging","AdvancedOrder, OrderExecution, Position, User, TradeExecution,  ||  tx_hash: Transaction hash if executed  ||  quantity_executed: Decimal,  ||  quantity_executed: Quantity executed  ||  quantity_executed=quantity_executed,  ||  executed_at=datetime.utcnow()  ||  new_remaining_quantity = order.remaining_quantity - quantity_executed  ||  # Use session.execute for updates to avoid type issues  ||  session.execute(  ||  ""quantity_executed"": str(quantity_executed),  ||  # Use session.execute for updates to avoid SQLAlchemy type issues  ||  session.execute(  ||  trade_value: Decimal,  ||  trade_type: str = ""buy""  ||  price: Trade price  ||  trade_value: Trade value in USD  ||  trade_type: Trade type (buy/sell)  ||  if existing_position and trade_type == ""buy"":  ||  total_cost = old_total_cost + trade_value  ||  # Use session.execute for updates  ||  session.execute(  ||  elif existing_position and trade_type == ""sell"":  ||  session.execute(  ||  total_cost=trade_value,"
"D:\dex\backend\app\storage\repositories.py","24606","from __future__ import annotations | from datetime import datetime, timezone | from decimal import Decimal | from typing import AsyncGenerator, List, Optional, Sequence, Dict, Any | from sqlalchemy import and_, desc, select, update | from sqlalchemy.ext.asyncio import AsyncSession | from sqlalchemy.orm import selectinload | from .database import get_db_session | from .models import (","LedgerEntry, TokenMetadata, Transaction, User, Wallet,  ||  SafetyEvent, BlacklistedToken  ||  default_trade_amount_gbp: Optional[Decimal] = None,  ||  risk_tolerance: Optional[str] = None,  ||  default_trade_amount_gbp: Default trade amount in GBP  ||  risk_tolerance: Risk tolerance level  ||  default_trade_amount_gbp=default_trade_amount_gbp,  ||  risk_tolerance=risk_tolerance,  ||  result = await self.session.execute(stmt)  ||  await self.session.execute(stmt)  ||  class WalletRepository(BaseRepository):  ||  """"""Repository for Wallet operations.""""""  ||  async def create_wallet(  ||  wallet_type: str,  ||  is_hot_wallet: bool = False,  ||  ) -> Wallet:  ||  Create a new wallet connection.  ||  address: Wallet address  ||  wallet_type: Type of wallet connection  ||  is_hot_wallet: Whether this is a hot wallet  ||  keystore_path: Path to encrypted keystore (for hot wallets)  ||  Created Wallet instance  ||  wallet = Wallet(  ||  wallet_type=wallet_type,  ||  is_hot_wallet=is_hot_wallet,  ||  self.session.add(wallet)  ||  await self.session.refresh(wallet)  ||  return wallet  ||  async def get_user_wallets(  ||  ) -> List[Wallet]:  ||  Get user's wallets, optionally filtered by chain.  ||  connected_only: Only return connected wallets  ||  List of Wallet instances  ||  conditions = [Wallet.user_id == user_id]  ||  conditions.append(Wallet.chain == chain)  ||  conditions.append(Wallet.is_connected == True)  ||  stmt = select(Wallet).where(and_(*conditions))  ||  result = await self.session.execute(stmt)  ||  async def disconnect_wallet(self, wallet_id: int) -> None:  ||  Mark wallet as disconnected.  ||  wallet_id: Wallet ID to disconnect  ||  update(Wallet)  ||  .where(Wallet.id == wallet_id)  ||  await self.session.execute(stmt)  ||  class SafetyRepository(BaseRepository):  ||  Repository for safety events and blacklisted tokens.  ||  Manages safety-related database operations including event logging,  ||  blacklist management, and risk tracking.  ||  async def log_safety_event(  ||  wallet_address: Optional[str] = None,  ||  risk_score: Optional[float] = None,  ||  ) -> SafetyEvent:  ||  Log a safety event.  ||  wallet_address: Wallet address  ||  risk_score: Associated risk score  ||  Created SafetyEvent instance  ||  event = SafetyEvent(  ||  wallet_address=wallet_address,  ||  risk_score=risk_score,  ||  ) -> List[SafetyEvent]:  ||  Get recent safety events with filtering.  ||  List of SafetyEvent instances  ||  conditions.append(SafetyEvent.severity == severity)  ||  conditions.append(SafetyEvent.event_type == event_type)  ||  conditions.append(SafetyEvent.resolved == resolved)  ||  stmt = select(SafetyEvent)  ||  stmt = stmt.order_by(desc(SafetyEvent.timestamp)).limit(limit)  ||  result = await self.session.execute(stmt)  ||  Mark a safety event as resolved.  ||  update(SafetyEvent)  ||  .where(SafetyEvent.id == event_id)  ||  await self.session.execute(stmt)  ||  result = await self.session.execute(stmt)  ||  result = await self.session.execute(stmt)  ||  result = await self.session.execute(stmt)  ||  wallet_id: int,  ||  wallet_id: Wallet ID  ||  wallet_id=wallet_id,  ||  await self.session.execute(stmt)  ||  result = await self.session.execute(stmt)  ||  result = await self.session.execute(stmt)  ||  class LedgerRepository(BaseRepository):  ||  """"""Repository for LedgerEntry operations.""""""  ||  wallet_address: str,  ||  ) -> LedgerEntry:  ||  Create a new ledger entry.  ||  entry_type: Type of ledger entry  ||  wallet_address: Wallet address  ||  Created LedgerEntry instance  ||  entry = LedgerEntry(  ||  wallet_address=wallet_address,  ||  async def get_user_ledger(  ||  ) -> List[LedgerEntry]:  ||  Get user's ledger entries with pagination and filtering.  ||  List of LedgerEntry instances  ||  conditions = [LedgerEntry.user_id == user_id]  ||  conditions.append(LedgerEntry.trade_type == entry_type)  # Changed from entry_type to trade_type  ||  conditions.append(LedgerEntry.chain == chain)  ||  select(LedgerEntry)  ||  .order_by(desc(LedgerEntry.created_at))  ||  result = await self.session.execute(stmt)  ||  result = await self.session.execute(stmt)  ||  async def update_risk_score(  ||  risk_score: Decimal,  ||  Update token risk assessment.  ||  risk_score: Risk score (0.00-1.00)  ||  risk_score=risk_score,  ||  await self.session.execute(stmt)  ||  async def get_wallet_repository() -> AsyncGenerator[WalletRepository, None]:  ||  """"""FastAPI dependency to get WalletRepository instance.""""""  ||  yield WalletRepository(session)  ||  async def get_safety_repository() -> AsyncGenerator[SafetyRepository, None]:  ||  """"""FastAPI dependency to get SafetyRepository instance.""""""  ||  yield SafetyRepository(session)  ||  async def get_ledger_repository() -> AsyncGenerator[LedgerRepository, None]:  ||  """"""FastAPI dependency to get LedgerRepository instance.""""""  ||  yield LedgerRepository(session)"
"D:\dex\backend\app\strategy\orders\advanced.py","34564","from __future__ import annotations | from typing import List, Optional, Dict, Any, Tuple | from decimal import Decimal, ROUND_DOWN | from datetime import datetime, timedelta | import asyncio | import uuid | import logging | from enum import Enum | from ...storage.models import ( | from ...storage.repos import AdvancedOrderRepository, PositionRepository | from ...services.pricing import PricingService | from ...trading.executor import TradeExecutor | from ...core.logging import get_logger | from ...core.retry import retry_with_backoff | from .triggers import OrderTriggerMonitor","User, TradeExecution  ||  from ...trading.executor import TradeExecutor  ||  self.trade_executor = TradeExecutor()  ||  trade_executor=self.trade_executor,  ||  ""orders_executed"": 0,"
"D:\dex\backend\app\strategy\orders\triggers.py","18498","from __future__ import annotations | import asyncio | import logging | from decimal import Decimal | from typing import Dict, List, Optional, Set, TYPE_CHECKING | from datetime import datetime, timezone | from backend.app.storage.models import AdvancedOrder, OrderStatus, OrderType, Position | from backend.app.storage.repos import AdvancedOrderRepository, PositionRepository |     from backend.app.trading.protocols import TradeExecutorProtocol |             from types import SimpleNamespace","from backend.app.trading.protocols import TradeExecutorProtocol  ||  Monitors active orders and executes them when trigger conditions are met.  ||  and executes trades when trigger conditions (price thresholds) are satisfied.  ||  >>> # Monitor will now watch all active orders and execute when triggered  ||  trade_executor: TradeExecutorProtocol,  ||  trade_executor: Service for executing trades  ||  self.trade_executor = trade_executor  ||  pair_key = f""{order.base_token}_{order.quote_token}_{order.chain}""  ||  base_token, quote_token, chain = pair_key.split('_')  ||  """"""Check if a specific order should trigger and execute if so.""""""  ||  pair_key = f""{order.base_token}_{order.quote_token}_{order.chain}""  ||  await self._execute_triggered_order(order, current_price)  ||  """"""Check if DCA order should execute next purchase.""""""  ||  async def _execute_triggered_order(self, order: AdvancedOrder, trigger_price: Decimal) -> None:  ||  """"""Execute an order that has been triggered.""""""  ||  # Execute the trade through trade executor  ||  # TODO: Implement actual trade execution method in TradeExecutor  ||  # For now, create a mock trade result  ||  trade_result = SimpleNamespace(  ||  if trade_result.success:  ||  'executed_at': datetime.now(timezone.utc),  ||  'execution_price': trade_result.execution_price,  ||  'execution_tx_hash': trade_result.tx_hash  ||  await self._update_position_from_execution(order, trade_result)  ||  logger.info(f""Successfully executed order {order.id} - tx: {trade_result.tx_hash}"")  ||  'failure_reason': trade_result.error_message  ||  logger.error(f""Failed to execute order {order.id}: {trade_result.error_message}"")  ||  async def _update_position_from_execution(self, order: AdvancedOrder, trade_result) -> None:  ||  position.exit_price = trade_result.execution_price  ||  position.exit_tx_hash = trade_result.tx_hash  ||  if position.entry_price and trade_result.execution_price:  ||  pnl_multiplier = trade_result.execution_price / position.entry_price"
"D:\dex\backend\app\strategy\orders\__init__.py","362","from .advanced import AdvancedOrderManager, OrderExecutionError, OrderValidationError",""
"D:\dex\backend\app\strategy\advanced_orders.py","24234","from __future__ import annotations | import logging | from datetime import datetime, timedelta | from decimal import Decimal | from typing import Dict, List, Optional | from pydantic import Field | from backend.app.strategy.orders.base import (","""max_gas_price"": self.max_gas_price,  ||  Executes multiple smaller orders over time to reduce timing risk.  ||  num_orders: int = Field(..., description=""Number of orders to execute"")  ||  orders_executed: int = Field(default=0, description=""Number of orders executed"")  ||  executed_orders: List[Dict] = Field(default_factory=list, description=""Executed order details"")  ||  Check if next DCA order should execute.  ||  True if next order should execute  ||  if self.orders_executed >= self.num_orders:  ||  if self.price_deviation_threshold and self.executed_orders:  ||  ""max_gas_price"": self.max_gas_price  ||  if self.adjust_for_trend and self.executed_orders:  ||  remaining_orders = self.num_orders - self.orders_executed  ||  if not self.executed_orders:  ||  for order in self.executed_orders)  ||  total_quantity = sum(Decimal(str(order[""quantity""])) for order in self.executed_orders)  ||  for order in self.executed_orders)  ||  quantity: Executed quantity  ||  ""order_number"": self.orders_executed + 1,  ||  self.executed_orders.append(execution_record)  ||  self.orders_executed += 1  ||  logger.info(f""DCA order {self.orders_executed}/{self.num_orders} executed for {self.order_id}"")  ||  slices_executed: int = Field(default=0, description=""Number of slices executed"")  ||  executed_slices: List[Dict] = Field(default_factory=list, description=""Executed slice details"")  ||  """"""Check if next TWAP slice should execute.""""""  ||  if self.slices_executed >= self.total_slices:  ||  ""max_gas_price"": self.max_gas_price  ||  if self.executed_slices:  ||  last_slice = self.executed_slices[-1]  ||  remaining_slices = self.total_slices - self.slices_executed  ||  # Last slice - execute remaining quantity  ||  ""slice_number"": self.slices_executed + 1,  ||  self.executed_slices.append(slice_record)  ||  self.slices_executed += 1  ||  logger.info(f""TWAP slice {self.slices_executed}/{self.total_slices} executed for {self.order_id}"")"
"D:\dex\backend\app\strategy\autotrade_strategy.py","4823","from app.strategy.risk_scoring import RiskScorer, RiskFactors | from app.ai.market_intelligence import get_market_intelligence_engine | import logging","Autotrade strategy with AI integration.  ||  from app.strategy.risk_scoring import RiskScorer, RiskFactors  ||  class AIAutotradeStrategy:  ||  """"""Integrates AI intelligence into autotrade decisions.""""""  ||  self.risk_scorer = RiskScorer()  ||  self.min_intelligence_score = 0.6  # Minimum score to trade  ||  self.max_risk_score = 60  # Maximum acceptable risk  ||  async def evaluate_trade_opportunity(  ||  logger.info(f""AI evaluating trade for {token_address} on {chain}"")  ||  # Get risk score  ||  risk_factors = RiskFactors(  ||  risk_score = await self.risk_scorer.calculate_risk_score(risk_factors)  ||  should_trade = (  ||  risk_score.total_score <= self.max_risk_score and  ||  intelligence['coordination_analysis']['manipulation_risk'] < 0.5  ||  intelligence, risk_score, should_trade  ||  'decision': 'execute' if should_trade else 'skip',  ||  'risk_score': risk_score.total_score,  ||  'risk_level': risk_score.risk_level,  ||  'manipulation_risk': intelligence['coordination_analysis']['manipulation_risk'],  ||  'suggested_position_size': float(risk_score.suggested_position_percent),  ||  'suggested_slippage': float(risk_score.suggested_slippage),  ||  'positive': risk_score.positive_signals[:3],  ||  'negative': risk_score.risk_reasons[:3]  ||  def _generate_reasoning(self, intelligence, risk_score, should_trade):  ||  if should_trade:  ||  f""Trade approved: Intelligence score {intelligence['intelligence_score']:.2f} ""  ||  f""exceeds threshold, risk level {risk_score.risk_level} is acceptable. ""  ||  f""Suggested position: {risk_score.suggested_position_percent}% of capital.""  ||  if risk_score.total_score > self.max_risk_score:  ||  reasons.append(f""Risk too high ({risk_score.total_score}/100)"")  ||  if intelligence['coordination_analysis']['manipulation_risk'] >= 0.5:  ||  reasons.append(""High manipulation risk detected"")  ||  return f""Trade skipped: {', '.join(reasons)}"""
"D:\dex\backend\app\strategy\base.py","15906","from __future__ import annotations | import asyncio | import logging | from abc import ABC, abstractmethod | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Dict, List, Optional, Set, Union | from pydantic import BaseModel, Field","gas_used: int = Field(..., description=""Gas used for transaction"")  ||  gas_price: Decimal = Field(..., description=""Gas price paid"")  ||  max_gas_price: Optional[Decimal] = Field(None, description=""Maximum gas price"")  ||  ""max_gas_price"": self.max_gas_price  ||  """"""Limit order that executes at or better than specified price.""""""  ||  ""max_gas_price"": self.max_gas_price"
"D:\dex\backend\app\strategy\behavioral_analysis.py","36229","from __future__ import annotations | import asyncio | import logging | import random | import statistics | from collections import defaultdict, deque | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Set, Tuple, Union | from dataclasses import dataclass, field | from pydantic import BaseModel, Field | import numpy as np |         import random","Advanced wallet pattern recognition and behavioral analysis that goes beyond  ||  basic metrics to understand trader psychology, strategies, and success patterns.  ||  This system provides multi-dimensional trader classification and prediction.  ||  - Risk tolerance and timing behavior analysis  ||  SCALPER = ""scalper""              # Very short holds, frequent trades  ||  class RiskProfile(str, Enum):  ||  """"""Risk tolerance profiles.""""""  ||  FOMO_TRADER = ""fomo_trader""      # Buys peaks, sells valleys  ||  class TradeEvent:  ||  """"""Individual trade event with context.""""""  ||  trade_type: str  # buy/sell  ||  gas_price: Decimal  ||  market_cap_at_trade: Optional[Decimal] = None  ||  volume_24h_at_trade: Optional[Decimal] = None  ||  holder_count_at_trade: Optional[int] = None  ||  age_minutes_at_trade: Optional[int] = None  # For new pairs  ||  total_trades: int = 0  ||  early_entry_rate: Decimal = Decimal(""0"")  # % of trades in first 10% of token age  ||  risk_scaling_behavior: Decimal = Decimal(""0"")  # How they scale with conviction  ||  new_pair_focus_rate: Decimal = Decimal(""0"")  # % trades on pairs < 24h old  ||  follow_smart_money_rate: Decimal = Decimal(""0"")  # % trades following whales  ||  contrarian_trades_rate: Decimal = Decimal(""0"")   # % trades against trend  ||  gas_optimization_score: Decimal = Decimal(""0"")   # Gas efficiency  ||  time_of_day_patterns: Dict[int, Decimal] = field(default_factory=dict)  # Hour -> trade rate  ||  # Risk management  ||  wallet_address: str  ||  trade_count: int  ||  risk_profile: RiskProfile  ||  predictive_score: Decimal      # How predictive this trader is for others  ||  risk_warnings: List[str]  ||  copy_trade_recommendations: List[str]  ||  self.trade_history_cache: Dict[str, List[TradeEvent]] = {}  ||  async def analyze_trader_behavior(  ||  wallet_address: str,  ||  min_trades: int = 10  ||  Perform comprehensive behavioral analysis of a trader.  ||  wallet_address: Wallet to analyze  ||  min_trades: Minimum trades required for analysis  ||  if min_trades < 1:  ||  raise ValueError(""Minimum trades must be positive"")  ||  # Get trade history  ||  trades = await self._get_trade_history(wallet_address, lookback_days)  ||  if len(trades) < min_trades:  ||  logger.info(f""Insufficient trades for {wallet_address}: {len(trades)} < {min_trades}"")  ||  metrics = await self._calculate_behavioral_metrics(trades)  ||  trading_style = self._classify_trading_style(metrics, trades)  ||  risk_profile = self._classify_risk_profile(metrics)  ||  psychology_profile = self._classify_psychology(metrics, trades)  ||  timing_behavior = self._classify_timing_behavior(metrics, trades)  ||  skill_score = await self._calculate_skill_score(metrics, trades)  ||  innovation_score = self._calculate_innovation_score(metrics, trades)  ||  future_performance, confidence = await self._predict_future_performance(metrics, trades)  ||  risk_warnings = self._generate_risk_warnings(risk_profile, metrics)  ||  wallet_address=wallet_address,  ||  trade_count=len(trades),  ||  risk_profile=risk_profile,  ||  risk_warnings=risk_warnings,  ||  copy_trade_recommendations=copy_recommendations  ||  self.profile_cache[wallet_address] = profile  ||  logger.info(f""Completed behavioral analysis for {wallet_address}: {trading_style} / {psychology_profile}"")  ||  logger.error(f""Behavioral analysis failed for {wallet_address}: {e}"")  ||  async def _get_trade_history(self, wallet_address: str, lookback_days: int) -> List[TradeEvent]:  ||  """"""Get comprehensive trade history for analysis.""""""  ||  cache_key = f""{wallet_address}_{lookback_days}""  ||  if cache_key in self.trade_history_cache:  ||  return self.trade_history_cache[cache_key]  ||  # 2. DEX trade events  ||  # 3. Token metadata at trade time  ||  # 4. Market conditions at trade time  ||  trades = []  ||  random.seed(hash(wallet_address) % 2**32)  # Deterministic per wallet  ||  # Generate 20-200 trades depending on trader type  ||  num_trades = random.randint(20, 200)  ||  for i in range(num_trades):  ||  # Random trade timestamp within lookback period  ||  trade_time = cutoff_date + timedelta(  ||  # Create realistic trade  ||  trade = TradeEvent(  ||  timestamp=trade_time,  ||  trade_type=random.choice(['buy', 'sell']),  ||  gas_price=Decimal(str(random.uniform(20, 200))),  ||  market_cap_at_trade=Decimal(str(random.uniform(10000, 100000000))),  ||  volume_24h_at_trade=Decimal(str(random.uniform(1000, 1000000))),  ||  holder_count_at_trade=random.randint(100, 50000),  ||  age_minutes_at_trade=random.randint(5, 10080) if random.random() > 0.5 else None  ||  trades.append(trade)  ||  trades.sort(key=lambda t: t.timestamp)  ||  self.trade_history_cache[cache_key] = trades  ||  return trades  ||  async def _calculate_behavioral_metrics(self, trades: List[TradeEvent]) -> BehavioralMetrics:  ||  """"""Calculate comprehensive behavioral metrics from trade history.""""""  ||  if not trades:  ||  metrics.total_trades = len(trades)  ||  metrics.unique_tokens = len(set(t.token_address for t in trades))  ||  metrics.total_volume_usd = sum(t.amount_usd for t in trades)  ||  profitable_trades = [t for t in trades if t.profit_loss_pct and t.profit_loss_pct > 0]  ||  trades_with_pnl = [t for t in trades if t.profit_loss_pct is not None]  ||  if trades_with_pnl:  ||  metrics.win_rate = Decimal(len(profitable_trades)) / Decimal(len(trades_with_pnl)) * 100  ||  metrics.avg_profit_pct = sum(t.profit_loss_pct for t in trades_with_pnl) / len(trades_with_pnl)  ||  hold_times = [t.hold_time_hours for t in trades if t.hold_time_hours]  ||  # Early entry analysis (trades on tokens < 1 hour old)  ||  new_pair_trades = [t for t in trades if t.age_minutes_at_trade and t.age_minutes_at_trade < 60]  ||  metrics.new_pair_focus_rate = Decimal(len(new_pair_trades)) / Decimal(len(trades)) * 100  ||  early_trades = [t for t in trades if t.age_minutes_at_trade and t.age_minutes_at_trade < 180]  # < 3 hours  ||  metrics.early_entry_rate = Decimal(len(early_trades)) / Decimal(len(trades)) * 100  ||  position_sizes = [t.position_size_pct for t in trades]  ||  # Gas optimization (lower is better)  ||  gas_prices = [float(t.gas_price) for t in trades]  ||  if gas_prices:  ||  avg_gas = statistics.mean(gas_prices)  ||  market_avg_gas = 100  # Simplified  ||  metrics.gas_optimization_score = max(Decimal(""0""), Decimal(""100"") - Decimal(str(avg_gas / market_avg_gas * 100)))  ||  for trade in trades:  ||  hour_counts[trade.timestamp.hour] += 1  ||  total_hours = len(set(trade.timestamp.hour for trade in trades))  ||  metrics.time_of_day_patterns[hour] = Decimal(count) / Decimal(metrics.total_trades) * 100  ||  if metrics.total_trades > 0:  ||  metrics.diversification_score = Decimal(metrics.unique_tokens) / Decimal(metrics.total_trades) * 100  ||  # Risk management scores  ||  trades_with_stops = random.randint(0, len(trades) // 3)  # Simplified  ||  metrics.stop_loss_usage_rate = Decimal(trades_with_stops) / Decimal(len(trades)) * 100  ||  logger.debug(f""Calculated metrics: {metrics.total_trades} trades, {metrics.win_rate}% win rate"")  ||  def _classify_trading_style(self, metrics: BehavioralMetrics, trades: List[TradeEvent]) -> TradingStyle:  ||  elif float(metrics.contrarian_trades_rate or 0) > 40:  ||  def _classify_risk_profile(self, metrics: BehavioralMetrics) -> RiskProfile:  ||  """"""Classify risk tolerance based on position sizing and behavior.""""""  ||  return RiskProfile.ULTRA_CONSERVATIVE  ||  return RiskProfile.CONSERVATIVE  ||  return RiskProfile.MODERATE  ||  return RiskProfile.AGGRESSIVE  ||  return RiskProfile.EXTREME  ||  def _classify_psychology(self, metrics: BehavioralMetrics, trades: List[TradeEvent]) -> PsychologyProfile:  ||  elif float(metrics.contrarian_trades_rate or 0) > 50:  ||  def _classify_timing_behavior(self, metrics: BehavioralMetrics, trades: List[TradeEvent]) -> TimingBehavior:  ||  return TimingBehavior.FOMO_TRADER  ||  async def _calculate_skill_score(self, metrics: BehavioralMetrics, trades: List[TradeEvent]) -> Decimal:  ||  risk_mgmt_score = float(metrics.stop_loss_usage_rate or 0)  ||  risk_mgmt_score * 0.2  ||  """"""Calculate how predictive this trader's behavior is.""""""  ||  # Factors that make a trader predictive  ||  """"""Calculate how reliable/consistent this trader is.""""""  ||  def _calculate_innovation_score(self, metrics: BehavioralMetrics, trades: List[TradeEvent]) -> Decimal:  ||  """"""Calculate how innovative/early this trader is.""""""  ||  trades: List[TradeEvent]  ||  trade_count = len(trades)  ||  sample_size_confidence = min(1.0, trade_count / 100)  ||  strengths.append(""High win rate - consistent profitable trades"")  ||  if float(metrics.gas_optimization_score or 0) > 70:  ||  strengths.append(""Gas efficient execution"")  ||  elif float(metrics.gas_optimization_score or 0) < 30:  ||  weaknesses.append(""Poor gas optimization - overpaying fees"")  ||  strengths.append(""Good risk management with stop losses"")  ||  weaknesses.append(""Lacks proper risk management"")  ||  TradingStyle.CONTRARIAN: f""Contrarian approach with {metrics.contrarian_trades_rate:.1f}% counter-trend trades"",  ||  PsychologyProfile.DISCIPLINED: f""Disciplined trader with {metrics.consistency_score:.1f}/100 consistency score"",  ||  PsychologyProfile.CONTRARIAN_PSYCH: ""Contrarian psychology - trades against crowd sentiment""  ||  def _generate_risk_warnings(self, risk_profile: RiskProfile, metrics: BehavioralMetrics) -> List[str]:  ||  """"""Generate risk warnings based on profile.""""""  ||  if risk_profile in [RiskProfile.AGGRESSIVE, RiskProfile.EXTREME]:  ||  warnings.append(""High risk profile - large position sizes may lead to significant losses"")  ||  warnings.append(""Low stop-loss usage - trades may suffer large losses"")  ||  recommendations.append(""High win rate makes this trader suitable for copy trading"")  ||  recommendations.append(""Highly consistent - low risk for copy trading"")  ||  if float(metrics.gas_optimization_score or 0) > 70:  ||  recommendations.append(""Gas efficient - good for minimizing trading costs"")  ||  recommendations.append(""Good risk management - uses stop losses effectively"")  ||  async def analyze_trader_behavior(  ||  wallet_address: str,  ||  """"""Convenience function to analyze trader behavior.""""""  ||  return await analyzer.analyze_trader_behavior(wallet_address, lookback_days)  ||  async def batch_analyze_traders(  ||  wallet_addresses: List[str],  ||  """"""Analyze multiple traders concurrently.""""""  ||  profile = await analyzer.analyze_trader_behavior(address, lookback_days)  ||  tasks = [analyze_single(addr) for addr in wallet_addresses]  ||  logger.info(f""Completed batch analysis of {len(profiles)} traders"")  ||  # Test with sample wallet  ||  test_wallet = ""0x742d35cc6634c0532925a3b8d51d3b4c8e6b3ed3""  ||  profile = await analyzer.analyze_trader_behavior(test_wallet, lookback_days=30)  ||  required_fields = ['wallet_address', 'trading_style', 'risk_profile',"
"D:\dex\backend\app\strategy\behavioral_scoring.py","40518","from __future__ import annotations | import asyncio | import logging | import math | import statistics | from collections import defaultdict, deque | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Set, Tuple, Union | from dataclasses import dataclass, field | from pydantic import BaseModel, Field | import numpy as np |     from .behavioral_analysis import ( |         import random |         from .behavioral_analysis import BehavioralProfile, BehavioralMetrics, TradingStyle, RiskProfile, PsychologyProfile, TimingBehavior","Multi-dimensional trader classification and prediction engine that goes beyond  ||  simple metrics to provide sophisticated behavioral scoring, trader ranking,  ||  - Trader ranking and tier classification  ||  RiskProfile,  ||  TradeEvent  ||  RISK_MANAGEMENT = ""risk_management""      # Risk control effectiveness  ||  RISK_ADJUSTED = ""risk_adjusted""  # Risk-adjusted performance  ||  context: str  # ""copy_trading"", ""alpha_generation"", ""risk_management"", etc.  ||  # Copy trading weights - emphasize consistency and risk management  ||  ScoringDimension.RISK_MANAGEMENT: Decimal(""20""),  ||  ScoringDimension.RISK_MANAGEMENT: Decimal(""10"")  ||  # Risk management weights - emphasize control and discipline  ||  risk_mgmt_weights = ScoringWeights(  ||  ScoringDimension.RISK_MANAGEMENT: Decimal(""30""),  ||  context=""risk_management""  ||  ""risk_management"": risk_mgmt_weights  ||  ScoringDimension.RISK_MANAGEMENT: self._score_risk_management,  ||  behavioral_profile: Trader's behavioral analysis  ||  behavioral_profile.wallet_address,  ||  self.score_history[behavioral_profile.wallet_address].append(composite_score)  ||  # Keep only last 100 scores per trader  ||  if len(self.score_history[behavioral_profile.wallet_address]) > 100:  ||  self.score_history[behavioral_profile.wallet_address] = \  ||  self.score_history[behavioral_profile.wallet_address][-100:]  ||  logger.info(f""Calculated composite score {weighted_score:.1f}/100 for {behavioral_profile.wallet_address}"")  ||  logger.error(f""Composite scoring failed for {behavioral_profile.wallet_address}: {e}"")  ||  # Emphasize risk management and emotional control in volatile markets  ||  adjusted_weights[ScoringDimension.RISK_MANAGEMENT] = \  ||  adjusted_weights.get(ScoringDimension.RISK_MANAGEMENT, Decimal(""0"")) + Decimal(""5"")  ||  """"""Score pure trading skill based on risk-adjusted returns.""""""  ||  # Adjust for trade count (more trades = higher confidence)  ||  trade_count_factor = min(1.0, profile.trade_count / 100)  ||  skill_score = base_score * trade_count_factor  ||  confidence = min(100, trade_count_factor * 100 * (float(metrics.consistency_score or 50) / 100))  ||  f""Trade count factor: {trade_count_factor:.2f}""  ||  confidence = min(100, profile.trade_count / 2)  # Higher with more trades  ||  confidence = min(100, profile.trade_count)  ||  async def _score_risk_management(self, profile: BehavioralProfile, regime: Optional[MarketRegime]) -> DimensionScore:  ||  """"""Score risk management effectiveness.""""""  ||  # Risk scoring (conservative is better for risk mgmt)  ||  risk_score = (  ||  confidence = 90  # Risk management is observable  ||  dimension=ScoringDimension.RISK_MANAGEMENT,  ||  score=Decimal(str(risk_score)),  ||  confidence = min(100, profile.trade_count / 2)  ||  # Gas optimization  ||  gas_score = float(metrics.gas_optimization_score or 50)  ||  gas_score * 0.7 +  ||  f""Gas optimization: {gas_score:.1f}%"",  ||  # Base score on risk profile (conservative handles volatility better)  ||  risk_profiles = {  ||  RiskProfile.ULTRA_CONSERVATIVE: 90,  ||  RiskProfile.CONSERVATIVE: 80,  ||  RiskProfile.MODERATE: 70,  ||  RiskProfile.AGGRESSIVE: 60,  ||  RiskProfile.EXTREME: 40  ||  score = risk_profiles.get(profile.risk_profile, 50)  ||  contributing_factors=[f""Risk profile: {profile.risk_profile}""]  ||  score = float(profile.metrics.gas_optimization_score or 50)  # Proxy measure  ||  # Conservative traders scale better  ||  risk_penalty = float(profile.metrics.avg_position_size_pct or 10) / 2  ||  score = max(0, 100 - risk_penalty)  ||  contributing_factors=[f""Average position size: {risk_penalty*2:.1f}%""]  ||  """"""Classify trader tier based on composite score.""""""  ||  wallet_address: str,  ||  if weakness == ScoringDimension.RISK_MANAGEMENT:  ||  recommendations.append(""Optimize gas usage and DEX routing"")  ||  async def score_trader_behavior(  ||  """"""Convenience function to score trader behavior.""""""  ||  async def batch_score_traders(  ||  """"""Score multiple traders concurrently.""""""  ||  return profile.wallet_address, score  ||  wallet, score = result  ||  scores[wallet] = score  ||  logger.info(f""Completed batch scoring of {len(scores)} traders"")  ||  from .behavioral_analysis import BehavioralProfile, BehavioralMetrics, TradingStyle, RiskProfile, PsychologyProfile, TimingBehavior  ||  total_trades=150,  ||  gas_optimization_score=Decimal(""65.4""),  ||  wallet_address=""0x123...789"",  ||  trade_count=150,  ||  risk_profile=RiskProfile.MODERATE,  ||  key_weaknesses=[""Risk management""],  ||  behavioral_summary=""Disciplined momentum trader"",  ||  risk_warnings=[],  ||  copy_trade_recommendations=[""Good for momentum strategies""]"
"D:\dex\backend\app\strategy\coordinator.py","30178","from __future__ import annotations | import asyncio | import time | from decimal import Decimal | from typing import Dict, List, Optional, Set, Any, Tuple, Union | from dataclasses import dataclass, field | from datetime import datetime, timezone, timedelta | from enum import Enum | from collections import defaultdict, deque | import heapq | import logging | from ..core.settings import settings | from ..strategy.risk_manager import risk_manager, RiskAssessment | from ..strategy.safety_controls import safety_controls | from ..chains.evm_client import evm_client | from ..chains.solana_client import solana_client | from ..discovery.chain_watchers import PairCreatedEvent | from ..ws.discovery_hub import broadcast_trading_opportunity | from .base import ( | from .position_sizing import position_sizer, PortfolioMetrics, HistoricalPerformance | from .timing import timing_engine, TimingResult, TimingSignal |         import random |         from .timing import PricePoint","from ..strategy.risk_manager import risk_manager, RiskAssessment  ||  from ..strategy.safety_controls import safety_controls  ||  LOW = ""low""          # Opportunistic trades, rebalancing  ||  average_gas_cost: Decimal  ||  estimated_gas: Decimal  ||  and provides portfolio-level risk management.  ||  self.max_concurrent_executions = settings.max_concurrent_trades  ||  self.max_daily_executions = settings.max_daily_trades  ||  average_gas_cost=Decimal(""0""),  ||  if not await strategy.should_execute():  ||  # Check risk assessment  ||  risk_assessment = await risk_manager.assess_risk(  ||  if not await safety_controls.check_trade_safety(risk_assessment, signal.chain):  ||  f""Signal blocked by safety controls: {signal.signal_id}"",  ||  risk_assessment=risk_assessment  ||  timing_result = await self._analyze_signal_timing(signal, risk_assessment)  ||  # Estimate gas cost for prioritization  ||  estimated_gas = await self._estimate_execution_gas(execution, chain)  ||  estimated_gas=estimated_gas  ||  # Check if we can execute more trades  ||  # Execute the trade  ||  await self._execute_trade(execution, queue_item.chain)  ||  async def _execute_trade(self, execution: StrategyExecution, chain: str) -> None:  ||  """"""Execute a single trade.""""""  ||  f""Executing trade: {execution_id}"",  ||  # Simulate trade execution (replace with actual trading logic)  ||  await self._simulate_trade_execution(execution, chain)  ||  f""Trade executed successfully: {execution_id}"",  ||  f""Trade execution failed: {e}"",  ||  async def _simulate_trade_execution(self, execution: StrategyExecution, chain: str) -> None:  ||  """"""Simulate trade execution (replace with actual implementation).""""""  ||  ""gas_cost"": float(Decimal(""0.001"") * position_size),  # 0.1% gas cost  ||  risk_assessment: Optional[RiskAssessment]  ||  risk_assessment=risk_assessment  ||  async def _estimate_execution_gas(self, execution: StrategyExecution, chain: str) -> Decimal:  ||  """"""Estimate gas cost for execution.""""""  ||  # Mock gas estimation (replace with actual estimation)  ||  base_gas = {  ||  return base_gas.get(chain, Decimal(""0.001""))"
"D:\dex\backend\app\strategy\copytrade.py","26403","from __future__ import annotations | import asyncio | import logging | from collections import defaultdict, deque | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Set, Tuple | from urllib.parse import urlparse | from pydantic import BaseModel, Field | from ..storage.database import get_session_context | from ..core.settings import get_settings |     from ..trading.executor import TradeExecutor |     from ..strategy.risk_manager import RiskManager |     from ..services.pricing import PricingService   |         import random |         import time","Advanced copy trading implementation with trader tracking, signal detection,  ||  successful traders and automatically copying their trades.  ||  File: backend/app/strategy/copytrade.py  ||  from ..trading.executor import TradeExecutor  ||  class TradeExecutor:  ||  from ..strategy.risk_manager import RiskManager  ||  class RiskManager:  ||  MIRROR = ""mirror""           # Mirror trader's exact position size percentage  ||  FIXED_AMOUNT = ""fixed_amount""  # Copy with fixed GBP amount per trade  ||  SIGNAL_ONLY = ""signal_only"" # Track signals but don't execute  ||  class TraderTier(str, Enum):  ||  """"""Trader performance tiers.""""""  ||  ROOKIE = ""rookie""           # < 50 trades, < 60% win rate  ||  EXPERIENCED = ""experienced"" # 50+ trades, 60%+ win rate  ||  EXPERT = ""expert""           # 100+ trades, 70%+ win rate, good Sharpe  ||  LEGEND = ""legend""           # 500+ trades, 75%+ win rate, excellent metrics  ||  class TraderMetrics(BaseModel):  ||  """"""Comprehensive trader performance metrics.""""""  ||  trader_address: str  ||  total_trades: int = 0  ||  winning_trades: int = 0  ||  avg_trade_size_usd: Decimal = Decimal(""0"")  ||  if self.total_trades == 0:  ||  return (Decimal(self.winning_trades) / Decimal(self.total_trades)) * Decimal(""100"")  ||  def avg_profit_per_trade(self) -> Decimal:  ||  """"""Calculate average profit per trade.""""""  ||  if self.total_trades == 0:  ||  return self.total_profit_loss / Decimal(self.total_trades)  ||  def tier(self) -> TraderTier:  ||  """"""Calculate trader tier based on performance.""""""  ||  if self.total_trades < 50:  ||  return TraderTier.ROOKIE  ||  elif self.total_trades < 100 or self.win_rate < Decimal(""70""):  ||  return TraderTier.EXPERIENCED  ||  elif self.total_trades < 500 or self.win_rate < Decimal(""75""):  ||  return TraderTier.EXPERT  ||  return TraderTier.LEGEND  ||  class CopyTradeSignal(BaseModel):  ||  """"""Individual copy trade signal from monitored trader.""""""  ||  trader_address: str  ||  trade_type: str  # ""buy"" or ""sell""  ||  risk_score: Decimal = Decimal(""5"")  ||  class CopyTradeConfig(BaseModel):  ||  followed_traders: List[str] = Field(default_factory=list)  ||  # Trader filtering  ||  min_trader_tier: TraderTier = TraderTier.EXPERIENCED  ||  min_total_trades: int = Field(50, ge=1)  ||  max_risk_score: Decimal = Field(Decimal(""7""), ge=1, le=10)  ||  # Trade filtering  ||  min_trade_amount_usd: Decimal = Field(Decimal(""100""), gt=0)  ||  max_trade_amount_usd: Decimal = Field(Decimal(""10000""), gt=0)  ||  # Risk management  ||  class TraderDatabase:  ||  """"""Database for tracking trader performance and signals.""""""  ||  """"""Initialize trader database.""""""  ||  self.trader_metrics: Dict[str, TraderMetrics] = {}  ||  self.signal_history: Dict[str, List[CopyTradeSignal]] = defaultdict(list)  ||  async def add_trader(self, trader_address: str) -> TraderMetrics:  ||  """"""Add or update trader in database.""""""  ||  if trader_address not in self.trader_metrics:  ||  self.trader_metrics[trader_address] = TraderMetrics(trader_address=trader_address)  ||  await self._update_trader_metrics(trader_address)  ||  return self.trader_metrics[trader_address]  ||  async def _update_trader_metrics(self, trader_address: str) -> None:  ||  """"""Update trader performance metrics.""""""  ||  # 1. Query on-chain data for the trader's transaction history  ||  # 2. Calculate performance metrics from historical trades  ||  # 3. Update the TraderMetrics object  ||  def add_signal(self, signal: CopyTradeSignal) -> None:  ||  """"""Add a new copy trade signal.""""""  ||  self.signal_history[signal.trader_address].append(signal)  ||  logger.debug(f""Added copy trade signal: {signal.signal_id}"")  ||  trader_address: Optional[str] = None,  ||  ) -> List[CopyTradeSignal]:  ||  """"""Get recent signals, optionally filtered by trader.""""""  ||  if trader_address:  ||  signals = [s for s in signals if s.trader_address == trader_address]  ||  def get_top_traders(self, limit: int = 20) -> List[TraderMetrics]:  ||  """"""Get top performing traders.""""""  ||  traders = list(self.trader_metrics.values())  ||  def performance_score(trader: TraderMetrics) -> Decimal:  ||  if trader.total_trades == 0:  ||  # Weighted score: win_rate * profit_per_trade * sqrt(total_trades)  ||  base_score = (trader.win_rate / 100) * trader.avg_profit_per_trade  ||  volume_multiplier = Decimal(trader.total_trades).sqrt()  ||  traders.sort(key=performance_score, reverse=True)  ||  return traders[:limit]  ||  """"""Detects and processes copy trade signals from monitored traders.""""""  ||  def __init__(self, trader_db: TraderDatabase) -> None:  ||  self.trader_db = trader_db  ||  """"""Start monitoring for copy trade signals.""""""  ||  logger.info(""Started copy trade signal monitoring"")  ||  logger.info(""Stopped copy trade signal monitoring"")  ||  """"""Scan for new copy trade signals.""""""  ||  # 1. Monitor mempool for transactions from tracked traders  ||  # 2. Parse transaction data to extract trade information  ||  # 3. Calculate confidence scores based on trader history  ||  # 4. Generate signals for qualified trades  ||  trader_address = f""0x{''.join(random.choices('0123456789abcdef', k=40))}""  ||  # Ensure trader exists in database  ||  await self.trader_db.add_trader(trader_address)  ||  signal = CopyTradeSignal(  ||  trader_address=trader_address,  ||  trade_type=random.choice([""buy"", ""sell""]),  ||  risk_score=Decimal(str(random.uniform(3, 8)))  ||  self.trader_db.add_signal(signal)  ||  logger.info(f""Detected copy trade signal: {signal.token_symbol} {signal.trade_type} from {signal.trader_address[:8]}..."")  ||  class CopyTradeExecutor:  ||  """"""Executes copy trades based on signals and user configuration.""""""  ||  def __init__(self, trader_db: TraderDatabase) -> None:  ||  """"""Initialize copy trade executor.""""""  ||  self.trader_db = trader_db  ||  self.trade_executor = TradeExecutor()  ||  logger.warning(f""TradeExecutor not available: {e}"")  ||  self.trade_executor = None  ||  self.risk_manager = RiskManager()  ||  logger.warning(f""RiskManager not available: {e}"")  ||  self.risk_manager = None  ||  self.user_configs: Dict[int, CopyTradeConfig] = {}  ||  """"""Start copy trade execution.""""""  ||  logger.warning(""Copy trade executor already active"")  ||  logger.info(""Started copy trade executor"")  ||  """"""Stop copy trade execution.""""""  ||  logger.info(""Stopped copy trade executor"")  ||  async def set_user_config(self, user_id: int, config: CopyTradeConfig) -> None:  ||  logger.info(f""Updated copy trade config for user {user_id}"")  ||  """"""Main execution loop for processing copy trades.""""""  ||  logger.error(f""Error in copy trade execution loop: {e}"")  ||  recent_signals = [s for s in list(self.trader_db.recent_signals)[-100:] if not s.processed]  ||  await self._queue_copy_trade(user_id, signal, config)  ||  async def _should_copy_signal(self, signal: CopyTradeSignal, config: CopyTradeConfig) -> bool:  ||  # Check if trader is in followed list  ||  if config.followed_traders and signal.trader_address not in config.followed_traders:  ||  # Check confidence and risk scores  ||  if signal.risk_score > config.max_risk_score:  ||  # Check trader metrics  ||  trader = self.trader_db.trader_metrics.get(signal.trader_address)  ||  if trader:  ||  if trader.total_trades < config.min_total_trades:  ||  if trader.win_rate < config.min_win_rate:  ||  async def _queue_copy_trade(  ||  signal: CopyTradeSignal,  ||  config: CopyTradeConfig  ||  """"""Queue a copy trade for execution.""""""  ||  copy_trade = {  ||  await self.execution_queue.put(copy_trade)  ||  logger.info(f""Queued copy trade for user {user_id}: {signal.token_symbol} - {copy_amount} GBP"")  ||  async def _calculate_copy_amount(self, signal: CopyTradeSignal, config: CopyTradeConfig) -> Decimal:  ||  # Mirror the percentage of trader's portfolio  ||  # This would require knowing the trader's total portfolio value  ||  # Scale based on user's portfolio size vs trader's portfolio size  ||  """"""Process queued copy trades.""""""  ||  copy_trade = await asyncio.wait_for(self.execution_queue.get(), timeout=0.1)  ||  await self._execute_copy_trade(copy_trade)  ||  async def _execute_copy_trade(self, copy_trade: Dict[str, Any]) -> None:  ||  """"""Execute a copy trade.""""""  ||  user_id = copy_trade[""user_id""]  ||  signal = copy_trade[""signal""]  ||  config = copy_trade[""config""]  ||  copy_amount = copy_trade[""copy_amount""]  ||  # 1. Get user's wallet and check balances  ||  # 2. Execute the actual trade through the trading engine  ||  # 3. Record the trade in the database  ||  logger.info(f""Executing copy trade for user {user_id}: {signal.token_symbol} {signal.trade_type} - {copy_amount} GBP"")  ||  if signal.trade_type == ""buy"":  ||  elif signal.trade_type == ""sell"" and position[""amount""] > 0:  ||  logger.error(f""Failed to execute copy trade: {e}"")  ||  """"""Monitor active copy trade positions for stop-loss/take-profit.""""""  ||  # Check position age and perform risk management  ||  # 4. Execute exit trades if conditions are met  ||  class CopyTradeManager:  ||  """"""Initialize copy trade manager.""""""  ||  self.trader_db = TraderDatabase()  ||  self.signal_detector = SignalDetector(self.trader_db)  ||  self.executor = CopyTradeExecutor(self.trader_db)  ||  async def set_user_config(self, user_id: int, config: CopyTradeConfig) -> None:  ||  async def get_user_config(self, user_id: int) -> Optional[CopyTradeConfig]:  ||  async def get_top_traders(self, limit: int = 20) -> List[TraderMetrics]:  ||  """"""Get top performing traders.""""""  ||  return self.trader_db.get_top_traders(limit)  ||  """"""Get active copy trade positions for a user.""""""  ||  _copy_trade_manager: Optional[CopyTradeManager] = None  ||  async def get_copy_trade_manager() -> Optional[CopyTradeManager]:  ||  """"""Get the global copy trade manager instance.""""""  ||  global _copy_trade_manager  ||  if _copy_trade_manager is None:  ||  _copy_trade_manager = CopyTradeManager()  ||  logger.error(f""Failed to initialize copy trade manager: {e}"")  ||  return _copy_trade_manager  ||  ""TraderTier"",  ||  ""TraderMetrics"",  ||  ""CopyTradeSignal"",  ||  ""CopyTradeConfig"",  ||  ""TraderDatabase"",  ||  ""CopyTradeExecutor"",  ||  ""CopyTradeManager"",  ||  ""get_copy_trade_manager"""
"D:\dex\backend\app\strategy\frontrunning_protection.py","33556","from __future__ import annotations | import asyncio | import hashlib | import logging | import random | import statistics | from collections import defaultdict, deque | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Set, Tuple, Union | from dataclasses import dataclass, field | from pydantic import BaseModel, Field | import numpy as np |         import random","Advanced protection against being frontrun by tracked wallets and MEV bots,  ||  - Tracked wallet behavior prediction  ||  - Dynamic gas strategy adaptation  ||  COPY_TRADER = ""copy_trader""             # Fast copy trading bots  ||  WHALE_FRONTRUN = ""whale_frontrun""       # Large traders copying signals  ||  COORDINATED_ATTACK = ""coordinated_attack""  # Multiple wallets coordinating  ||  GAS_STRATEGY = ""gas_strategy""          # Dynamic gas optimization  ||  gas_price_delta: Decimal  ||  class WalletBehaviorPattern:  ||  """"""Behavioral pattern analysis for wallet.""""""  ||  wallet_address: str  ||  pattern_type: str  # ""mev_bot"", ""copy_trader"", ""normal"", etc.  ||  gas_premium_tendency: Decimal  # How much extra gas they pay  ||  gas_price_behavior: str  # ""aggressive"", ""moderate"", ""efficient""  ||  follows_specific_wallets: List[str]  ||  monitor_wallets: List[str] = field(default_factory=list)  ||  gas_premium_limit_pct: Decimal = Decimal(""20"")  ||  self.wallet_patterns: Dict[str, WalletBehaviorPattern] = {}  ||  gas_price = int(tx_data.get(""gasPrice"", 0))  ||  # Analyze gas price behavior  ||  if gas_price > 200e9:  # > 200 Gwei indicates aggressive frontrunning  ||  return await self._analyze_aggressive_gas_behavior(tx_data)  ||  # Analyze wallet behavior patterns  ||  pattern_threat = await self._analyze_wallet_pattern(tx_data)  ||  async def _analyze_aggressive_gas_behavior(self, tx_data: Dict[str, Any]) -> Optional[FrontrunningThreat]:  ||  """"""Analyze aggressive gas price behavior.""""""  ||  gas_price = int(tx_data.get(""gasPrice"", 0))  ||  # Track gas price history for this wallet  ||  if from_address not in self.wallet_patterns:  ||  return FrontrunningThreat.MEV_BOT  # Unknown wallet with high gas = likely MEV  ||  pattern = self.wallet_patterns[from_address]  ||  # If consistently high gas + high frequency = MEV bot  ||  if (pattern.gas_premium_tendency > 50 and  ||  # 1. High gas price transaction before target  ||  # 2. Low gas price transaction after target  ||  # 3. Same wallet for both transactions  ||  # Look for recent transactions from same wallet  ||  # Check for gas price pattern (high -> low)  ||  gas_prices = [int(tx.get(""gasPrice"", 0)) for tx in recent_txs]  ||  if len(gas_prices) >= 2 and gas_prices[0] > gas_prices[-1] * 2:  ||  async def _analyze_wallet_pattern(self, tx_data: Dict[str, Any]) -> Optional[FrontrunningThreat]:  ||  """"""Analyze wallet behavior patterns.""""""  ||  if from_address not in self.wallet_patterns:  ||  pattern = self.wallet_patterns[from_address]  ||  elif pattern.pattern_type == ""copy_trader"":  ||  return FrontrunningThreat.COPY_TRADER  ||  async def update_wallet_pattern(self, wallet_address: str, tx_data: Dict[str, Any]) -> None:  ||  """"""Update behavioral pattern for a wallet.""""""  ||  wallet_address = wallet_address.lower()  ||  if wallet_address not in self.wallet_patterns:  ||  self.wallet_patterns[wallet_address] = WalletBehaviorPattern(  ||  wallet_address=wallet_address,  ||  gas_premium_tendency=Decimal(""0""),  ||  gas_price_behavior=""moderate"",  ||  follows_specific_wallets=[],  ||  pattern = self.wallet_patterns[wallet_address]  ||  # Update gas behavior  ||  gas_price = int(tx_data.get(""gasPrice"", 0))  ||  if gas_price > 100e9:  # > 100 Gwei  ||  pattern.gas_premium_tendency = min(100, pattern.gas_premium_tendency + Decimal(""5""))  ||  if pattern.gas_premium_tendency > 80 and pattern.transaction_frequency > 50:  ||  pattern.pattern_type = ""copy_trader""  ||  async def analyze_execution_risk(  ||  trade_request: Dict[str, Any],  ||  target_wallets: List[str] = None  ||  Analyze frontrunning risk for a trade execution.  ||  trade_request: Trade details to execute  ||  target_wallets: Specific wallets to monitor for  ||  Tuple of (threat_level, detected_threats, risk_analysis)  ||  token_address = trade_request.get(""token_address"", """")  ||  trade_amount = Decimal(str(trade_request.get(""amount"", 0)))  ||  risk_factors = {}  ||  # Check for wallet-specific threats  ||  if target_wallets:  ||  wallet_threats = await self._analyze_target_wallets(target_wallets, token_address)  ||  detected_threats.extend(wallet_threats)  ||  # Analyze trade size risk  ||  size_risk = await self._analyze_trade_size_risk(trade_amount, token_address)  ||  risk_factors[""size_risk""] = size_risk  ||  coordination_risk = await self._detect_coordinated_attacks(token_address)  ||  if coordination_risk:  ||  threat_level = self._calculate_threat_level(detected_threats, risk_factors)  ||  logger.info(f""Risk analysis: {threat_level} threat level with {len(detected_threats)} threats"")  ||  return threat_level, detected_threats, risk_factors  ||  logger.error(f""Risk analysis failed: {e}"")  ||  # 3. Analyze gas prices and wallet patterns  ||  FrontrunningThreat.COPY_TRADER,  ||  async def _analyze_target_wallets(self, target_wallets: List[str], token_address: str) -> List[FrontrunningThreat]:  ||  """"""Analyze specific wallets for frontrunning behavior.""""""  ||  for wallet in target_wallets:  ||  # Check if wallet is actively trading this token  ||  pattern = self.mempool_monitor.wallet_patterns.get(wallet.lower())  ||  elif pattern.pattern_type == ""copy_trader"":  ||  threats.append(FrontrunningThreat.COPY_TRADER)  ||  async def _analyze_trade_size_risk(self, amount: Decimal, token_address: str) -> Decimal:  ||  """"""Analyze risk based on trade size.""""""  ||  # Larger trades are more attractive to frontrunners  ||  # - Typical trade sizes  ||  return Decimal(""90"")  # High risk  ||  return Decimal(""70"")  # Moderate risk  ||  return Decimal(""40"")  # Low risk  ||  return Decimal(""10"")  # Minimal risk  ||  # Look for multiple wallets with similar behavior patterns  ||  for group_id, wallets in self.mempool_monitor.coordination_groups.items():  ||  active_wallets = 0  ||  for wallet in wallets:  ||  pattern = self.mempool_monitor.wallet_patterns.get(wallet)  ||  active_wallets += 1  ||  if active_wallets >= 3:  # 3+ wallets active = coordination  ||  risk_factors: Dict[str, Any]  ||  if not threats and not risk_factors:  ||  FrontrunningThreat.COPY_TRADER: 60,  ||  # Add risk factor scoring  ||  size_risk = float(risk_factors.get(""size_risk"", 0))  ||  total_risk = max_threat_score + size_risk * 0.2  ||  if total_risk >= 90:  ||  elif total_risk >= 70:  ||  elif total_risk >= 40:  ||  elif total_risk >= 20:  ||  trade_request: Dict[str, Any]  ||  strategies.append(ProtectionStrategy.GAS_STRATEGY)  ||  if trade_request.get(""amount"", 0) > 10000:  # Large trades  ||  async def execute_protection_strategies(  ||  trade_request: Dict[str, Any]  ||  """"""Execute protection strategies and modify trade request.""""""  ||  protected_request = trade_request.copy()  ||  ""gas_adjustment"": Decimal(""0""),  ||  elif strategy == ProtectionStrategy.GAS_STRATEGY:  ||  gas_adj = await self._apply_gas_strategy(protected_request)  ||  execution_metadata[""gas_adjustment""] = gas_adj  ||  async def _apply_timing_delay(self, trade_request: Dict[str, Any]) -> int:  ||  async def _apply_order_splitting(self, trade_request: Dict[str, Any]) -> int:  ||  original_amount = Decimal(str(trade_request.get(""amount"", 0)))  ||  trade_request[""amount""] = float(split_amount)  ||  trade_request[""split_count""] = splits  ||  trade_request[""is_split_order""] = True  ||  async def _apply_gas_strategy(self, trade_request: Dict[str, Any]) -> Decimal:  ||  """"""Apply dynamic gas strategy.""""""  ||  # 1. Analyze current gas prices  ||  # 2. Predict MEV bot gas prices  ||  # 3. Set competitive but not excessive gas  ||  # Simplified gas adjustment  ||  gas_premium = random.uniform(5, 15)  # 5-15% premium  ||  gas_premium = min(gas_premium, float(self.config.gas_premium_limit_pct))  ||  trade_request[""gas_premium_pct""] = gas_premium  ||  logger.debug(f""Applied {gas_premium}% gas premium"")  ||  return Decimal(str(gas_premium))  ||  async def _apply_randomization(self, trade_request: Dict[str, Any]) -> None:  ||  amount = Decimal(str(trade_request.get(""amount"", 0)))  ||  trade_request[""amount""] = float(adjusted_amount)  ||  # Add random gas price variation  ||  gas_variation = random.uniform(-2, 5)  # -2% to +5%  ||  current_premium = trade_request.get(""gas_premium_pct"", 0)  ||  trade_request[""gas_premium_pct""] = max(0, current_premium + gas_variation)  ||  async def _apply_private_mempool(self, trade_request: Dict[str, Any]) -> None:  ||  trade_request[""private_mempool_provider""] = provider  ||  trade_request[""use_private_mempool""] = True  ||  async def _apply_stealth_mode(self, trade_request: Dict[str, Any]) -> None:  ||  trade_request[""stealth_mode""] = True  ||  trade_request[""minimize_logs""] = True  ||  current_amount = Decimal(str(trade_request.get(""amount"", 0)))  ||  if current_amount > 10000:  # Reduce large trades  ||  trade_request[""amount""] = float(current_amount * Decimal(""0.5""))  ||  trade_request[""stealth_reduction""] = True  ||  async def analyze_frontrunning_risk(  ||  trade_request: Dict[str, Any],  ||  """"""Convenience function to analyze frontrunning risk.""""""  ||  # Analyze risk  ||  threat_level, threats, risk_factors = await protector.analyze_execution_risk(trade_request)  ||  strategies = await protector.generate_protection_strategy(threat_level, threats, trade_request)  ||  async def protect_trade_execution(  ||  trade_request: Dict[str, Any],  ||  threat_level, threats, _ = await protector.analyze_execution_risk(trade_request)  ||  strategies = await protector.generate_protection_strategy(threat_level, threats, trade_request)  ||  protected_request, metadata = await protector.execute_protection_strategies(strategies, trade_request)  ||  ProtectionStrategy.GAS_STRATEGY  ||  # Create test trade request  ||  trade_request = {  ||  ""trade_type"": ""buy"",  ||  # Test risk analysis  ||  threat_level, threats, risk_factors = await protector.analyze_execution_risk(trade_request)  ||  strategies = await protector.generate_protection_strategy(threat_level, threats, trade_request)  ||  protected_request, metadata = await protector.execute_protection_strategies(strategies, trade_request)"
"D:\dex\backend\app\strategy\portfolio_analysis.py","43058","from __future__ import annotations | import asyncio | import logging | import math | import random | import statistics | from collections import defaultdict, deque | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Set, Tuple, Union | from dataclasses import dataclass, field | from pydantic import BaseModel, Field | import numpy as np |         import random","Complete trader portfolio understanding and strategy detection system.  ||  Analyzes entire portfolio compositions, correlations, risk exposures,  ||  - Risk exposure and correlation analysis  ||  RISK_PARITY = ""risk_parity""                     # Equal risk allocation approach  ||  BARBELL_STRATEGY = ""barbell_strategy""           # Mix of safe + high-risk assets  ||  class RiskLevel(str, Enum):  ||  """"""Risk level classifications.""""""  ||  EXTREME = ""extreme""        # Ultra high-risk speculation  ||  last_trade_date: datetime  ||  risk_level: Optional[RiskLevel] = None  ||  # Risk metrics  ||  wallet_address: str  ||  # Risk metrics  ||  portfolio_risk_score: Decimal  # 0-100  ||  value_at_risk_5pct: Decimal  ||  risk_level_allocations: Dict[RiskLevel, Decimal] = field(default_factory=dict)  ||  risk_warnings: List[str] = field(default_factory=list)  ||  wallet_address: str  ||  # Risk evolution  ||  risk_profile_changes: List[Tuple[datetime, str, Decimal]]  # date, change_type, magnitude  ||  wallet_address: str,  ||  wallet_address: Wallet to analyze  ||  ValueError: If wallet address invalid  ||  if not wallet_address or not wallet_address.startswith(""0x""):  ||  raise ValueError(""Invalid wallet address"")  ||  positions = await self._get_current_positions(wallet_address, include_dust_threshold)  ||  logger.warning(f""No positions found for {wallet_address}"")  ||  return self._create_empty_snapshot(wallet_address)  ||  # Analyze risk metrics  ||  risk_metrics = await self._analyze_portfolio_risk(positions)  ||  risk_level_allocations = self._calculate_risk_level_allocations(positions)  ||  risk_warnings = self._generate_risk_warnings(positions, risk_metrics)  ||  wallet_address=wallet_address,  ||  portfolio_risk_score=risk_metrics[""portfolio_risk_score""],  ||  value_at_risk_5pct=risk_metrics[""var_5pct""],  ||  expected_shortfall=risk_metrics[""expected_shortfall""],  ||  risk_level_allocations=risk_level_allocations,  ||  risk_warnings=risk_warnings,  ||  self.portfolio_cache[wallet_address] = snapshot  ||  logger.error(f""Portfolio analysis failed for {wallet_address}: {e}"")  ||  return self._create_empty_snapshot(wallet_address)  ||  wallet_address: str,  ||  """"""Get current token positions for wallet.""""""  ||  ""risk_level"": RiskLevel.LOW,  ||  ""risk_level"": RiskLevel.MODERATE,  ||  ""risk_level"": RiskLevel.MODERATE,  ||  ""risk_level"": RiskLevel.VERY_LOW,  ||  ""risk_level"": RiskLevel.VERY_HIGH,  ||  random.seed(hash(wallet_address) % 2**32)  # Deterministic per wallet  ||  last_trade_date=datetime.utcnow() - timedelta(days=random.randint(1, 30)),  ||  risk_level=token_data[""risk_level""],  ||  def _create_empty_snapshot(self, wallet_address: str) -> PortfolioSnapshot:  ||  wallet_address=wallet_address,  ||  portfolio_risk_score=Decimal(""0""),  ||  value_at_risk_5pct=Decimal(""0""),  ||  # Risk level analysis  ||  risk_allocations = defaultdict(lambda: Decimal(""0""))  ||  risk_allocations[pos.risk_level] += Decimal(str(pos.current_value_usd))  ||  # Check for risk parity (equal risk allocation)  ||  risk_values = list(risk_allocations.values())  ||  if len(risk_values) > 2:  ||  risk_variance = statistics.variance([float(v) for v in risk_values])  ||  if risk_variance < float(total_value) * 0.1:  # Low variance = risk parity  ||  return PortfolioStrategy.RISK_PARITY, Decimal(""70"")  ||  # Check for barbell (safe + risky)  ||  safe_allocation = risk_allocations.get(RiskLevel.VERY_LOW, Decimal(""0"")) + \  ||  risk_allocations.get(RiskLevel.LOW, Decimal(""0""))  ||  risky_allocation = risk_allocations.get(RiskLevel.VERY_HIGH, Decimal(""0"")) + \  ||  risk_allocations.get(RiskLevel.EXTREME, Decimal(""0""))  ||  if safe_allocation / total_value > 0.3 and risky_allocation / total_value > 0.3:  ||  # Adjust for risk level diversification  ||  risk_levels = set(pos.risk_level for pos in positions if pos.risk_level)  ||  risk_bonus = min(10, len(risk_levels) * 2)  ||  final_score = min(100, diversification_score + sector_bonus + risk_bonus)  ||  async def _analyze_portfolio_risk(self, positions: List[TokenPosition]) -> Dict[str, Decimal]:  ||  """"""Analyze comprehensive portfolio risk metrics.""""""  ||  ""portfolio_risk_score"": Decimal(""0""),  ||  # Calculate weighted risk score  ||  risk_scores = {  ||  RiskLevel.VERY_LOW: 10,  ||  RiskLevel.LOW: 25,  ||  RiskLevel.MODERATE: 50,  ||  RiskLevel.HIGH: 75,  ||  RiskLevel.VERY_HIGH: 90,  ||  RiskLevel.EXTREME: 100  ||  weighted_risk = sum(  ||  (float(pos.current_value_usd) / float(total_value)) * risk_scores.get(pos.risk_level, 50)  ||  # Calculate Value at Risk (simplified Monte Carlo approach)  ||  ""portfolio_risk_score"": Decimal(str(weighted_risk)),  ||  def _calculate_risk_level_allocations(self, positions: List[TokenPosition]) -> Dict[RiskLevel, Decimal]:  ||  """"""Calculate risk level allocation percentages.""""""  ||  risk_allocations = defaultdict(lambda: Decimal(""0""))  ||  if pos.risk_level:  ||  risk_allocations[pos.risk_level] += Decimal(str(allocation_pct))  ||  return dict(risk_allocations)  ||  PortfolioStrategy.MEME_SPECULATION: ""High-risk meme token speculation strategy"",  ||  def _generate_risk_warnings(  ||  risk_metrics: Dict[str, Decimal]  ||  """"""Generate risk warnings.""""""  ||  # Portfolio risk score warning  ||  risk_score = float(risk_metrics[""portfolio_risk_score""])  ||  if risk_score > 80:  ||  warnings.append(""Very high portfolio risk - consider reducing exposure to volatile assets"")  ||  elif risk_score > 60:  ||  warnings.append(""Elevated portfolio risk - monitor positions closely"")  ||  warnings.append(""High concentration risk - top 5 positions represent >80% of portfolio"")  ||  warnings.append(f""High meme token exposure ({meme_exposure:.1f}%) - extreme volatility risk"")  ||  warnings.append(f""{len(low_liquidity_positions)} positions have low liquidity - exit risk"")  ||  suggestions.append(""Consider increasing diversification across sectors and risk levels"")  ||  # Risk management suggestions  ||  suggestions.append(""High-risk strategy - consider taking profits on winners incrementally"")  ||  wallet_address: str,  ||  wallet_address=wallet_address,  ||  risk_profile_changes=[],  # Would track risk changes  ||  async def analyze_trader_portfolio(  ||  wallet_address: str,  ||  """"""Convenience function to analyze trader portfolio.""""""  ||  return await analyzer.analyze_current_portfolio(wallet_address, dust_threshold)  ||  wallet_addresses: List[str],  ||  tasks = [analyze_single(addr) for addr in wallet_addresses]  ||  logger.info(f""Completed batch portfolio analysis of {len(snapshots)} wallets"")  ||  # Test with sample wallet  ||  test_wallet = ""0x742d35cc6634c0532925a3b8d51d3b4c8e6b3ed3""  ||  snapshot = await analyzer.analyze_current_portfolio(test_wallet)  ||  'wallet_address', 'total_value_usd', 'positions',  ||  'category', 'risk_level'  ||  evolution = await analyzer.track_portfolio_evolution(test_wallet, 30)  ||  logger.info(f""Risk Score: {snapshot.portfolio_risk_score}/100"")"
"D:\dex\backend\app\strategy\position_sizing.py","24770","from __future__ import annotations | import math | from decimal import Decimal, ROUND_DOWN | from typing import Dict, List, Optional, Tuple, Union | from dataclasses import dataclass | from datetime import datetime, timezone, timedelta | from enum import Enum | import logging | from ..strategy.risk_manager import RiskLevel, RiskAssessment | from .base import StrategySignal, StrategyConfig","Position sizing algorithms with Kelly criterion and risk-based calculations.  ||  capital allocation based on strategy confidence, risk assessment,  ||  from ..strategy.risk_manager import RiskLevel, RiskAssessment  ||  RISK_PARITY = ""risk_parity""  ||  DYNAMIC_RISK = ""dynamic_risk""  ||  risk_factor: float  ||  daily_var: Optional[Decimal]  # Value at Risk  ||  total_trades: int  ||  risk parity, volatility adjustment, and confidence weighting.  ||  default_method: PositionSizingMethod = PositionSizingMethod.DYNAMIC_RISK,  ||  risk_assessment: Optional[RiskAssessment] = None,  ||  risk_assessment: Risk assessment for the trade  ||  # Calculate risk and confidence factors  ||  risk_factor = self._calculate_risk_factor(risk_assessment, config.risk_tolerance)  ||  signal, config, max_size, confidence_factor, risk_factor  ||  signal, config, portfolio_metrics, confidence_factor, risk_factor  ||  confidence_factor, risk_factor  ||  elif method == PositionSizingMethod.RISK_PARITY:  ||  result = await self._calculate_risk_parity_size(  ||  signal, config, portfolio_metrics, risk_assessment,  ||  confidence_factor, risk_factor  ||  signal, config, portfolio_metrics, risk_assessment,  ||  confidence_factor, risk_factor  ||  signal, config, portfolio_metrics, confidence_factor, risk_factor  ||  elif method == PositionSizingMethod.DYNAMIC_RISK:  ||  result = await self._calculate_dynamic_risk_size(  ||  signal, config, portfolio_metrics, risk_assessment,  ||  historical_performance, confidence_factor, risk_factor  ||  ""risk_factor"": risk_factor  ||  def _calculate_risk_factor(  ||  risk_assessment: Optional[RiskAssessment],  ||  risk_tolerance: RiskLevel  ||  """"""Calculate risk adjustment factor (0.1 to 1.0).""""""  ||  if not risk_assessment:  ||  return 0.7  # Default moderate risk factor  ||  # Base risk factor from assessment  ||  risk_score = risk_assessment.risk_score  ||  base_factor = max(0.1, 1.0 - (risk_score / 100.0))  ||  # Adjust based on risk tolerance  ||  RiskLevel.VERY_LOW: 1.2,  ||  RiskLevel.LOW: 1.0,  ||  RiskLevel.MEDIUM: 0.9,  ||  RiskLevel.HIGH: 0.7,  ||  RiskLevel.VERY_HIGH: 0.5  ||  tolerance_multiplier = tolerance_multipliers.get(risk_tolerance, 0.8)  ||  risk_factor: float  ||  adjusted_size = base_size * Decimal(str(confidence_factor)) * Decimal(str(risk_factor))  ||  risk_factor=risk_factor,  ||  reasoning=f""Fixed size of ${base_size} adjusted by confidence ({confidence_factor:.2f}) and risk ({risk_factor:.2f})"",  ||  risk_factor: float  ||  adjusted_size = base_size * Decimal(str(confidence_factor)) * Decimal(str(risk_factor))  ||  risk_factor=risk_factor,  ||  reasoning=f""Portfolio percentage ({percentage:.1%}) adjusted by confidence and risk"",  ||  risk_factor: float  ||  if not historical_performance or historical_performance.total_trades < 20:  ||  kelly_fraction *= confidence_factor * risk_factor  ||  risk_factor=risk_factor,  ||  async def _calculate_risk_parity_size(  ||  risk_assessment: Optional[RiskAssessment],  ||  risk_factor: float  ||  """"""Calculate risk parity position size.""""""  ||  # Target risk contribution (e.g., 2% of portfolio value)  ||  target_risk_percent = config.custom_parameters.get(""target_risk_percent"", 2.0)  ||  target_risk_usd = portfolio_metrics.total_portfolio_value * Decimal(str(target_risk_percent / 100))  ||  if risk_assessment and hasattr(risk_assessment, 'volatility_score'):  ||  estimated_volatility = risk_assessment.volatility_score / 100  ||  warnings.append(""Using default volatility estimate for risk parity calculation"")  ||  # Position size = Target Risk / (Volatility * Confidence)  ||  base_size = target_risk_usd / Decimal(str(estimated_volatility))  ||  base_size *= Decimal(str(confidence_factor)) * Decimal(str(risk_factor))  ||  sizing_method=PositionSizingMethod.RISK_PARITY,  ||  risk_factor=risk_factor,  ||  reasoning=f""Risk parity targeting {target_risk_percent}% portfolio risk with {estimated_volatility:.1%} volatility"",  ||  risk_assessment: Optional[RiskAssessment],  ||  risk_factor: float  ||  if risk_assessment and hasattr(risk_assessment, 'volatility_score'):  ||  current_volatility = risk_assessment.volatility_score / 100  ||  adjusted_size *= Decimal(str(confidence_factor)) * Decimal(str(risk_factor))  ||  risk_factor=risk_factor,  ||  risk_factor: float  ||  adjusted_size = base_size * Decimal(str(confidence_scaling)) * Decimal(str(risk_factor))  ||  risk_factor=risk_factor,  ||  async def _calculate_dynamic_risk_size(  ||  risk_assessment: Optional[RiskAssessment],  ||  risk_factor: float  ||  """"""Calculate dynamic risk-adjusted position size (recommended default).""""""  ||  historical_performance.total_trades >= 20 and  ||  confidence_factor, risk_factor  ||  if risk_assessment and hasattr(risk_assessment, 'volatility_score'):  ||  current_volatility = max(0.05, risk_assessment.volatility_score / 100)  ||  # Final risk adjustment  ||  final_size = base_size * Decimal(str(risk_factor))  ||  sizing_method=PositionSizingMethod.DYNAMIC_RISK,  ||  risk_factor=risk_factor,  ||  reasoning=f""Dynamic risk sizing combining Kelly ({kelly_fraction or 'N/A'}), volatility ({volatility_factor:.2f}), and risk adjustments"","
"D:\dex\backend\app\strategy\presets.py","36819","from __future__ import annotations | import uuid | import json | from decimal import Decimal | from typing import Dict, List, Optional, Any, Union | from dataclasses import dataclass, field, asdict | from datetime import datetime, timezone, timedelta | from enum import Enum | import logging | from ..strategy.risk_manager import RiskLevel | from .base import ( | from .position_sizing import PositionSizingMethod","risk-based parameter scaling, and preset performance tracking for  ||  from ..strategy.risk_manager import RiskLevel  ||  RISK_BASED = ""risk_based""  ||  total_trades: int = 0  ||  winning_trades: int = 0  ||  losing_trades: int = 0  ||  risk_adjusted_return: float = 0.0  ||  if self.total_trades > 0:  ||  self.win_rate = (self.winning_trades / self.total_trades) * 100  ||  if self.winning_trades > 0 and self.losing_trades > 0:  ||  float(self.total_profit_loss) / self.winning_trades  ||  # Calculate risk-adjusted return (simplified Sharpe-like ratio)  ||  self.risk_adjusted_return = float(self.total_profit_loss) / float(self.max_drawdown)  ||  risk_score: float = 0.0  ||  # Conservative Preset - Lower risk, smaller positions, tighter stops  ||  max_daily_trades=5,  ||  risk_tolerance=RiskLevel.LOW,  ||  ""max_gas_price_gwei"": 15,  ||  ""risk_multiplier"": 0.5,  ||  max_daily_trades=8,  ||  risk_tolerance=RiskLevel.LOW,  ||  position_sizing_method=PositionSizingMethod.RISK_PARITY.value,  ||  # Standard/Moderate Preset - Balanced risk and reward  ||  max_daily_trades=10,  ||  risk_tolerance=RiskLevel.MEDIUM,  ||  position_sizing_method=PositionSizingMethod.DYNAMIC_RISK.value,  ||  ""max_gas_price_gwei"": 25,  ||  ""risk_multiplier"": 1.0,  ||  max_daily_trades=15,  ||  risk_tolerance=RiskLevel.MEDIUM,  ||  # Aggressive Preset - Higher risk, larger positions, faster execution  ||  max_daily_trades=20,  ||  risk_tolerance=RiskLevel.HIGH,  ||  ""max_gas_price_gwei"": 50,  ||  ""risk_multiplier"": 1.8,  ||  max_daily_trades=25,  ||  risk_tolerance=RiskLevel.HIGH,  ||  max_daily_trades=base_config.max_daily_trades,  ||  risk_tolerance=base_config.risk_tolerance,  ||  risk_score = 0.0  ||  warnings.append(""Large position size may increase risk significantly"")  ||  risk_score += 20  ||  risk_score += 15  ||  # Validate risk tolerance vs position size  ||  if config.risk_tolerance == RiskLevel.LOW and config.max_position_size_usd > Decimal(""100""):  ||  warnings.append(""Large position size inconsistent with low risk tolerance"")  ||  suggestions.append(""Consider reducing position size for low risk tolerance"")  ||  risk_reward_ratio = config.take_profit_percent / config.stop_loss_percent  ||  if risk_reward_ratio < 1.5:  ||  warnings.append(""Risk/reward ratio below 1.5:1 may not be profitable long-term"")  ||  risk_score += 10  ||  # Validate daily trade limits  ||  if config.max_daily_trades > 50:  ||  warnings.append(""High daily trade limit may lead to overtrading"")  ||  risk_score += 10  ||  warnings.append(""Low confidence threshold may result in poor quality trades"")  ||  risk_score += 15  ||  warnings.append(""High tax tolerance may indicate risky tokens"")  ||  risk_score += 20  ||  elif risk_score > 50 or len(warnings) > 5:  ||  expected_performance = self._estimate_preset_performance(config, risk_score)  ||  risk_score=risk_score,  ||  def _estimate_preset_performance(self, config: StrategyConfig, risk_score: float) -> Dict[str, float]:  ||  # Adjust based on risk level  ||  risk_multipliers = {  ||  RiskLevel.VERY_LOW: {""win_rate"": 1.1, ""return"": 0.7, ""drawdown"": 0.6},  ||  RiskLevel.LOW: {""win_rate"": 1.05, ""return"": 0.85, ""drawdown"": 0.8},  ||  RiskLevel.MEDIUM: {""win_rate"": 1.0, ""return"": 1.0, ""drawdown"": 1.0},  ||  RiskLevel.HIGH: {""win_rate"": 0.9, ""return"": 1.3, ""drawdown"": 1.5},  ||  RiskLevel.VERY_HIGH: {""win_rate"": 0.8, ""return"": 1.6, ""drawdown"": 2.0}  ||  multipliers = risk_multipliers.get(config.risk_tolerance, risk_multipliers[RiskLevel.MEDIUM])  ||  # Adjust for risk score  ||  risk_adjustment = max(0.5, 1.0 - (risk_score / 200))  ||  estimated_win_rate = base_win_rate * multipliers[""win_rate""] * risk_adjustment  ||  estimated_drawdown = base_max_drawdown * multipliers[""drawdown""] / risk_adjustment  ||  PositionSizingMethod.RISK_PARITY.value: {""stability"": 1.1, ""drawdown"": 0.9},  ||  PositionSizingMethod.DYNAMIC_RISK.value: {""return"": 1.1, ""stability"": 1.05}  ||  ""risk_score"": round(risk_score, 1),  ||  ""recommended_allocation_percent"": round(max(5, 25 - risk_score / 4), 1)  ||  trade_result: Dict[str, Any]  ||  # Update trade counts  ||  performance.total_trades += 1  ||  profit_loss = Decimal(str(trade_result.get(""profit_loss"", 0)))  ||  performance.winning_trades += 1  ||  performance.losing_trades += 1  ||  hold_time = trade_result.get(""hold_time_minutes"", 0)  ||  weight = 1.0 / performance.total_trades  ||  ""total_trades"": performance.total_trades,  ||  risk_preference: RiskLevel,  ||  # Score based on risk alignment  ||  risk_score = self._calculate_risk_alignment(config.risk_tolerance, risk_preference)  ||  ""score"": risk_score,  ||  ""reason"": f""Built-in {preset_name} preset aligned with your risk preferences""  ||  if preset.performance and preset.performance.total_trades >= 10:  ||  score = preset.performance.win_rate + preset.performance.risk_adjusted_return * 10  ||  def _calculate_risk_alignment(self, config_risk: RiskLevel, user_risk: RiskLevel) -> float:  ||  """"""Calculate alignment score between config risk and user preference.""""""  ||  risk_values = {  ||  RiskLevel.VERY_LOW: 1,  ||  RiskLevel.LOW: 2,  ||  RiskLevel.MEDIUM: 3,  ||  RiskLevel.HIGH: 4,  ||  RiskLevel.VERY_HIGH: 5  ||  config_value = risk_values.get(config_risk, 3)  ||  user_value = risk_values.get(user_risk, 3)  ||  total_trades = sum(p.total_trades for p in self.preset_performance.values())  ||  if total_trades > 0:  ||  p.winning_trades for p in self.preset_performance.values()  ||  ) / total_trades * 100  ||  if perf.total_trades >= 5  ||  ""total_trades"": total_trades,  ||  ""total_trades"": perf.total_trades,"
"D:\dex\backend\app\strategy\risk_manager.py","41908","from __future__ import annotations | import asyncio | import logging | import time | import uuid | from decimal import Decimal | from enum import Enum | from typing import Dict, List, Optional, Any, Set, Tuple | from dataclasses import dataclass | from datetime import datetime, timezone | import logging | from ..core.settings import settings |     from ..chains.evm_client import EVMClient |     from ..chains.solana_client import SolanaClient","Core risk assessment engine for multi-layer token and trade validation.  ||  This module provides comprehensive risk assessment including honeypot detection,  ||  contract security analysis, liquidity validation, and risk scoring with  ||  class RiskLevel(str, Enum):  ||  """"""Risk level classification.""""""  ||  class RiskCategory(str, Enum):  ||  """"""Risk assessment categories.""""""  ||  class RiskFactor:  ||  """"""Individual risk factor assessment.""""""  ||  category: RiskCategory  ||  level: RiskLevel  ||  class RiskAssessment:  ||  """"""Complete risk assessment for a token.""""""  ||  overall_risk: RiskLevel  ||  risk_factors: List[RiskFactor]  ||  tradeable: bool  ||  class RiskManager:  ||  Comprehensive risk management for DEX trading operations.  ||  Evaluates tokens, pairs, and trade parameters against multiple  ||  risk criteria including liquidity, contract security, and market conditions.  ||  """"""Initialize risk manager.""""""  ||  self.risk_thresholds = {  ||  RiskLevel.LOW: 0.25,  ||  RiskLevel.MEDIUM: 0.50,  ||  RiskLevel.HIGH: 0.75,  ||  RiskLevel.CRITICAL: 1.0,  ||  # Risk factor weights for overall score calculation  ||  self.risk_weights = {  ||  RiskCategory.HONEYPOT: 1.0,  ||  RiskCategory.TRADING_DISABLED: 1.0,  ||  RiskCategory.TAX_EXCESSIVE: 0.8,  ||  RiskCategory.OWNER_PRIVILEGES: 0.9,  ||  RiskCategory.BLACKLIST_FUNCTION: 0.9,  ||  RiskCategory.LP_UNLOCKED: 0.8,  ||  RiskCategory.LIQUIDITY_LOW: 0.7,  ||  RiskCategory.DEV_CONCENTRATION: 0.7,  ||  RiskCategory.PROXY_CONTRACT: 0.6,  ||  RiskCategory.CONTRACT_UNVERIFIED: 0.5,  ||  # Critical risk patterns that block trading  ||  async def assess_token_risk(  ||  trade_amount: Optional[Decimal] = None,  ||  ) -> RiskAssessment:  ||  Perform comprehensive risk assessment for a token.  ||  trade_amount: Planned trade amount (optional)  ||  Comprehensive risk assessment  ||  f""Starting risk assessment for {token_address} on {chain}"",  ||  ""module"": ""risk_manager"",  ||  ""trade_amount"": str(trade_amount) if trade_amount else None  ||  # Initialize risk factors list  ||  risk_factors: List[RiskFactor] = []  ||  # Run all risk checks concurrently  ||  risk_tasks = [  ||  self._check_honeypot_risk(token_address, chain, chain_clients),  ||  self._check_tax_risk(token_address, chain, chain_clients),  ||  self._check_liquidity_risk(token_address, chain, chain_clients, trade_amount),  ||  # Execute all risk checks  ||  risk_results = await asyncio.gather(*risk_tasks, return_exceptions=True)  ||  # Process results and collect valid risk factors  ||  for i, result in enumerate(risk_results):  ||  if isinstance(result, RiskFactor):  ||  risk_factors.append(result)  ||  f""Risk check {i} failed: {result}"",  ||  ""module"": ""risk_manager"",  ||  # Calculate overall risk score and level  ||  overall_score = self._calculate_overall_score(risk_factors)  ||  overall_risk = self._determine_risk_level(overall_score)  ||  # Determine if token is tradeable  ||  tradeable = self._is_tradeable(risk_factors, overall_risk)  ||  warnings = self._generate_warnings(risk_factors)  ||  recommendations = self._generate_recommendations(risk_factors, overall_risk)  ||  assessment = RiskAssessment(  ||  overall_risk=overall_risk,  ||  risk_factors=risk_factors,  ||  tradeable=tradeable,  ||  f""Risk assessment completed: {overall_risk.value} (score: {overall_score:.3f})"",  ||  ""module"": ""risk_manager"",  ||  ""overall_risk"": overall_risk.value,  ||  ""tradeable"": tradeable,  ||  ""risk_factors_count"": len(risk_factors)  ||  f""Risk assessment failed: {e}"",  ||  ""module"": ""risk_manager"",  ||  async def _check_honeypot_risk(  ||  ) -> RiskFactor:  ||  Risk factor for honeypot assessment  ||  risk_score = 0.0  ||  risk_score = 0.9  ||  if risk_score > 0.8:  ||  level = RiskLevel.CRITICAL  ||  elif risk_score > 0.5:  ||  level = RiskLevel.HIGH  ||  description = ""Moderate honeypot risk detected""  ||  elif risk_score > 0.2:  ||  level = RiskLevel.MEDIUM  ||  description = ""Low honeypot risk detected""  ||  level = RiskLevel.LOW  ||  return RiskFactor(  ||  category=RiskCategory.HONEYPOT,  ||  score=risk_score,  ||  return RiskFactor(  ||  category=RiskCategory.HONEYPOT,  ||  level=RiskLevel.MEDIUM,  ||  description=""Unable to assess honeypot risk"",  ||  async def _check_tax_risk(  ||  ) -> RiskFactor:  ||  risk_score = 0.0  ||  if risk_score > 0.15:  # >15% tax is excessive  ||  level = RiskLevel.HIGH  ||  description = f""Excessive trading tax detected: {risk_score*100:.1f}%""  ||  elif risk_score > 0.10:  # >10% tax is concerning  ||  level = RiskLevel.MEDIUM  ||  description = f""High trading tax: {risk_score*100:.1f}%""  ||  elif risk_score > 0.05:  # >5% tax is noteworthy  ||  level = RiskLevel.LOW  ||  description = f""Moderate trading tax: {risk_score*100:.1f}%""  ||  level = RiskLevel.LOW  ||  return RiskFactor(  ||  category=RiskCategory.TAX_EXCESSIVE,  ||  score=risk_score,  ||  return RiskFactor(  ||  category=RiskCategory.TAX_EXCESSIVE,  ||  level=RiskLevel.MEDIUM,  ||  description=""Unable to assess tax risk"",  ||  async def _check_liquidity_risk(  ||  trade_amount: Optional[Decimal] = None  ||  ) -> RiskFactor:  ||  if trade_amount:  ||  liquidity_ratio = estimated_liquidity / trade_amount  ||  # Calculate risk based on liquidity adequacy  ||  risk_score = 0.8  ||  level = RiskLevel.HIGH  ||  elif liquidity_ratio < 5:  # Trade size > 20% of liquidity  ||  risk_score = 0.6  ||  level = RiskLevel.MEDIUM  ||  description = f""Trade size may impact price significantly""  ||  elif liquidity_ratio < 10:  # Trade size > 10% of liquidity  ||  risk_score = 0.3  ||  level = RiskLevel.LOW  ||  description = f""Moderate liquidity for trade size""  ||  risk_score = 0.1  ||  level = RiskLevel.LOW  ||  return RiskFactor(  ||  category=RiskCategory.LIQUIDITY_LOW,  ||  score=risk_score,  ||  ""liquidity_ratio"": str(liquidity_ratio) if trade_amount else None  ||  return RiskFactor(  ||  category=RiskCategory.LIQUIDITY_LOW,  ||  level=RiskLevel.MEDIUM,  ||  description=""Unable to assess liquidity risk"",  ||  ) -> RiskFactor:  ||  risk_score = 0.0  ||  risk_score = 0.9  ||  level = RiskLevel.CRITICAL  ||  risk_score = 0.7  ||  level = RiskLevel.HIGH  ||  risk_score = 0.4  ||  level = RiskLevel.MEDIUM  ||  risk_score = 0.1  ||  level = RiskLevel.LOW  ||  return RiskFactor(  ||  category=RiskCategory.OWNER_PRIVILEGES,  ||  score=risk_score,  ||  return RiskFactor(  ||  category=RiskCategory.OWNER_PRIVILEGES,  ||  level=RiskLevel.MEDIUM,  ||  ) -> RiskFactor:  ||  risk_score = 0.7  ||  level = RiskLevel.HIGH  ||  risk_score = 0.4  ||  level = RiskLevel.MEDIUM  ||  risk_score = 0.1  ||  level = RiskLevel.LOW  ||  return RiskFactor(  ||  category=RiskCategory.PROXY_CONTRACT,  ||  score=risk_score,  ||  return RiskFactor(  ||  category=RiskCategory.PROXY_CONTRACT,  ||  level=RiskLevel.LOW,  ||  ) -> RiskFactor:  ||  risk_score = 0.8  ||  level = RiskLevel.HIGH  ||  risk_score = 0.6  ||  level = RiskLevel.MEDIUM  ||  risk_score = 0.3  ||  level = RiskLevel.LOW  ||  risk_score = 0.1  ||  level = RiskLevel.LOW  ||  return RiskFactor(  ||  category=RiskCategory.LP_UNLOCKED,  ||  score=risk_score,  ||  return RiskFactor(  ||  category=RiskCategory.LP_UNLOCKED,  ||  level=RiskLevel.MEDIUM,  ||  ) -> RiskFactor:  ||  risk_score = 0.6  ||  level = RiskLevel.MEDIUM  ||  risk_score = 0.1  ||  level = RiskLevel.LOW  ||  return RiskFactor(  ||  category=RiskCategory.CONTRACT_UNVERIFIED,  ||  score=risk_score,  ||  return RiskFactor(  ||  category=RiskCategory.CONTRACT_UNVERIFIED,  ||  level=RiskLevel.MEDIUM,  ||  ) -> RiskFactor:  ||  risk_score = 1.0  ||  level = RiskLevel.CRITICAL  ||  risk_score = 0.0  ||  level = RiskLevel.LOW  ||  return RiskFactor(  ||  category=RiskCategory.TRADING_DISABLED,  ||  score=risk_score,  ||  return RiskFactor(  ||  category=RiskCategory.TRADING_DISABLED,  ||  level=RiskLevel.MEDIUM,  ||  ) -> RiskFactor:  ||  risk_score = 0.9  ||  level = RiskLevel.HIGH  ||  risk_score = 0.1  ||  level = RiskLevel.LOW  ||  return RiskFactor(  ||  category=RiskCategory.BLACKLIST_FUNCTION,  ||  score=risk_score,  ||  return RiskFactor(  ||  category=RiskCategory.BLACKLIST_FUNCTION,  ||  level=RiskLevel.MEDIUM,  ||  ) -> RiskFactor:  ||  risk_score = 0.8  ||  level = RiskLevel.HIGH  ||  risk_score = 0.5  ||  level = RiskLevel.MEDIUM  ||  risk_score = 0.3  ||  level = RiskLevel.LOW  ||  risk_score = 0.1  ||  level = RiskLevel.LOW  ||  return RiskFactor(  ||  category=RiskCategory.DEV_CONCENTRATION,  ||  score=risk_score,  ||  return RiskFactor(  ||  category=RiskCategory.DEV_CONCENTRATION,  ||  level=RiskLevel.MEDIUM,  ||  def _calculate_overall_score(self, risk_factors: List[RiskFactor]) -> float:  ||  Calculate weighted overall risk score.  ||  risk_factors: List of individual risk factors  ||  Overall risk score (0.0 - 1.0)  ||  if not risk_factors:  ||  for factor in risk_factors:  ||  weight = self.risk_weights.get(factor.category, 0.5)  ||  def _determine_risk_level(self, overall_score: float) -> RiskLevel:  ||  Determine risk level from overall score.  ||  overall_score: Overall risk score  ||  Corresponding risk level  ||  if overall_score >= self.risk_thresholds[RiskLevel.CRITICAL]:  ||  return RiskLevel.CRITICAL  ||  elif overall_score >= self.risk_thresholds[RiskLevel.HIGH]:  ||  return RiskLevel.HIGH  ||  elif overall_score >= self.risk_thresholds[RiskLevel.MEDIUM]:  ||  return RiskLevel.MEDIUM  ||  return RiskLevel.LOW  ||  def _is_tradeable(self, risk_factors: List[RiskFactor], overall_risk: RiskLevel) -> bool:  ||  Determine if token is safe to trade.  ||  risk_factors: List of risk factors  ||  overall_risk: Overall risk level  ||  True if token can be traded safely  ||  for factor in risk_factors:  ||  if factor.category in [RiskCategory.HONEYPOT, RiskCategory.TRADING_DISABLED]:  ||  if factor.level in [RiskLevel.CRITICAL, RiskLevel.HIGH]:  ||  # Block if overall risk is critical  ||  if overall_risk == RiskLevel.CRITICAL:  ||  def _generate_warnings(self, risk_factors: List[RiskFactor]) -> List[str]:  ||  for factor in risk_factors:  ||  if factor.level in [RiskLevel.HIGH, RiskLevel.CRITICAL]:  ||  async def assess_pair_risk(  ||  ) -> RiskAssessment:  ||  Assess risk for a trading pair.  ||  Risk assessment for the pair  ||  # Perform risk assessment on the target token  ||  return await self.assess_token_risk(  ||  trade_amount=liquidity_usd / 10 if liquidity_usd else None  ||  async def quick_risk_check(  ||  Perform quick risk check without full assessment.  ||  Quick risk check results  ||  risk_level = ""medium""  ||  quick_summary = ""Standard risk profile""  ||  risk_level = ""critical""  ||  risk_level = ""critical""  ||  risk_level = ""high""  ||  # Default to moderate risk for unknown tokens  ||  risk_level = ""medium""  ||  quick_summary = ""Unknown token - moderate risk""  ||  ""risk_level"": risk_level,  ||  logger.error(f""Quick risk check failed: {e}"")  ||  ""risk_level"": ""unknown"",  ||  ""quick_summary"": f""Risk check failed: {str(e)}"",  ||  risk_factors: List[RiskFactor],  ||  overall_risk: RiskLevel  ||  if overall_risk == RiskLevel.CRITICAL:  ||  recommendations.append(""⛔ DO NOT TRADE - Critical risks detected"")  ||  elif overall_risk == RiskLevel.HIGH:  ||  recommendations.append(""⚠️ Trade with extreme caution and small amounts only"")  ||  elif overall_risk == RiskLevel.MEDIUM:  ||  recommendations.append(""✅ Acceptable risk profile for trading"")  ||  # Add specific recommendations based on risk factors  ||  for factor in risk_factors:  ||  if factor.category == RiskCategory.LIQUIDITY_LOW and factor.level >= RiskLevel.MEDIUM:  ||  recommendations.append(""💧 Consider smaller trade sizes due to low liquidity"")  ||  elif factor.category == RiskCategory.TAX_EXCESSIVE and factor.level >= RiskLevel.MEDIUM:  ||  elif factor.category == RiskCategory.LP_UNLOCKED and factor.level >= RiskLevel.MEDIUM:  ||  def get_risk_categories(self) -> Dict[str, Dict[str, Any]]:  ||  Get all supported risk categories with descriptions.  ||  Dictionary of risk categories and their metadata  ||  # Global risk manager instance  ||  risk_manager = RiskManager()"
"D:\dex\backend\app\strategy\risk_scoring.py","35928","from __future__ import annotations | import logging | from decimal import Decimal | from typing import Dict, List, Optional, Tuple | from datetime import datetime, timedelta | from dataclasses import dataclass, field | from app.core.logging import get_logger","Risk scoring system for DEX Sniper Pro.  ||  Provides numerical risk assessment (0-100) based on multiple factors  ||  class RiskFactors:  ||  """"""Container for all risk assessment factors.""""""  ||  max_wallet_percent: Decimal = Decimal(""100"")  ||  trades_24h: int = 0  ||  unique_traders_24h: int = 0  ||  class RiskScore:  ||  """"""Risk assessment result with detailed breakdown.""""""  ||  total_score: int  # 0-100, higher = riskier  ||  risk_level: str  # ""low"", ""medium"", ""high"", ""critical""  ||  factors: Optional[RiskFactors] = None  ||  risk_reasons: List[str] = field(default_factory=list)  ||  recommendation: str = ""avoid""  # ""avoid"", ""monitor"", ""consider"", ""trade""  ||  class RiskScorer:  ||  Core risk scoring engine for token assessment.  ||  Analyzes multiple factors to produce a comprehensive risk score  ||  # Risk thresholds  ||  ""min_trades_24h"": 100,  ||  ""min_unique_traders"": 30  ||  Initialize risk scorer.  ||  self.trace_id = trace_id or f""risk_{datetime.utcnow().isoformat()}""  ||  async def calculate_risk_score(  ||  factors: RiskFactors,  ||  ) -> RiskScore:  ||  Calculate comprehensive risk score from factors.  ||  factors: Risk factors to analyze  ||  RiskScore: Complete risk assessment  ||  ""Calculating risk score"",  ||  # Honeypot override - always maximum risk  ||  # Determine risk level  ||  risk_level = self._get_risk_level(total_score)  ||  # Generate risk reasons and positive signals  ||  risk_reasons = self._generate_risk_reasons(  ||  risk_score = RiskScore(  ||  risk_level=risk_level,  ||  risk_reasons=risk_reasons,  ||  ""Risk score calculated"",  ||  ""risk_level"": risk_level,  ||  return risk_score  ||  f""Failed to calculate risk score: {e}"",  ||  # Return maximum risk score on error  ||  return RiskScore(  ||  risk_level=""critical"",  ||  risk_reasons=[f""Risk calculation failed: {str(e)}""]  ||  def _score_liquidity(self, factors: RiskFactors, strict: bool) -> int:  ||  Score liquidity risk (0-100, higher = riskier).  ||  factors: Risk factors  ||  int: Liquidity risk score  ||  return 100  # Maximum risk  ||  def _score_distribution(self, factors: RiskFactors, strict: bool) -> int:  ||  Score holder distribution risk (0-100, higher = riskier).  ||  factors: Risk factors  ||  int: Distribution risk score  ||  def _score_age(self, factors: RiskFactors, strict: bool) -> int:  ||  Score contract age risk (0-100, higher = riskier).  ||  factors: Risk factors  ||  int: Age risk score  ||  # Replace the _generate_risk_reasons method (around line 615)  ||  def _generate_risk_reasons(  ||  factors: RiskFactors,  ||  Generate human-readable risk reasons.  ||  factors: Risk factors  ||  List[str]: Risk reasons  ||  def _score_volume(self, factors: RiskFactors, strict: bool) -> int:  ||  Score volume patterns risk (0-100, higher = riskier).  ||  factors: Risk factors  ||  int: Volume risk score  ||  if factors.trades_24h < self.THRESHOLDS[""min_trades_24h""]:  ||  if factors.unique_traders_24h < self.THRESHOLDS[""min_unique_traders""]:  ||  def _score_volatility(self, factors: RiskFactors, strict: bool) -> int:  ||  Score price volatility risk (0-100, higher = riskier).  ||  factors: Risk factors  ||  int: Volatility risk score  ||  def _score_security(self, factors: RiskFactors, strict: bool) -> int:  ||  Score security factors risk (0-100, higher = riskier).  ||  factors: Risk factors  ||  int: Security risk score  ||  # Honeypot is critical risk  ||  # Check max wallet restriction  ||  if factors.max_wallet_percent < 1:  ||  elif factors.max_wallet_percent < 3:  ||  def _get_risk_level(self, score: int) -> str:  ||  Convert numerical score to risk level.  ||  score: Risk score (0-100)  ||  str: Risk level category  ||  def _calculate_confidence(self, factors: RiskFactors) -> float:  ||  Calculate confidence in risk assessment based on data completeness.  ||  factors: Risk factors  ||  if factors.trades_24h > 0:  ||  def _generate_risk_reasons(  ||  factors: RiskFactors,  ||  Generate human-readable risk reasons.  ||  factors: Risk factors  ||  List[str]: Risk reasons  ||  factors: RiskFactors,  ||  factors: Risk factors  ||  Generate trading recommendation based on risk score.  ||  score: Total risk score  ||  return ""trade""  ||  return ""trade""  ||  def _calculate_position_size(self, score: int, factors: RiskFactors) -> Decimal:  ||  score: Total risk score  ||  factors: Risk factors  ||  return Decimal(""0"")  # Don't trade  ||  # Base position from risk score  ||  base_position = Decimal(""1"")  # 1% for high risk  ||  base_position = Decimal(""3"")  # 3% for medium risk  ||  base_position = Decimal(""5"")  # 5% for low risk  ||  # Additional safety check for poor metrics  ||  volatility_score: Volatility risk score  ||  liquidity_score: Liquidity risk score  ||  async def quick_risk_assessment(  ||  ) -> RiskScore:  ||  Quick risk assessment with minimal data.  ||  RiskScore: Basic risk assessment  ||  factors = RiskFactors(  ||  scorer = RiskScorer(trace_id=trace_id)  ||  return await scorer.calculate_risk_score(factors, strict_mode=False)"
"D:\dex\backend\app\strategy\safety_controls.py","35269","from __future__ import annotations | import asyncio | import time | import uuid | from decimal import Decimal | from typing import Dict, List, Optional, Any, Set, Tuple | from dataclasses import dataclass, field | from datetime import datetime, timezone, timedelta | from enum import Enum | import logging | from ..core.settings import settings | from ..strategy.risk_manager import risk_manager, RiskLevel, RiskAssessment | from ..storage.models import SafetyEvent, BlacklistedToken | from ..storage.repositories import SafetyRepository","Comprehensive safety controls and circuit breakers for automated trading.  ||  cooldown management, and circuit breakers to protect against trading risks  ||  from ..strategy.risk_manager import risk_manager, RiskLevel, RiskAssessment  ||  from ..storage.models import SafetyEvent, BlacklistedToken  ||  from ..storage.repositories import SafetyRepository  ||  class SafetyLevel(str, Enum):  ||  """"""Safety control levels.""""""  ||  PERMISSIVE = ""permissive""      # Minimal safety checks  ||  STANDARD = ""standard""          # Balanced safety and performance  ||  CONSERVATIVE = ""conservative""  # Maximum safety, slower execution  ||  HIGH_RISK_TOKENS = ""high_risk_tokens""  ||  gas_used: Optional[int] = None  ||  risk_score: Optional[float] = None  ||  per_trade_usd: Decimal  ||  class SafetyControls:  ||  Comprehensive safety control system for automated trading.  ||  def __init__(self, safety_repository: Optional[SafetyRepository] = None):  ||  """"""Initialize safety controls.""""""  ||  self.safety_repo = safety_repository or SafetyRepository()  ||  # Current safety level  ||  self.safety_level = SafetyLevel.STANDARD  ||  per_trade_usd=Decimal(""1000""),  ||  per_trade_usd=Decimal(""500""),  ||  per_trade_usd=Decimal(""250""),  ||  per_trade_usd=Decimal(""300""),  ||  per_trade_usd=Decimal(""500""),  ||  per_trade_usd=Decimal(""200""),  ||  CircuitBreakerType.HIGH_RISK_TOKENS: CircuitBreaker(  ||  breaker_type=CircuitBreakerType.HIGH_RISK_TOKENS,  ||  threshold=3,  # 3 high-risk tokens in window  ||  threshold=10,  # 10 trades in window  ||  self.recent_trades: List[Dict[str, Any]] = []  ||  self.safety_checks_performed = 0  ||  self.trades_blocked = 0  ||  self.canaries_executed = 0  ||  async def check_trade_safety(  ||  trade_amount_usd: Decimal,  ||  risk_assessment: Optional[RiskAssessment] = None  ||  Comprehensive safety check for a proposed trade.  ||  trade_amount_usd: Trade amount in USD  ||  risk_assessment: Pre-computed risk assessment (optional)  ||  self.safety_checks_performed += 1  ||  f""Starting safety check for {token_address} on {chain}"",  ||  ""module"": ""safety_controls"",  ||  ""trade_amount_usd"": str(trade_amount_usd),  ||  ""safety_level"": self.safety_level.value  ||  spend_violations = await self._check_spend_limits(chain, trade_amount_usd)  ||  # 6. Risk assessment check  ||  if not risk_assessment:  ||  risk_assessment = await risk_manager.assess_token_risk(  ||  trade_amount=trade_amount_usd  ||  risk_violations = await self._check_risk_thresholds(risk_assessment)  ||  if risk_violations:  ||  blocking_reasons.extend(risk_violations)  ||  # 7. Safety level specific checks  ||  safety_violations = await self._check_safety_level_requirements(  ||  token_address, chain, trade_amount_usd, risk_assessment  ||  if safety_violations:  ||  blocking_reasons.extend(safety_violations)  ||  self.trades_blocked += 1  ||  # Log safety violation  ||  await self._log_safety_event(  ||  event_type=""trade_blocked"",  ||  trade_amount_usd=trade_amount_usd,  ||  f""Safety check completed: {'PASSED' if is_safe else 'BLOCKED'}"",  ||  ""module"": ""safety_controls"",  ||  f""Safety check failed: {e}"",  ||  ""module"": ""safety_controls"",  ||  # Fail safe - block trade on error  ||  return False, [f""Safety check error: {str(e)}""]  ||  async def execute_canary_test(  ||  Execute graduated canary testing for a token.  ||  self.canaries_executed += 1  ||  ""module"": ""safety_controls"",  ||  # 1. Pre-flight risk assessment  ||  risk_assessment = await risk_manager.assess_token_risk(  ||  trade_amount=size_usd  ||  result.risk_score = risk_assessment.overall_score  ||  # Skip canary if risk is too high  ||  if risk_assessment.overall_risk in [RiskLevel.CRITICAL, RiskLevel.HIGH]:  ||  result.failure_reason = f""Risk too high: {risk_assessment.overall_risk.value}""  ||  # Auto-blacklist critical risk tokens  ||  if risk_assessment.overall_risk == RiskLevel.CRITICAL:  ||  f""Critical risk score: {risk_assessment.overall_score:.1f}""  ||  # 2. Execute micro buy  ||  buy_result = await self._execute_canary_buy(  ||  result.gas_used = buy_result.get(""gas_used"", 0)  ||  sell_result = await self._execute_canary_sell(  ||  ""module"": ""safety_controls"",  ||  ""module"": ""safety_controls"",  ||  await self.safety_repo.add_blacklisted_token(  ||  await self._log_safety_event(  ||  ""module"": ""safety_controls"",  ||  await self._log_safety_event(  ||  ""module"": ""safety_controls"",  ||  async def set_safety_level(self, level: SafetyLevel) -> None:  ||  Change current safety level.  ||  level: New safety level to set  ||  old_level = self.safety_level  ||  self.safety_level = level  ||  await self._log_safety_event(  ||  event_type=""safety_level_changed"",  ||  f""Safety level changed: {old_level.value} → {level.value}"",  ||  ""module"": ""safety_controls"",  ||  await self._log_safety_event(  ||  ""module"": ""safety_controls"",  ||  async def get_safety_status(self) -> Dict[str, Any]:  ||  Get comprehensive safety system status.  ||  Dictionary with safety system status and metrics  ||  ""safety_level"": self.safety_level.value,  ||  ""per_trade_usd"": str(limits.per_trade_usd),  ||  ""safety_checks_performed"": self.safety_checks_performed,  ||  ""trades_blocked"": self.trades_blocked,  ||  ""canaries_executed"": self.canaries_executed,  ||  blacklisted = await self.safety_repo.get_active_blacklisted_tokens()  ||  """"""Check spend limits for a trade.""""""  ||  # Check per-trade limit  ||  if amount_usd > limits.per_trade_usd:  ||  violations.append(f""Exceeds per-trade limit: ${amount_usd} > ${limits.per_trade_usd}"")  ||  async def _check_risk_thresholds(self, risk_assessment: RiskAssessment) -> List[str]:  ||  """"""Check risk assessment against safety thresholds.""""""  ||  # Safety level specific risk thresholds  ||  risk_thresholds = {  ||  SafetyLevel.PERMISSIVE: {""max_score"": 0.8, ""max_level"": RiskLevel.CRITICAL},  ||  SafetyLevel.STANDARD: {""max_score"": 0.6, ""max_level"": RiskLevel.HIGH},  ||  SafetyLevel.CONSERVATIVE: {""max_score"": 0.4, ""max_level"": RiskLevel.MEDIUM},  ||  SafetyLevel.EMERGENCY: {""max_score"": 0.0, ""max_level"": None}  ||  threshold = risk_thresholds[self.safety_level]  ||  if risk_assessment.overall_score > threshold[""max_score""]:  ||  violations.append(f""Risk score too high: {risk_assessment.overall_score:.2f} > {threshold['max_score']}"")  ||  if threshold[""max_level""] and risk_assessment.overall_risk.value not in [level.value for level in [RiskLevel.LOW, RiskLevel.MEDIUM, RiskLevel.HIGH] if level.value <= threshold[""max_level""].value]:  ||  violations.append(f""Risk level too high: {risk_assessment.overall_risk.value}"")  ||  async def _check_safety_level_requirements(  ||  trade_amount_usd: Decimal,  ||  risk_assessment: RiskAssessment  ||  """"""Check safety level specific requirements.""""""  ||  if self.safety_level == SafetyLevel.EMERGENCY:  ||  elif self.safety_level == SafetyLevel.CONSERVATIVE:  ||  async def _execute_canary_buy(  ||  """"""Execute canary buy operation.""""""  ||  ""gas_used"": 150000  ||  async def _execute_canary_sell(  ||  """"""Execute canary sell operation.""""""  ||  async def _log_safety_event(  ||  trade_amount_usd: Optional[Decimal] = None,  ||  """"""Log safety event to database and logs.""""""  ||  await self.safety_repo.log_safety_event(  ||  logger.error(f""Failed to log safety event: {e}"")  ||  # Global safety controls instance  ||  safety_controls = SafetyControls()"
"D:\dex\backend\app\strategy\stop_orders.py","18512","from __future__ import annotations | import logging | from datetime import datetime, timedelta | from decimal import Decimal | from typing import Dict, Optional | from pydantic import Field | from backend.app.strategy.orders.base import (","Advanced stop orders with dynamic adjustment and risk management.  ||  # Risk management  ||  ""order_type"": ""market"",  # Stop-loss executes as market order  ||  ""max_gas_price"": self.max_gas_price,  ||  # Risk management  ||  ""order_type"": ""market"",  # Take-profit executes as market order  ||  ""max_gas_price"": self.max_gas_price,  ||  Quantity to execute  ||  ""max_gas_price"": self.max_gas_price  ||  Provides comprehensive risk management for a complete trade setup.  ||  ""max_gas_price"": self.max_gas_price  ||  ""max_gas_price"": self.max_gas_price  ||  max_gas_price=self.max_gas_price,  ||  max_gas_price=self.max_gas_price,"
"D:\dex\backend\app\strategy\strategies.py","33515","from __future__ import annotations | import asyncio | import time | import uuid | from abc import ABC, abstractmethod | from decimal import Decimal | from typing import Dict, List, Optional, Any, Type, Callable | from dataclasses import dataclass, field | from datetime import datetime, timezone, timedelta | from enum import Enum | import logging | from ..core.settings import settings | from ..strategy.risk_manager import risk_manager, RiskAssessment, RiskLevel | from ..strategy.safety_controls import safety_controls, CanaryResult | from ..trading.canary import enhanced_canary_tester, CanaryStrategy | from ..discovery.chain_watchers import PairCreatedEvent | from ..ws.discovery_hub import broadcast_trading_opportunity","from ..strategy.risk_manager import risk_manager, RiskAssessment, RiskLevel  ||  from ..strategy.safety_controls import safety_controls, CanaryResult  ||  max_daily_trades: int = 10  ||  risk_tolerance: RiskLevel = RiskLevel.MEDIUM  ||  trades_executed: List[Dict[str, Any]] = field(default_factory=list)  ||  revert_executed: bool = field(default=False)  ||  risk management, position sizing, and execution tracking.  ||  ""successful_trades"": 0,  ||  ""failed_trades"": 0,  ||  async def execute_strategy(  ||  Execute trading strategy based on signal.  ||  signal: Trading signal to execute  ||  # 1. Safety check  ||  if not await self._safety_check(signal, chain_clients):  ||  execution.failure_reason = ""Failed safety checks""  ||  # 2. Risk assessment  ||  risk_assessment = await self._assess_risk(signal, chain_clients)  ||  if not self._is_risk_acceptable(risk_assessment):  ||  execution.failure_reason = f""Risk too high: {risk_assessment.overall_risk.value}""  ||  position_size = await self._calculate_position_size(signal, risk_assessment)  ||  # 4. Execute trades  ||  await self._execute_trades(execution, position_size, chain_clients)  ||  ""trades_executed"": len(execution.trades_executed),  ||  async def _safety_check(  ||  """"""Perform comprehensive safety checks.""""""  ||  is_safe, blocking_reasons = await safety_controls.check_trade_safety(  ||  trade_amount_usd=signal.recommended_size_usd  ||  f""Safety check failed: {', '.join(blocking_reasons)}"",  ||  logger.error(f""Safety check error: {e}"")  ||  async def _assess_risk(  ||  ) -> RiskAssessment:  ||  """"""Assess risk for the trading signal.""""""  ||  return await risk_manager.assess_token_risk(  ||  trade_amount=signal.recommended_size_usd  ||  def _is_risk_acceptable(self, risk_assessment: RiskAssessment) -> bool:  ||  """"""Check if risk level is acceptable for strategy.""""""  ||  RiskLevel.LOW: [RiskLevel.LOW, RiskLevel.MEDIUM, RiskLevel.HIGH],  ||  RiskLevel.MEDIUM: [RiskLevel.LOW, RiskLevel.MEDIUM],  ||  RiskLevel.HIGH: [RiskLevel.LOW]  ||  return risk_assessment.overall_risk in acceptable_levels.get(  ||  self.config.risk_tolerance, [RiskLevel.LOW]  ||  risk_assessment: RiskAssessment  ||  # Apply risk-based scaling  ||  risk_multiplier = {  ||  RiskLevel.LOW: Decimal(""1.0""),  ||  RiskLevel.MEDIUM: Decimal(""0.7""),  ||  RiskLevel.HIGH: Decimal(""0.4""),  ||  RiskLevel.CRITICAL: Decimal(""0.1"")  ||  }.get(risk_assessment.overall_risk, Decimal(""0.1""))  ||  position_size = base_size * risk_multiplier * confidence_multiplier  ||  async def _execute_trades(  ||  """"""Execute the actual trades for the strategy.""""""  ||  # This would integrate with the trade executor  ||  # For now, simulate trade execution  ||  trade_result = {  ||  ""trade_id"": str(uuid.uuid4()),  ||  ""gas_used"": 150000,  ||  execution.trades_executed.append(trade_result)  ||  trade_result = {  ||  ""trade_id"": str(uuid.uuid4()),  ||  ""gas_used"": 120000,  ||  execution.trades_executed.append(trade_result)  ||  if not execution.trades_executed:  ||  self.performance_stats[""successful_trades""] += 1  ||  self.performance_stats[""failed_trades""] += 1  ||  total_trades = (  ||  self.performance_stats[""successful_trades""] +  ||  self.performance_stats[""failed_trades""]  ||  if total_trades > 0:  ||  self.performance_stats[""successful_trades""] / total_trades * 100  ||  # Check if canary test is required and execute it  ||  canary_result = await enhanced_canary_tester.execute_canary_test(  ||  re-entry on established trends with proper risk management.  ||  ""risk_tolerance"": RiskLevel.LOW,  ||  ""risk_tolerance"": RiskLevel.MEDIUM,  ||  ""risk_tolerance"": RiskLevel.HIGH,  ||  async def execute_signal(  ||  """"""Execute a trading signal through appropriate strategy.""""""  ||  # Execute strategy  ||  execution = await strategy.execute_strategy(signal, chain_clients)"
"D:\dex\backend\app\strategy\timing.py","35148","from __future__ import annotations | import asyncio | import math | from decimal import Decimal | from typing import Dict, List, Optional, Tuple, Union, Any | from dataclasses import dataclass, field | from datetime import datetime, timezone, timedelta | from enum import Enum | import statistics | import logging | from ..strategy.risk_manager import RiskAssessment | from .base import StrategySignal, TriggerCondition, SignalType","Entry/exit timing logic with technical indicators for optimal trade execution.  ||  from ..strategy.risk_manager import RiskAssessment  ||  to determine optimal timing for trade execution.  ||  risk_assessment: Optional[RiskAssessment] = None,  ||  risk_assessment: Optional risk assessment  ||  signal, current_price, technical_analysis, risk_assessment  ||  risk_assessment: Optional[RiskAssessment]  ||  # Calculate stop loss based on risk assessment  ||  if risk_assessment:  ||  # Higher risk = tighter stops  ||  risk_multiplier = Decimal(str(risk_assessment.risk_score / 100))  ||  stop_percent = base_stop_percent * (Decimal(""1"") + risk_multiplier)"
"D:\dex\backend\app\trading\overflow\private_submit.py","25246","from __future__ import annotations | import asyncio | import json | import logging | import time | from dataclasses import dataclass, field | from datetime import datetime, timedelta | from decimal import Decimal | from enum import Enum | from typing import Any, Dict, List, Optional, Tuple, Union | from urllib.parse import urljoin | import httpx | from eth_account import Account | from eth_account.signers.local import LocalAccount | from pydantic import BaseModel | from ...core.settings import get_settings | from ...chains.evm_client import EVMClient | from ...monitoring.alerts import create_system_alert |             import random","total_gas_used: int = 0"
"D:\dex\backend\app\trading\approvals.py","21331","from __future__ import annotations | import asyncio | import logging | import time | from datetime import datetime, timedelta, timezone | from decimal import Decimal | from typing import Dict, List, Optional, Tuple | from eth_account import Account | from eth_account.signers.local import LocalAccount | from web3 import Web3 | from ..chains.evm_client import evm_client | import logging | from ..core.settings import settings | from ..services.token_metadata import token_metadata_service | from ..storage.repositories import TransactionRepository, get_transaction_repository |             from ..chains.rpc_pool import rpc_pool |             from ..core.wallet_registry import wallet_registry","Approval manager with Permit2 support, limited approvals, and scheduled revocation.  ||  class ApprovalError(Exception):  ||  """"""Raised when approval operations fail.""""""  ||  class ApprovalManager:  ||  Manages token approvals with Permit2 support and automatic revocation.  ||  Provides secure approval management with limited amounts, time-based  ||  """"""Initialize approval manager.""""""  ||  # Active approvals tracking  ||  self._active_approvals: Dict[str, Dict] = {}  ||  self._approval_locks: Dict[str, asyncio.Lock] = {}  ||  # Default approval settings  ||  self.default_approval_duration = 3600  # 1 hour  ||  self.max_approval_amount = Web3.to_wei(1000000, 'ether')  # 1M tokens max  ||  logger.info(""Approval manager initialized"")  ||  async def ensure_approval(  ||  wallet_address: str,  ||  approval_duration: Optional[int] = None,  ||  Ensure sufficient token approval for spender.  ||  wallet_address: Wallet address that owns tokens  ||  use_permit2: Whether to use Permit2 for approvals  ||  approval_duration: Custom approval duration in seconds  ||  Approval result with transaction info  ||  ApprovalError: If approval fails  ||  approval_key = f""{chain}:{wallet_address}:{token_address}:{spender_address}""  ||  # Create lock for this approval if it doesn't exist  ||  if approval_key not in self._approval_locks:  ||  self._approval_locks[approval_key] = asyncio.Lock()  ||  async with self._approval_locks[approval_key]:  ||  chain, token_address, wallet_address, spender_address  ||  'wallet_address': wallet_address,  ||  # Check if approval is sufficient  ||  self._track_approval(  ||  approval_key, current_allowance, spender_address,  ||  approval_duration or self.default_approval_duration  ||  # Calculate optimal approval amount  ||  approval_amount = self._calculate_approval_amount(required_amount)  ||  # Execute approval  ||  chain, wallet_address, token_address,  ||  spender_address, approval_amount  ||  chain, wallet_address, token_address,  ||  spender_address, approval_amount  ||  # Track the new approval  ||  self._track_approval(  ||  approval_key, approval_amount, spender_address,  ||  approval_duration or self.default_approval_duration  ||  f""Approval completed: {approval_amount} for {token_address}"",  ||  'wallet_address': wallet_address,  ||  'approval_amount': str(approval_amount),  ||  ""approval_amount"": str(approval_amount),  ||  ""gas_used"": tx_result.get('gas_used'),  ||  logger.error(f""Approval failed: {e}"")  ||  raise ApprovalError(f""Approval failed: {e}"")  ||  async def revoke_approval(  ||  wallet_address: str,  ||  Revoke token approval for spender.  ||  wallet_address: Wallet address that owns tokens  ||  spender_address: Address to revoke approval from  ||  ApprovalError: If revocation fails  ||  # Execute revocation (set allowance to 0)  ||  chain, wallet_address, token_address, spender_address, Decimal(0)  ||  approval_key = f""{chain}:{wallet_address}:{token_address}:{spender_address}""  ||  if approval_key in self._active_approvals:  ||  del self._active_approvals[approval_key]  ||  f""Approval revoked for {token_address}"",  ||  'wallet_address': wallet_address,  ||  ""gas_used"": tx_result.get('gas_used')  ||  logger.error(f""Approval revocation failed: {e}"")  ||  raise ApprovalError(f""Approval revocation failed: {e}"")  ||  async def list_active_approvals(  ||  wallet_address: Optional[str] = None,  ||  List active token approvals.  ||  wallet_address: Optional wallet filter  ||  List of active approval information  ||  approvals = []  ||  for approval_key, approval_data in self._active_approvals.items():  ||  # Parse approval key  ||  key_parts = approval_key.split("":"")  ||  approval_chain, approval_wallet, token_addr, spender_addr = key_parts  ||  if chain and approval_chain != chain:  ||  if wallet_address and approval_wallet != wallet_address:  ||  expires_at = approval_data[""created_at""] + approval_data[""duration""]  ||  approval_info = {  ||  ""chain"": approval_chain,  ||  ""wallet_address"": approval_wallet,  ||  ""spender_name"": approval_data.get(""spender_name"", ""Unknown""),  ||  ""amount"": str(approval_data[""amount""]),  ||  ""created_at"": datetime.fromtimestamp(approval_data[""created_at""]).isoformat(),  ||  ""last_used"": approval_data.get(""last_used"")  ||  approvals.append(approval_info)  ||  approvals.sort(key=lambda x: x[""created_at""], reverse=True)  ||  return approvals  ||  async def cleanup_expired_approvals(self) -> Dict[str, int]:  ||  Clean up expired approvals and optionally revoke them.  ||  # Find expired approvals  ||  for approval_key, approval_data in self._active_approvals.items():  ||  expires_at = approval_data[""created_at""] + approval_data[""duration""]  ||  expired_keys.append(approval_key)  ||  # Process expired approvals  ||  for approval_key in expired_keys:  ||  key_parts = approval_key.split("":"")  ||  chain, wallet_address, token_address, spender_address = key_parts  ||  if settings.auto_revoke_expired_approvals:  ||  await self.revoke_approval(  ||  chain, wallet_address, token_address, spender_address  ||  errors.append(f""Failed to revoke {approval_key}: {e}"")  ||  del self._active_approvals[approval_key]  ||  errors.append(f""Failed to process expired approval {approval_key}: {e}"")  ||  f""Approval cleanup: {expired_count} expired, {revoked_count} revoked"",  ||  wallet_address: str,  ||  """"""Execute standard ERC-20 approval.""""""  ||  from ..core.wallet_registry import wallet_registry  ||  private_key = await wallet_registry.get_signing_key(chain, wallet_address)  ||  # Build approval transaction  ||  from_address=wallet_address,  ||  wallet_id=1,  # TODO: Get from context  ||  trace_id=f""approval_{int(time.time())}"",  ||  gas_used=receipt.get(""gasUsed"", 0)  ||  ""gas_used"": receipt.get(""gasUsed"", 0),  ||  logger.error(f""Standard approval failed: {e}"")  ||  raise ApprovalError(f""Standard approval failed: {e}"")  ||  wallet_address: str,  ||  """"""Execute approval using Permit2.""""""  ||  # TODO: Implement Permit2 approval  ||  logger.warning(""Permit2 approval not yet implemented, falling back to standard"")  ||  chain, wallet_address, token_address, spender_address, amount  ||  def _calculate_approval_amount(self, required_amount: Decimal) -> Decimal:  ||  """"""Calculate optimal approval amount.""""""  ||  max_amount = Decimal(self.max_approval_amount)  ||  def _track_approval(  ||  approval_key: str,  ||  """"""Track approval for management and revocation.""""""  ||  self._active_approvals[approval_key] = {  ||  # Global approval manager instance  ||  approval_manager = ApprovalManager()"
"D:\dex\backend\app\trading\canary.py","35476","from __future__ import annotations | import asyncio | import time | import uuid | from decimal import Decimal | from typing import Dict, List, Optional, Any, Tuple | from dataclasses import dataclass, field | from datetime import datetime, timezone, timedelta | from enum import Enum | import logging | from ..core.settings import settings | from ..dex.uniswap_v2 import UniswapV2Adapter | from ..dex.uniswap_v3 import UniswapV3Adapter | from ..dex.pancake import PancakeAdapter | from ..dex.jupiter import JupiterAdapter | from ..trading.executor import TradeExecutor | from ..trading.gas_strategy import GasStrategy | from ..chains.evm_client import EVMClient | from ..chains.solana_client import SolanaClient |             import random |             import random","from ..trading.executor import TradeExecutor  ||  from ..trading.gas_strategy import GasStrategy  ||  gas_multiplier: float = 1.2  ||  buy_gas_used: Optional[int] = None  ||  sell_gas_used: Optional[int] = None  ||  buy_gas_price: Optional[int] = None  ||  sell_gas_price: Optional[int] = None  ||  quote_token: str  ||  total_gas_used: int = 0  ||  self.trade_executor = TradeExecutor()  ||  self.gas_strategy = GasStrategy()  ||  self.canaries_executed = 0  ||  async def execute_canary_test(  ||  Execute comprehensive canary test.  ||  self.canaries_executed += 1  ||  # Determine quote token  ||  quote_token = self.native_tokens.get(chain, """")  ||  if not quote_token:  ||  quote_token=quote_token,  ||  # Execute strategy-specific testing  ||  await self._execute_instant_strategy(result, chain_clients)  ||  await self._execute_delayed_strategy(result, chain_clients)  ||  await self._execute_graduated_strategy(result, chain_clients)  ||  await self._execute_comprehensive_strategy(result, chain_clients)  ||  canary_id, token_address, quote_token, chain, dex,  ||  canary_id, token_address, quote_token, chain, dex,  ||  async def _execute_instant_strategy(  ||  """"""Execute instant buy/sell strategy.""""""  ||  # Step 1: Execute buy  ||  buy_result = await self._execute_canary_buy(  ||  result.quote_token,  ||  stage.buy_gas_used = buy_result.get(""gas_used"", 0)  ||  sell_result = await self._execute_canary_sell(  ||  result.quote_token,  ||  stage.sell_gas_used = sell_result.get(""gas_used"", 0)  ||  async def _execute_delayed_strategy(  ||  """"""Execute delayed buy/sell strategy with wait period.""""""  ||  # Execute buy  ||  buy_result = await self._execute_canary_buy(  ||  result.quote_token,  ||  stage.buy_gas_used = buy_result.get(""gas_used"", 0)  ||  # Execute sell  ||  sell_result = await self._execute_canary_sell(  ||  result.quote_token,  ||  stage.sell_gas_used = sell_result.get(""gas_used"", 0)  ||  async def _execute_graduated_strategy(  ||  """"""Execute graduated sizing strategy with progressive amounts.""""""  ||  # Execute instant test for this size  ||  await self._execute_single_stage(stage, result, chain_clients)  ||  async def _execute_comprehensive_strategy(  ||  """"""Execute comprehensive multi-stage analysis.""""""  ||  await self._execute_single_stage(micro_stage, result, chain_clients)  ||  await self._execute_single_stage(standard_stage, result, chain_clients)  ||  # Execute with delay  ||  buy_result = await self._execute_canary_buy(  ||  result.token_address, result.quote_token, result.chain,  ||  sell_result = await self._execute_canary_sell(  ||  result.token_address, result.quote_token, result.chain,  ||  async def _execute_single_stage(  ||  """"""Execute a single canary stage.""""""  ||  buy_result = await self._execute_canary_buy(  ||  result.quote_token,  ||  stage.buy_gas_used = buy_result.get(""gas_used"", 0)  ||  sell_result = await self._execute_canary_sell(  ||  result.quote_token,  ||  stage.sell_gas_used = sell_result.get(""gas_used"", 0)  ||  async def _execute_canary_buy(  ||  quote_token: str,  ||  """"""Execute canary buy operation.""""""  ||  # This would integrate with the actual DEX adapters and trade executor  ||  ""gas_used"": random.randint(100000, 200000),  ||  async def _execute_canary_sell(  ||  quote_token: str,  ||  """"""Execute canary sell operation.""""""  ||  # This would integrate with the actual DEX adapters and trade executor  ||  ""gas_used"": random.randint(80000, 150000),  ||  # Normal successful trade with typical slippage  ||  ""gas_used"": random.randint(80000, 150000),  ||  result.total_gas_used = sum(  ||  (stage.buy_gas_used or 0) + (stage.sell_gas_used or 0)  ||  recommendations.append(""✅ Token passed canary tests - generally safe to trade"")  ||  recommendations.append(""🍯 HONEYPOT DETECTED - DO NOT TRADE"")  ||  quote_token: str,  ||  quote_token=quote_token,  ||  total_tests = self.canaries_executed"
"D:\dex\backend\app\trading\executor.py","52087","from __future__ import annotations | import asyncio | import logging | import random | import time | import uuid | from dataclasses import dataclass | from decimal import Decimal | from enum import Enum | from typing import TYPE_CHECKING, Any, Dict, List, Optional, Tuple | from pydantic import BaseModel, Field | from ..core.settings import settings  # noqa: F401  (used by implementations not shown) | from .models import ( | from .protocols import TradeExecutorProtocol |     from .nonce_manager import NonceManager |     from .canary import CanaryTradeValidator |     from ..storage.repositories import TransactionRepository |     from ..ledger.ledger_writer import LedgerWriter |             from ..ai.market_intelligence import MarketIntelligenceEngine","DEX Sniper Pro - Trade Executor with Dual-Mode + AI Integration.  ||  This module provides the core TradeExecutor (live + paper trading) and enhances it  ||  slippage, delay/blocks, and risk-aware execution.  ||  TradePreview,  ||  TradeRequest,  ||  TradeResult,  ||  TradeStatus,  ||  TradeType,  ||  from .protocols import TradeExecutorProtocol  ||  from .nonce_manager import NonceManager  ||  from .canary import CanaryTradeValidator  ||  from ..ledger.ledger_writer import LedgerWriter  ||  """"""Trade execution modes for dual-mode trading.""""""  ||  class PaperTradeSimulation(BaseModel):  ||  """"""Paper trade simulation configuration.""""""  ||  # Gas simulation  ||  gas_variance: float = Field(default=0.15, description=""Gas price variance (±15%)"")  ||  class TradeExecutor(TradeExecutorProtocol):  ||  """"""Core trade execution engine with dual-mode support, enhanced with AI integration.""""""  ||  nonce_manager: ""NonceManager"",  ||  canary_validator: ""CanaryTradeValidator"",  ||  ledger_writer: ""LedgerWriter"",  ||  Initialize trade executor.  ||  nonce_manager: Manages transaction nonces per chain  ||  canary_validator: Validates trades with small test amounts  ||  ledger_writer: Service for trade ledger recording  ||  self.nonce_manager = nonce_manager  ||  self.ledger_writer = ledger_writer  ||  self.paper_simulation = PaperTradeSimulation()  ||  ""TradeExecutor initialized with dual-mode support (live + paper trading)""  ||  # Active trades tracking  ||  self.active_trades: Dict[str, TradeResult] = {}  ||  self.paper_trade_count = 0  ||  # Keep original execute_trade, then wrap with AI-informed version.  ||  self._original_execute_trade = self.execute_trade  # bound method  ||  self.execute_trade = enhance_trade_executor_with_ai().__get__(self, TradeExecutor)  ||  async def preview_trade(  ||  request: TradeRequest,  ||  ) -> TradePreview:  ||  Generate trade preview with validation (identical for both modes).  ||  ""Generating trade preview: %s"",  ||  # Check wallet balance  ||  balance_check = await self._check_wallet_balance(request, client)  ||  # Check token approvals  ||  approval_check = await self._check_token_approval(request, client)  ||  if not approval_check[""approved""]:  ||  f""Token approval required: {approval_check['message']}""  ||  # Estimate gas  ||  gas_estimate, gas_price = await self._estimate_gas_and_price(  ||  gas_estimate, gas_price, request.chain  ||  preview = TradePreview(  ||  gas_estimate=str(gas_estimate),  ||  gas_price=str(gas_price),  ||  ""Trade preview completed: %s, valid: %s"",  ||  ""Trade preview failed: %s: %s"",  ||  async def execute_trade(  # NOTE: wrapped by AI at runtime in __init__  ||  request: TradeRequest,  ||  preview: Optional[TradePreview] = None,  ||  ) -> TradeResult:  ||  Execute trade with full validation and monitoring.  ||  ""Starting trade execution: %s (mode: %s)"",  ||  ""trade_type"": request.trade_type,  ||  ""wallet"": request.wallet_address,  ||  # Initialize trade result  ||  result = TradeResult(  ||  status=TradeStatus.PENDING,  ||  # Track active trade  ||  self.active_trades[trace_id] = result  ||  result.status = TradeStatus.BUILDING  ||  preview = await self.preview_trade(request, chain_clients)  ||  result.status = TradeStatus.FAILED  ||  f""Invalid trade: {', '.join(preview.validation_errors)}""  ||  return await self._execute_paper_trade(request, result, preview)  ||  return await self._execute_solana_trade(request, client, result)  ||  return await self._execute_evm_trade(request, client, result, preview)  ||  ""Trade execution failed: %s: %s"",  ||  result.status = TradeStatus.FAILED  ||  # Write to ledger (both modes)  ||  await self._write_to_ledger(request, result, execution_mode)  ||  # Clean up active trades after completion  ||  TradeStatus.CONFIRMED,  ||  TradeStatus.FAILED,  ||  TradeStatus.REVERTED,  ||  self.active_trades.pop(trace_id, None)  ||  async def _execute_paper_trade(  ||  request: TradeRequest,  ||  result: TradeResult,  ||  preview: TradePreview,  ||  ) -> TradeResult:  ||  """"""Execute realistic paper trade simulation.""""""  ||  # Update paper trade metrics  ||  self.paper_trade_count += 1  ||  ""Executing paper trade: %s"",  ||  ""paper_trade_count"": self.paper_trade_count,  ||  # Simulate approval phase if needed  ||  result.status = TradeStatus.APPROVING  ||  await asyncio.sleep(0.1)  # Brief approval delay  ||  result.status = TradeStatus.BUILDING  ||  TradeStatus.REVERTED if failure_result[""reverted""] else TradeStatus.FAILED  ||  ""Paper trade failed: %s: %s"",  ||  result.status = TradeStatus.EXECUTING  ||  # Simulate gas usage  ||  simulated_gas = self._simulate_gas_usage(preview)  ||  result.status = TradeStatus.SUBMITTED  ||  result.status = TradeStatus.CONFIRMED  ||  result.gas_used = str(simulated_gas[""gas_used""])  ||  ""Paper trade executed successfully: %s"",  ||  self.paper_success_count / self.paper_trade_count  ||  if self.paper_trade_count  ||  logger.error(""Paper trade execution error: %s"", e)  ||  result.status = TradeStatus.FAILED  ||  result.error_message = f""Paper trade simulation error: {str(e)}""  ||  def _simulate_execution_failures(self, request: TradeRequest) -> Dict[str, Any]:  ||  # Transaction failure (network issues, gas estimation errors)  ||  ""reason"": ""Transaction failed: gas estimation error"",  ||  self, request: TradeRequest, preview: TradePreview  ||  request: TradeRequest,  ||  preview: TradePreview,  ||  def _simulate_gas_usage(self, preview: TradePreview) -> Dict[str, Any]:  ||  """"""Simulate realistic gas usage with variance.""""""  ||  base_gas = int(preview.gas_estimate)  ||  # Gas can vary by ±15% due to network conditions  ||  variance = int(base_gas * self.paper_simulation.gas_variance)  ||  actual_gas = random.randint(max(21000, base_gas - variance), base_gas + variance)  ||  ""gas_used"": actual_gas,  ||  ""gas_efficiency"": actual_gas / base_gas if base_gas > 0 else 1.0,  ||  self.paper_success_count / self.paper_trade_count  ||  if self.paper_trade_count > 0  ||  ""total_paper_trades"": self.paper_trade_count,  ||  ""successful_paper_trades"": self.paper_success_count,  ||  async def _execute_evm_trade(  ||  request: TradeRequest,  ||  result: TradeResult,  ||  preview: TradePreview,  ||  ) -> TradeResult:  ||  """"""Execute EVM-based trade.""""""  ||  # Handle approvals if needed  ||  result.status = TradeStatus.APPROVING  ||  await self._handle_token_approval(request, client, w3)  ||  result.status = TradeStatus.BUILDING  ||  # Get nonce  ||  nonce = await self.nonce_manager.get_next_nonce(  ||  request.wallet_address, request.chain  ||  # Execute canary trade if required  ||  if request.trade_type == TradeType.AUTOTRADE:  ||  canary_result = await self.canary_validator.validate_trade(  ||  result.status = TradeStatus.FAILED  ||  # Execute trade  ||  result.status = TradeStatus.EXECUTING  ||  tx_data, nonce, request.wallet_address, client  ||  result.status = TradeStatus.SUBMITTED  ||  result.status = TradeStatus.CONFIRMED  ||  result.gas_used = str(confirmation_result.gas_used)  ||  TradeStatus.REVERTED if confirmation_result.reverted else TradeStatus.FAILED  ||  logger.error(""EVM trade execution failed: %s"", e)  ||  result.status = TradeStatus.FAILED  ||  async def _execute_solana_trade(  ||  request: TradeRequest,  ||  result: TradeResult,  ||  ) -> TradeResult:  ||  """"""Execute Solana-based trade via Jupiter.""""""  ||  result.status = TradeStatus.EXECUTING  ||  user_public_key=request.wallet_address,  ||  result.status = TradeStatus.SUBMITTING  ||  swap_transaction, request.wallet_address  ||  result.status = TradeStatus.SUBMITTED  ||  result.status = TradeStatus.CONFIRMED  ||  result.status = TradeStatus.FAILED  ||  logger.error(""Solana trade execution failed: %s"", e)  ||  result.status = TradeStatus.FAILED  ||  async def get_trade_status(self, trace_id: str) -> Optional[TradeResult]:  ||  """"""Get current status of a trade.""""""  ||  if trace_id in self.active_trades:  ||  return self.active_trades[trace_id]  ||  # Check database for completed trades  ||  db_trade = await self.transaction_repo.get_by_trace_id(trace_id)  ||  if db_trade:  ||  return TradeResult(  ||  status=TradeStatus(db_trade.status),  ||  transaction_id=str(db_trade.id),  ||  tx_hash=db_trade.tx_hash,  ||  block_number=db_trade.block_number,  ||  gas_used=str(db_trade.gas_used) if db_trade.gas_used else None,  ||  str(db_trade.output_amount) if db_trade.output_amount else None  ||  error_message=db_trade.error_message,  ||  execution_time_ms=0.0,  # Historical trades don't track exec time  ||  logger.warning(""Failed to fetch trade from database: %s"", e)  ||  async def cancel_trade(self, trace_id: str) -> bool:  ||  """"""Cancel an active trade if possible.""""""  ||  if trace_id not in self.active_trades:  ||  trade = self.active_trades[trace_id]  ||  # Can only cancel trades that haven't been submitted  ||  if trade.status in [  ||  TradeStatus.PENDING,  ||  TradeStatus.BUILDING,  ||  TradeStatus.APPROVING,  ||  trade.status = TradeStatus.CANCELLED  ||  trade.error_message = ""Trade cancelled by user""  ||  # Remove from active trades  ||  self.active_trades.pop(trace_id, None)  ||  logger.info(""Trade cancelled: %s"", trace_id)  ||  logger.warning(""Cannot cancel trade in status %s: %s"", trade.status, trace_id)  ||  request: TradeRequest,  ||  ) -> TradePreview:  ||  """"""Create invalid trade preview.""""""  ||  return TradePreview(  ||  gas_estimate=""0"",  ||  gas_price=""0"",  ||  async def _validate_token_addresses(self, request: TradeRequest, client) -> bool:  ||  async def _check_wallet_balance(self, request: TradeRequest, client) -> Dict[str, Any]:  ||  """"""Check if wallet has sufficient balance.""""""  ||  async def _check_token_approval(self, request: TradeRequest, client) -> Dict[str, Any]:  ||  """"""Check if token approval is sufficient.""""""  ||  return {""approved"": True, ""message"": ""Approval check passed""}  ||  async def _estimate_gas_and_price(  ||  self, request: TradeRequest, client  ||  """"""Estimate gas and gas price for transaction.""""""  ||  base_gas = 180000 if ""v3"" in request.dex else 150000  ||  gas_price = 20_000_000_000  # 20 Gwei in wei  ||  return base_gas, gas_price  ||  self, gas_estimate: int, gas_price: int, chain: str  ||  return Decimal(str(gas_estimate * gas_price))  ||  async def _handle_token_approval(self, request: TradeRequest, client, w3) -> None:  ||  """"""Handle token approval if needed.""""""  ||  self, request: TradeRequest, client, w3, preview: TradePreview  ||  self, tx_data: Dict[str, Any], nonce: int, wallet: str, client  ||  gas_used = 150000  ||  async def _write_to_ledger(  ||  request: TradeRequest,  ||  result: TradeResult,  ||  """"""Write trade result to ledger with execution mode tracking.""""""  ||  await self.ledger_writer.write_trade(  ||  trade_type=request.trade_type,  ||  gas_used=result.gas_used,  ||  logger.error(""Failed to write to ledger: %s"", e)  ||  class RiskLevel(str, Enum):  ||  """"""AI-derived risk assessment levels.""""""  ||  """"""AI intelligence data for trade execution.""""""  ||  coordination_risk_score: float  # 0.0 to 100.0  ||  ai_risk_level: RiskLevel  ||  whale_dump_risk: bool  ||  AI-informed trade execution enhancement.  ||  Adds AI intelligence consumption to the existing TradeExecutor.  ||  self.coordination_risk_threshold = 70.0  ||  coordination_risk_score=analysis.get(""coordination_risk"", 0.0),  ||  ai_risk_level=RiskLevel(analysis.get(""risk_level"", ""moderate"")),  ||  whale_dump_risk=analysis.get(""whale_dump_risk"", False),  ||  def should_block_trade(self, intelligence: AIIntelligence) -> Tuple[bool, str]:  ||  """"""Determine if trade should be blocked based on AI intelligence.""""""  ||  if intelligence.coordination_risk_score > self.coordination_risk_threshold:  ||  return True, f""High coordination risk: {intelligence.coordination_risk_score:.1f}%""  ||  if intelligence.whale_dump_risk:  ||  return True, ""Whale dump risk detected""  ||  async def apply_ai_intelligence_to_trade(  ||  self, request: ""TradeRequest"", token_address: str  ||  ) -> ""TradeRequest"":  ||  """"""Apply AI intelligence adjustments to trade request.""""""  ||  should_block, block_reason = self.should_block_trade(intelligence)  ||  ""AI blocked trade: %s"",  ||  ""coordination_risk"": intelligence.coordination_risk_score,  ||  raise Exception(f""AI intelligence blocked trade: {block_reason}"")  ||  ""risk_level"": intelligence.ai_risk_level.value,  ||  ""coordination_risk"": intelligence.coordination_risk_score,  ||  ""Applied AI intelligence to trade request"",  ||  ""risk_level"": intelligence.ai_risk_level.value,  ||  ""whale_dump"": intelligence.whale_dump_risk,  ||  def enhance_trade_executor_with_ai():  ||  Integration function to enhance the existing TradeExecutor with AI intelligence.  ||  This returns a coroutine method that wraps the original `execute_trade`.  ||  async def ai_informed_execute_trade(  ||  self: TradeExecutor,  ||  request: ""TradeRequest"",  ||  preview: Optional[""TradePreview""] = None,  ||  ) -> ""TradeResult"":  ||  enhanced_request = await self.ai_executor.apply_ai_intelligence_to_trade(  ||  ""Trade enhanced with AI intelligence"",  ||  return await self._original_execute_trade(  ||  ""AI enhancement failed, proceeding with original trade: %s"",  ||  return await self._original_execute_trade(  ||  return ai_informed_execute_trade  ||  async def execute_live_trade(  ||  executor: TradeExecutor,  ||  request: TradeRequest,  ||  preview: Optional[TradePreview] = None,  ||  ) -> TradeResult:  ||  """"""Execute live trade with real funds.""""""  ||  return await executor.execute_trade(  ||  async def execute_paper_trade(  ||  executor: TradeExecutor,  ||  request: TradeRequest,  ||  preview: Optional[TradePreview] = None,  ||  ) -> TradeResult:  ||  """"""Execute paper trade simulation (no real funds).""""""  ||  return await executor.execute_trade("
"D:\dex\backend\app\trading\models.py","4378","from __future__ import annotations | from decimal import Decimal | from enum import Enum | from typing import List, Optional, Dict, Any | from datetime import datetime | from pydantic import BaseModel, Field","class TradeStatus(str, Enum):  ||  """"""Trade execution status.""""""  ||  class TradeType(str, Enum):  ||  """"""Trade type classification.""""""  ||  AUTOTRADE = ""autotrade""  ||  class TradeRequest(BaseModel):  ||  """"""Trade execution request.""""""  ||  dex: str = Field(..., description=""DEX to execute on"")  ||  wallet_address: str = Field(..., description=""Wallet address"")  ||  trade_type: TradeType = Field(default=TradeType.MANUAL, description=""Trade type"")  ||  gas_price_gwei: Optional[str] = Field(default=None, description=""Custom gas price in Gwei"")  ||  class TradeResult(BaseModel):  ||  """"""Trade execution result.""""""  ||  status: TradeStatus = Field(..., description=""Execution status"")  ||  gas_used: Optional[str] = Field(default=None, description=""Gas used"")  ||  class TradePreview(BaseModel):  ||  """"""Trade preview with cost estimation.""""""  ||  gas_estimate: str = Field(..., description=""Estimated gas units"")  # Changed from estimated_gas  ||  gas_price: str = Field(..., description=""Gas price in gwei"")"
"D:\dex\backend\app\trading\nonce_manager.py","14407","from __future__ import annotations | import asyncio | import logging | from typing import Dict, Optional | import logging | from ..core.settings import settings","Nonce management service for reliable transaction ordering.  ||  class NonceManager:  ||  Thread-safe nonce management for multiple chains and wallets.  ||  Ensures sequential nonce allocation to prevent transaction conflicts  ||  and handles nonce recovery for failed transactions.  ||  """"""Initialize nonce manager.""""""  ||  # Format: {chain: {wallet_address: {current_nonce: int, pending_count: int, lock: asyncio.Lock}}}  ||  self._nonce_data: Dict[str, Dict[str, Dict]] = {}  ||  async def get_next_nonce(self, wallet_address: str, chain: str) -> int:  ||  Get the next available nonce for a wallet on a specific chain.  ||  wallet_address: Wallet address (checksummed)  ||  Next available nonce  ||  if chain not in self._nonce_data:  ||  self._nonce_data[chain] = {}  ||  # Initialize wallet if not exists  ||  if wallet_address not in self._nonce_data[chain]:  ||  self._nonce_data[chain][wallet_address] = {  ||  ""current_nonce"": None,  ||  # Use wallet-specific lock for thread safety  ||  wallet_data = self._nonce_data[chain][wallet_address]  ||  async with wallet_data[""lock""]:  ||  # Get current nonce from chain if not cached  ||  if wallet_data[""current_nonce""] is None:  ||  wallet_data[""current_nonce""] = await self._fetch_nonce_from_chain(  ||  wallet_address, chain  ||  f""Initialized nonce for {wallet_address} on {chain}: {wallet_data['current_nonce']}"",  ||  'wallet': wallet_address,  ||  'nonce': wallet_data['current_nonce'],  ||  # Calculate next nonce considering pending transactions  ||  next_nonce = wallet_data[""current_nonce""] + wallet_data[""pending_count""]  ||  wallet_data[""pending_count""] += 1  ||  f""Allocated nonce {next_nonce} for {wallet_address} on {chain}"",  ||  'wallet': wallet_address,  ||  'nonce': next_nonce,  ||  'pending_count': wallet_data[""pending_count""],  ||  return next_nonce  ||  async def confirm_nonce(self, wallet_address: str, chain: str, nonce: int) -> None:  ||  Confirm that a nonce has been successfully used.  ||  wallet_address: Wallet address  ||  nonce: Confirmed nonce  ||  if (chain in self._nonce_data and  ||  wallet_address in self._nonce_data[chain]):  ||  wallet_data = self._nonce_data[chain][wallet_address]  ||  async with wallet_data[""lock""]:  ||  # Update current nonce if this is the next expected nonce  ||  if nonce == wallet_data[""current_nonce""]:  ||  wallet_data[""current_nonce""] = nonce + 1  ||  wallet_data[""pending_count""] = max(0, wallet_data[""pending_count""] - 1)  ||  f""Confirmed nonce {nonce} for {wallet_address} on {chain}"",  ||  'wallet': wallet_address,  ||  'confirmed_nonce': nonce,  ||  'new_current': wallet_data[""current_nonce""],  ||  'pending_count': wallet_data[""pending_count""],  ||  f""Nonce confirmation out of order: expected {wallet_data['current_nonce']}, got {nonce}"",  ||  'wallet': wallet_address,  ||  'expected_nonce': wallet_data['current_nonce'],  ||  'confirmed_nonce': nonce,  ||  # Trigger nonce recovery  ||  await self._recover_nonce(wallet_address, chain)  ||  async def fail_nonce(self, wallet_address: str, chain: str, nonce: int) -> None:  ||  Handle a failed transaction nonce.  ||  wallet_address: Wallet address  ||  nonce: Failed nonce  ||  if (chain in self._nonce_data and  ||  wallet_address in self._nonce_data[chain]):  ||  wallet_data = self._nonce_data[chain][wallet_address]  ||  async with wallet_data[""lock""]:  ||  # Decrease pending count but don't advance current_nonce  ||  # Failed nonce can be reused  ||  wallet_data[""pending_count""] = max(0, wallet_data[""pending_count""] - 1)  ||  f""Failed nonce {nonce} for {wallet_address} on {chain}"",  ||  'wallet': wallet_address,  ||  'failed_nonce': nonce,  ||  'pending_count': wallet_data[""pending_count""],  ||  async def reset_nonce(self, wallet_address: str, chain: str) -> None:  ||  Reset nonce tracking for a wallet (force refresh from chain).  ||  wallet_address: Wallet address  ||  if (chain in self._nonce_data and  ||  wallet_address in self._nonce_data[chain]):  ||  wallet_data = self._nonce_data[chain][wallet_address]  ||  async with wallet_data[""lock""]:  ||  # Fetch fresh nonce from chain  ||  chain_nonce = await self._fetch_nonce_from_chain(wallet_address, chain)  ||  wallet_data[""current_nonce""] = chain_nonce  ||  wallet_data[""pending_count""] = 0  ||  f""Reset nonce for {wallet_address} on {chain} to {chain_nonce}"",  ||  'wallet': wallet_address,  ||  'reset_nonce': chain_nonce,  ||  async def get_current_nonce(self, wallet_address: str, chain: str) -> Optional[int]:  ||  Get current nonce for a wallet without incrementing.  ||  wallet_address: Wallet address  ||  Current nonce or None if not tracked  ||  if (chain in self._nonce_data and  ||  wallet_address in self._nonce_data[chain]):  ||  wallet_data = self._nonce_data[chain][wallet_address]  ||  return wallet_data.get(""current_nonce"")  ||  async def get_pending_count(self, wallet_address: str, chain: str) -> int:  ||  Get number of pending transactions for a wallet.  ||  wallet_address: Wallet address  ||  if (chain in self._nonce_data and  ||  wallet_address in self._nonce_data[chain]):  ||  wallet_data = self._nonce_data[chain][wallet_address]  ||  return wallet_data.get(""pending_count"", 0)  ||  async def _fetch_nonce_from_chain(self, wallet_address: str, chain: str) -> int:  ||  Fetch current nonce from the blockchain.  ||  wallet_address: Wallet address  ||  Current nonce from chain  ||  # - Call web3.eth.get_transaction_count(wallet_address, 'pending')  ||  # - Return the nonce  ||  logger.debug(f""Fetching nonce from {chain} for {wallet_address}"")  ||  # Return mock nonce (in real implementation, this would be actual chain call)  ||  f""Failed to fetch nonce from {chain} for {wallet_address}: {e}"",  ||  'wallet': wallet_address,  ||  async def _recover_nonce(self, wallet_address: str, chain: str) -> None:  ||  Recover nonce state by fetching from chain.  ||  wallet_address: Wallet address  ||  f""Recovering nonce for {wallet_address} on {chain}"",  ||  'wallet': wallet_address,  ||  # Fetch current nonce from chain  ||  chain_nonce = await self._fetch_nonce_from_chain(wallet_address, chain)  ||  wallet_data = self._nonce_data[chain][wallet_address]  ||  old_nonce = wallet_data[""current_nonce""]  ||  old_pending = wallet_data[""pending_count""]  ||  wallet_data[""current_nonce""] = chain_nonce  ||  wallet_data[""pending_count""] = 0  ||  f""Nonce recovery completed: {old_nonce} -> {chain_nonce}, pending: {old_pending} -> 0"",  ||  'wallet': wallet_address,  ||  'old_nonce': old_nonce,  ||  'new_nonce': chain_nonce,  ||  f""Nonce recovery failed for {wallet_address} on {chain}: {e}"",  ||  'wallet': wallet_address,  ||  Get health status of nonce manager.  ||  total_wallets = sum(len(wallets) for wallets in self._nonce_data.values())  ||  wallet_data.get(""pending_count"", 0)  ||  for chain_data in self._nonce_data.values()  ||  for wallet_data in chain_data.values()  ||  ""tracked_chains"": len(self._nonce_data),  ||  ""tracked_wallets"": total_wallets,  ||  ""wallets"": len(wallets),  ||  w.get(""pending_count"", 0) for w in wallets.values()  ||  for chain, wallets in self._nonce_data.items()"
"D:\dex\backend\app\trading\protocols.py","2429","from __future__ import annotations | from abc import ABC, abstractmethod | from typing import Dict, Optional, Any | from decimal import Decimal | from .models import TradeRequest, TradeResult, TradePreview","from .models import TradeRequest, TradeResult, TradePreview  ||  class TradeExecutorProtocol(ABC):  ||  """"""Protocol interface for trade executor to avoid circular imports.""""""  ||  async def preview_trade(  ||  request: TradeRequest,  ||  ) -> TradePreview:  ||  Generate trade preview with validation and cost estimation.  ||  request: Trade execution request details  ||  TradePreview: Complete preview with routing and validation  ||  async def execute_trade(  ||  request: TradeRequest,  ||  preview: Optional[TradePreview] = None,  ||  ) -> TradeResult:  ||  Execute trade transaction with monitoring and safety checks.  ||  request: Trade execution request details  ||  preview: Optional pre-computed trade preview  ||  TradeResult: Execution result with transaction details  ||  TradingError: When trade execution fails  ||  async def execute_canary(  ||  request: TradeRequest,  ||  ) -> TradeResult:  ||  Execute small canary trade for risk validation.  ||  request: Base trade request for canary execution  ||  TradeResult: Canary execution result"
"D:\dex\backend\app\ws\autotrade_handler.py","1459","from app.strategy.autotrade_strategy import AIAutotradeStrategy | import logging","from app.strategy.autotrade_strategy import AIAutotradeStrategy  ||  class AutotradeWebSocketHandler:  ||  self.ai_strategy = AIAutotradeStrategy()  ||  async def handle_trade_opportunity(self, opportunity: dict):  ||  """"""Process a trade opportunity through AI before execution.""""""  ||  ai_decision = await self.ai_strategy.evaluate_trade_opportunity(  ||  # Execute trade if approved  ||  if ai_decision['decision'] == 'execute':  ||  await self.execute_trade(  ||  logger.info(f""AI blocked trade: {ai_decision['reasoning']}"")"
"D:\dex\backend\app\ws\hub.py","21697","import asyncio | import json | import logging | import uuid | from datetime import datetime, timezone | from typing import Dict, Set, Optional, Any, List | from dataclasses import dataclass, asdict | from enum import Enum | from fastapi import WebSocket, WebSocketDisconnect","DEX Sniper Pro - WebSocket Hub Import Fix.  ||  from fastapi import WebSocket, WebSocketDisconnect  ||  """"""WebSocket message types for type safety.""""""  ||  # Autotrade messages  ||  TRADE_EXECUTED = ""trade_executed""  ||  RISK_ALERT = ""risk_alert""  ||  RISK_UPDATE = ""risk_update""  ||  """"""WebSocket channels for message routing.""""""  ||  AUTOTRADE = ""autotrade""  ||  class WebSocketMessage:  ||  """"""Standardized WebSocket message structure.""""""  ||  logger.error(f""Failed to serialize WebSocket message: {e}"")  ||  def from_dict(cls, data: Dict[str, Any]) -> 'WebSocketMessage':  ||  logger.error(f""Invalid WebSocket message format: {e}"")  ||  raise ValueError(f""Invalid WebSocket message format: {e}"")  ||  """"""WebSocket client connection info.""""""  ||  websocket: WebSocket  ||  class WebSocketHub:  ||  Enhanced WebSocket connection manager with Intelligence Bridge.  ||  """"""Initialize the WebSocket hub with intelligence bridge.""""""  ||  Channel.AUTOTRADE: set(),  ||  logger.info(""WebSocket Hub initialized with Intelligence Bridge"")  ||  """"""Start the WebSocket hub with intelligence bridge.""""""  ||  logger.info(""WebSocket Hub started with background tasks and intelligence bridge"")  ||  logger.error(f""Failed to start WebSocket Hub: {e}"")  ||  """"""Stop the WebSocket hub and cleanup.""""""  ||  logger.info(""Stopping WebSocket Hub..."")  ||  logger.info(""WebSocket Hub stopped"")  ||  websocket: WebSocket,  ||  """"""Connect a new WebSocket client.""""""  ||  websocket=websocket,  ||  ack_message = WebSocketMessage(  ||  logger.info(f""WebSocket client connected: {client_id}"")  ||  logger.error(f""Failed to connect WebSocket client {client_id}: {e}"")  ||  """"""Disconnect a WebSocket client and cleanup.""""""  ||  # Close WebSocket  ||  if connection.websocket.client_state.name != ""DISCONNECTED"":  ||  await connection.websocket.close(code=1000, reason=reason[:120])  ||  logger.info(f""WebSocket client disconnected: {client_id}"")  ||  ack_message = WebSocketMessage(  ||  async def broadcast_to_channel(self, channel: Channel, message: WebSocketMessage) -> int:  ||  """"""Handle incoming message from a WebSocket client.""""""  ||  message = WebSocketMessage.from_dict(data)  ||  """"""Get WebSocket hub statistics.""""""  ||  if hasattr(self._intelligence_hub, 'register_autotrade_callback'):  ||  await self._intelligence_hub.register_autotrade_callback(self._handle_intelligence_event)  ||  ws_message = WebSocketMessage(  ||  # Send high-priority events to autotrade subscribers  ||  autotrade_message = WebSocketMessage(  ||  channel=Channel.AUTOTRADE,  ||  ""autotrade_relevance"": ""high""  ||  await self.broadcast_to_channel(Channel.AUTOTRADE, autotrade_message)  ||  async def _send_to_client(self, client_id: str, message: WebSocketMessage) -> bool:  ||  if connection.websocket.client_state.name == ""DISCONNECTED"":  ||  await self.disconnect_client(client_id, ""WebSocket disconnected"")  ||  await connection.websocket.send_text(message.to_json())  ||  except WebSocketDisconnect:  ||  async def _handle_heartbeat(self, client_id: str, message: WebSocketMessage) -> None:  ||  response = WebSocketMessage(  ||  async def _handle_subscription_request(self, client_id: str, message: WebSocketMessage) -> None:  ||  heartbeat_message = WebSocketMessage(  ||  # Global WebSocket hub instance - CRITICAL: This must be at module level  ||  ws_hub = WebSocketHub()  ||  __all__ = ['ws_hub', 'WebSocketHub', 'MessageType', 'Channel', 'WebSocketMessage']"
"D:\dex\backend\app\ws\intelligence_handler.py","4100","from fastapi import WebSocket, WebSocketDisconnect | from app.strategy.risk_scoring import RiskScorer, RiskFactors | from app.core.logging import get_logger | from decimal import Decimal | import asyncio | import json","WebSocket handler for real-time AI intelligence updates.  ||  from fastapi import WebSocket, WebSocketDisconnect  ||  from app.strategy.risk_scoring import RiskScorer, RiskFactors  ||  class IntelligenceWebSocketManager:  ||  self.risk_scorer = RiskScorer()  ||  async def connect(self, websocket: WebSocket, wallet_address: str):  ||  await websocket.accept()  ||  self.active_connections[wallet_address] = websocket  ||  logger.info(f""AI Intelligence WebSocket connected for {wallet_address}"")  ||  await websocket.send_json({  ||  def disconnect(self, wallet_address: str):  ||  if wallet_address in self.active_connections:  ||  del self.active_connections[wallet_address]  ||  logger.info(f""AI Intelligence WebSocket disconnected for {wallet_address}"")  ||  async def process_message(self, wallet_address: str, data: dict):  ||  if wallet_address not in self.active_connections:  ||  websocket = self.active_connections[wallet_address]  ||  await websocket.send_json({  ||  # Calculate risk score  ||  risk_factors = RiskFactors(  ||  risk_score = await self.risk_scorer.calculate_risk_score(risk_factors)  ||  await websocket.send_json({  ||  ""message"": f""📊 Risk Score: {risk_score.total_score}/100 ({risk_score.risk_level})"",  ||  if risk_score.positive_signals:  ||  await websocket.send_json({  ||  ""message"": f""✅ {risk_score.positive_signals[0]}"",  ||  if risk_score.risk_reasons:  ||  await websocket.send_json({  ||  ""message"": f""⚠️ {risk_score.risk_reasons[0]}"",  ||  decision = ""approved"" if risk_score.recommendation in [""trade"", ""consider""] else ""blocked""  ||  await websocket.send_json({  ||  ""risk_score"": risk_score.total_score,  ||  ""risk_level"": risk_score.risk_level,  ||  ""message"": f""{'✅ APPROVED' if decision == 'approved' else '❌ BLOCKED'}: {risk_score.recommendation.upper()}"",  ||  manager = IntelligenceWebSocketManager()"
"D:\dex\backend\app\ws\intelligence_hub.py","22739","from __future__ import annotations | import asyncio | import json | import logging | from typing import Dict, Set, Optional, Any, List, Callable | from datetime import datetime, timezone | from enum import Enum | from fastapi import WebSocket, WebSocketDisconnect | from pydantic import BaseModel |                 from ..ai.market_intelligence import MarketIntelligenceEngine |                 from ..discovery.event_processor import event_processor, ProcessingStatus |                 import random","DEX Sniper Pro - Intelligence WebSocket Hub with Autotrade Bridge.  ||  Enhanced with Phase 1.3 autotrade bridge functionality for routing AI intelligence  ||  to autotrade subscribers in real-time.  ||  from fastapi import WebSocket, WebSocketDisconnect  ||  """"""Intelligence event for WebSocket streaming.""""""  ||  class IntelligenceWebSocketHub:  ||  Enhanced WebSocket hub for real-time intelligence updates with autotrade bridge.  ||  Also routes high-priority intelligence to autotrade subscribers.  ||  """"""Initialize intelligence WebSocket hub with autotrade bridge.""""""  ||  self.active_connections: Dict[str, WebSocket] = {}  ||  # Autotrade bridge functionality  ||  self._autotrade_callbacks: List[Callable] = []  ||  logger.info(""Intelligence WebSocket Hub initialized with autotrade bridge support"")  ||  """"""Start the intelligence hub with event processor integration and autotrade bridge.""""""  ||  logger.warning(""Intelligence WebSocket hub already running"")  ||  logger.info(""Intelligence WebSocket hub started successfully with autotrade bridge"")  ||  logger.error(f""Failed to start Intelligence WebSocket hub: {e}"", exc_info=True)  ||  logger.info(""Stopping Intelligence WebSocket hub"")  ||  for user_id, websocket in self.active_connections.items():  ||  await websocket.close(code=1001, reason=""Server shutdown"")  ||  logger.warning(f""Error closing WebSocket for user {user_id}: {e}"")  ||  self._autotrade_callbacks.clear()  ||  logger.info(""Intelligence WebSocket hub stopped"")  ||  # Autotrade Bridge Methods  ||  async def register_autotrade_callback(self, callback: Callable[[Dict[str, Any]], None]) -> None:  ||  Register callback for autotrade intelligence events.  ||  self._autotrade_callbacks.append(callback)  ||  logger.info(f""Autotrade callback registered (total: {len(self._autotrade_callbacks)})"")  ||  await self._send_to_autotrade_bridge({  ||  ""message"": ""Autotrade bridge established"",  ||  ""callbacks_registered"": len(self._autotrade_callbacks),  ||  logger.error(f""Failed to register autotrade callback: {e}"")  ||  async def _send_to_autotrade_bridge(self, event_data: Dict[str, Any]) -> None:  ||  Send intelligence event to autotrade bridge.  ||  if not self._autotrade_callbacks:  ||  for callback in self._autotrade_callbacks:  ||  logger.error(f""Error calling autotrade callback: {e}"")  ||  logger.debug(f""Intelligence event sent to {len(self._autotrade_callbacks)} autotrade bridges"")  ||  logger.error(f""Error sending to autotrade bridge: {e}"")  ||  async def connect_user(self, websocket: WebSocket, user_id: str):  ||  websocket: WebSocket connection  ||  await websocket.accept()  ||  self.active_connections[user_id] = websocket  ||  logger.info(f""User {user_id} connected to intelligence hub (bridge: {len(self._autotrade_callbacks) > 0})"")  ||  ""autotrade_bridge_active"": len(self._autotrade_callbacks) > 0,  ||  ""features"": [""ai_analysis"", ""whale_tracking"", ""coordination_detection"", ""autotrade_bridge""]  ||  data = await websocket.receive_text()  ||  except WebSocketDisconnect:  ||  logger.error(f""Error in intelligence WebSocket connection for user {user_id}: {e}"")  ||  websocket = self.active_connections[user_id]  ||  await websocket.close()  ||  logger.warning(f""Error closing WebSocket for user {user_id}: {e}"")  ||  ""bridge_active"": len(self._autotrade_callbacks) > 0  ||  ""bridge_active"": len(self._autotrade_callbacks) > 0,  ||  ""callbacks_registered"": len(self._autotrade_callbacks),  ||  ""bridge_active"": len(self._autotrade_callbacks) > 0  ||  websocket = self.active_connections[user_id]  ||  await websocket.send_text(json.dumps(data, default=str))  ||  Broadcast intelligence event to subscribed users AND autotrade bridge.  ||  # Still send to autotrade bridge even if no direct subscribers  ||  # Send high-priority events to autotrade bridge  ||  """"""Send high-priority events to autotrade bridge.""""""  ||  await self._send_to_autotrade_bridge(bridge_data)  ||  ""risk_assessment"": pair_data.get(""risk_assessment"", {}),  ||  logger.error(f""Error processing pair approval: {e}"")  ||  """"""Background task to monitor market regime changes with autotrade bridge.""""""  ||  logger.info(f""Market regime changed to {current_regime} (bridged to autotrade)"")  ||  ""bridge_active"": len(self._autotrade_callbacks) > 0,  ||  ""bridge_callbacks"": len(self._autotrade_callbacks),  ||  Get current hub statistics including autotrade bridge metrics.  ||  ""bridge_active"": len(self._autotrade_callbacks) > 0,  ||  ""bridge_callbacks_registered"": len(self._autotrade_callbacks),  ||  intelligence_hub = IntelligenceWebSocketHub()"
"D:\dex\backend\app\ws\manager.py","5170","from __future__ import annotations | import json | import logging | from typing import Dict, Set, List, Optional, Any | from dataclasses import dataclass | from datetime import datetime | import asyncio | from fastapi import WebSocket, WebSocketDisconnect","WebSocket connection manager for DEX Sniper Pro.  ||  Handles WebSocket connections, channel subscriptions, and message broadcasting  ||  from fastapi import WebSocket, WebSocketDisconnect  ||  class WebSocketConnection:  ||  """"""Represents an active WebSocket connection.""""""  ||  websocket: WebSocket  ||  """"""Manages WebSocket connections and message broadcasting.""""""  ||  self.active_connections: Dict[str, WebSocketConnection] = {}  ||  async def connect(self, websocket: WebSocket, client_id: str) -> None:  ||  """"""Accept and register a new WebSocket connection.""""""  ||  await websocket.accept()  ||  connection = WebSocketConnection(  ||  websocket=websocket,  ||  logger.info(f""WebSocket connected: {client_id}"")  ||  """"""Remove a WebSocket connection.""""""  ||  logger.info(f""WebSocket disconnected: {client_id}"")  ||  await connection.websocket.send_text(json.dumps(message))  ||  WebSocketManager = ConnectionManager()"
"D:\dex\backend\app\ws\__init__.py","401","from __future__ import annotations | from .manager import WebSocketManager, ConnectionManager","WebSocket module for DEX Sniper Pro.  ||  - Autotrade status and execution updates  ||  - Risk alerts and monitoring  ||  __all__ = [""WebSocketManager"", ""ConnectionManager""]  ||  from .manager import WebSocketManager, ConnectionManager"
"D:\dex\backend\app\__init__.py","3","False",""
